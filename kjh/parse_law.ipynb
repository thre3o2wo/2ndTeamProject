{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ë²•ë¥  íŒŒì‹± í…ŒìŠ¤íŠ¸ ë…¸íŠ¸ë¶\n",
    "## ì£¼íƒì„ëŒ€ì°¨ RAG - ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•, ë¯¼ë²• íŒŒì‹±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-section",
   "metadata": {},
   "source": [
    "### 1. í•„ìš” íŒ¨í‚¤ì§€ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "import re\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "category-section",
   "metadata": {},
   "source": [
    "### 2. ì¹´í…Œê³ ë¦¬ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "category-def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¹´í…Œê³ ë¦¬ ì •ì˜ ì™„ë£Œ\n",
      "ì´ 9ê°œ ì¹´í…Œê³ ë¦¬\n"
     ]
    }
   ],
   "source": [
    "def get_law_category():\n",
    "    \"\"\"ì£¼íƒì„ëŒ€ì°¨ RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì¹´í…Œê³ ë¦¬-í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì‚¬ì „\"\"\"\n",
    "    return {\n",
    "        'ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥': {\n",
    "            'ë³´ì¦ê¸ˆ': 3, 'ëŒ€í•­ë ¥': 3, 'ìš°ì„ ë³€ì œê¶Œ': 3, 'ìµœìš°ì„ ë³€ì œ': 3,\n",
    "            'ë³´ì¦ê¸ˆë°˜í™˜': 3, 'ì „ì„¸ê¸ˆ': 2, 'ì†Œì•¡ì„ì°¨ì¸': 2, 'í™•ì •ì¼ì': 2,\n",
    "            'ì „ì…ì‹ ê³ ': 2, 'ì ìœ ': 2, 'ì„ì°¨ê¶Œë“±ê¸°': 3, 'ë°°ë‹¹': 2,\n",
    "            'ë°˜í™˜ë³´ì¦': 2, 'HUG': 1, 'ë³´ì¦ë³´í—˜': 2\n",
    "        },\n",
    "        'ê³„ì•½ê°±ì‹ ': {\n",
    "            'ê³„ì•½ê°±ì‹ ': 3, 'ê°±ì‹ ìš”êµ¬': 3, 'ê°±ì‹ ê±°ì ˆ': 3, 'ë¬µì‹œì ê°±ì‹ ': 3,\n",
    "            'ê³„ì•½ì—°ì¥': 2, 'ì‹¤ê±°ì£¼': 3, 'ì¡´ì†ê¸°ê°„': 2, '2ë…„': 1,\n",
    "            'ì¬ê³„ì•½': 2, 'ê°±ì‹ ì²­êµ¬': 2, 'ê±°ì ˆì‚¬ìœ ': 2, 'ë³µë¹„': 1\n",
    "        },\n",
    "        'ê³„ì•½í•´ì§€': {\n",
    "            'ê³„ì•½í•´ì§€': 3, 'í•´ì§€í†µê³ ': 3, 'ì¤‘ë„í•´ì§€': 3, 'ê¸°ê°„ë§Œë£Œ': 2,\n",
    "            'ê³„ì•½ì¢…ë£Œ': 2, 'í‡´ê±°': 2, 'ì´ì‚¬': 1, 'ëª…ë„': 2,\n",
    "            'í•©ì˜í•´ì§€': 2, 'í†µì§€': 1, '3ê°œì›”': 2, 'ì¦‰ì‹œí•´ì§€': 3\n",
    "        },\n",
    "        'ì„ëŒ€ë£Œ_ì¦ê°': {\n",
    "            'ì°¨ì„': 3, 'ì›”ì„¸': 2, 'ì¦ì•¡': 3, 'ê°ì•¡': 2, 'ì¸ìƒ': 2,\n",
    "            '5í¼ì„¼íŠ¸': 3, '5%': 3, '20ë¶„ì˜ 1': 2, 'ìƒí•œ': 2,\n",
    "            'ì „í™˜ìœ¨': 2, 'ì›”ì°¨ì„': 2, 'ê²½ì œì‚¬ì •': 1, 'ë¶€ë‹´': 1\n",
    "        },\n",
    "        'ìˆ˜ì„ _ì›ìƒíšŒë³µ': {\n",
    "            'ìˆ˜ì„ ': 3, 'ìˆ˜ë¦¬': 3, 'ì›ìƒíšŒë³µ': 3, 'íŒŒì†': 2, 'í›¼ì†': 2,\n",
    "            'ëˆ„ìˆ˜': 2, 'ê³°íŒ¡ì´': 2, 'ë³´ì¼ëŸ¬': 2, 'í•„ìš”ë¹„': 3, 'ìœ ìµë¹„': 3,\n",
    "            'ë¹„ìš©ìƒí™˜': 2, 'ë³´ì¡´í–‰ìœ„': 2, 'ê´€ë¦¬ë¹„': 1\n",
    "        },\n",
    "        'ê¶Œë¦¬_ë¦¬ìŠ¤í¬': {\n",
    "            'ì „ì„¸ì‚¬ê¸°': 3, 'ê¹¡í†µì „ì„¸': 3, 'ì‹ íƒ': 3, 'ê·¼ì €ë‹¹': 3, 'ì €ë‹¹ê¶Œ': 3,\n",
    "            'ì„ ìˆœìœ„': 3, 'ê°€ì••ë¥˜': 3, 'ì••ë¥˜': 3, 'êµ­ì„¸': 2, 'ì§€ë°©ì„¸': 2,\n",
    "            'ì²´ë‚©': 3, 'ë‚©ì„¸ì¦ëª…': 2, 'ìœ„ë°˜ê±´ì¶•ë¬¼': 2, 'ë¶ˆë²•ê±´ì¶•ë¬¼': 2,\n",
    "            'íŠ¹ì•½': 2, 'ë…ì†Œì¡°í•­': 2, 'ê°•í–‰ê·œì •': 3, 'íš¨ë ¥ì´ ì—†ë‹¤': 3,\n",
    "            'ë¬´íš¨': 3, 'ë¶ˆë¦¬í•œ ì•½ì •': 3, 'í¸ë©´ì  ê°•í–‰ê·œì •': 2\n",
    "        },\n",
    "        'í–‰ì •ì ˆì°¨': {\n",
    "            'í™•ì •ì¼ìë¶€ì—¬': 3, 'ë™ì£¼ë¯¼ì„¼í„°': 2, 'ë“±ê¸°ì†Œ': 2, 'ì¸í„°ë„·ë“±ê¸°ì†Œ': 3,\n",
    "            'ìˆ˜ìˆ˜ë£Œ': 1, 'ì—´ëŒ': 2, 'ì œê³µìš”ì²­': 2, 'ì´í•´ê´€ê³„ì¸': 2,\n",
    "            'ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ': 2, 'ì „ìê³„ì•½': 2, 'ì‹ ë¶„ì¦': 1\n",
    "        },\n",
    "        'ë¶„ìŸí•´ê²°': {\n",
    "            'ë¶„ìŸì¡°ì •': 3, 'ì¡°ì •ìœ„ì›íšŒ': 2, 'ì§€ê¸‰ëª…ë ¹': 3, 'ì†Œì†¡': 3,\n",
    "            'íŒê²°': 2, 'ì§‘í–‰ê¶Œì›': 2, 'ê²½ë§¤': 3, 'ê³µë§¤': 2,\n",
    "            'ë‚´ìš©ì¦ëª…': 2, 'ì†í•´ë°°ìƒ': 3, 'ì§€ì—°ì´ì': 2\n",
    "        },\n",
    "        'ì„ì°¨ê¶Œ_ìŠ¹ê³„': {\n",
    "            'ì„ì°¨ê¶ŒìŠ¹ê³„': 3, 'ìŠ¹ê³„': 3, 'ì‚¬ë§': 3, 'ìƒì†': 3, 'ìƒì†ì¸': 3,\n",
    "            'ì‚¬ì‹¤í˜¼': 3, 'ë°°ìš°ì': 2, 'ê°€ì •ê³µë™ìƒí™œ': 3, '2ì´Œ': 2,\n",
    "            'ê³µë™ìƒì†': 2, 'ë°˜í™˜ì²­êµ¬ê¶Œ': 2\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"âœ… ì¹´í…Œê³ ë¦¬ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"ì´ {len(get_law_category())}ê°œ ì¹´í…Œê³ ë¦¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "categorize-section",
   "metadata": {},
   "source": [
    "### 3. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "categorize-func",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ê²°ê³¼: ['ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥']\n"
     ]
    }
   ],
   "source": [
    "def categorize_content(content, top_k=None):\n",
    "    \"\"\"ë‚´ìš© ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ - ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ì ìˆ˜ ìˆœìœ¼ë¡œ ë°˜í™˜\"\"\"\n",
    "    category_keywords = get_law_category()\n",
    "    category_scores = {}\n",
    "    \n",
    "    for category, weighted_keywords in category_keywords.items():\n",
    "        score = 0\n",
    "        for keyword, weight in weighted_keywords.items():\n",
    "            count = content.count(keyword)\n",
    "            score += count * weight\n",
    "        if score > 0:\n",
    "            category_scores[category] = score\n",
    "    \n",
    "    sorted_categories = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    all_categories = [category[0] for category in sorted_categories]\n",
    "    \n",
    "    if not all_categories:\n",
    "        all_categories = [\"ê¸°íƒ€\"]\n",
    "    \n",
    "    if top_k is not None:\n",
    "        return all_categories[:top_k]\n",
    "    else:\n",
    "        return all_categories\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_text = \"ë³´ì¦ê¸ˆ ë°˜í™˜ê³¼ ìš°ì„ ë³€ì œê¶Œì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤. í™•ì •ì¼ìë¥¼ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "print(\"í…ŒìŠ¤íŠ¸ ê²°ê³¼:\", categorize_content(test_text, top_k=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "path-section",
   "metadata": {},
   "source": [
    "### 4. ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "path-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ê²½ë¡œ ì„¤ì • ì™„ë£Œ\n",
      "Raw ë””ë ‰í† ë¦¬: c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\n",
      "CSV ì €ì¥ ê²½ë¡œ: c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\processed\\csv\\law.csv\n"
     ]
    }
   ],
   "source": [
    "# í˜„ì¬ ë…¸íŠ¸ë¶ ê¸°ì¤€ ê²½ë¡œ ì„¤ì •\n",
    "BASE_DIR = Path.cwd().parents[1]  # ë…¸íŠ¸ë¶ì´ src/ í•˜ìœ„ì— ìˆë‹¤ê³  ê°€ì •\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "CSV_DIR = PROCESSED_DIR / \"csv\"\n",
    "LOG_DIR = PROCESSED_DIR / \"log\"\n",
    "\n",
    "LAW_RAW_DIR = RAW_DIR / \"law\"\n",
    "LAW_CSV_PATH = CSV_DIR / \"law.csv\"\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "CSV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LAW_RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“ ê²½ë¡œ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"Raw ë””ë ‰í† ë¦¬: {LAW_RAW_DIR}\")\n",
    "print(f\"CSV ì €ì¥ ê²½ë¡œ: {LAW_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parse-section",
   "metadata": {},
   "source": [
    "### 5. íŒŒì‹± í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parse-func",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒì‹± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "ARTICLE_PATTERN = re.compile(r\"(ì œ\\s*\\d+ì¡°(?:ì˜\\d+)?)\")\n",
    "\n",
    "def extract_article_title(text):\n",
    "    \"\"\"ì¡°ë¬¸ì—ì„œ ì œëª© ì¶”ì¶œ (ê´„í˜¸ ì•ˆì˜ ë‚´ìš©)\"\"\"\n",
    "    match = re.search(r'\\(([^)]+)\\)', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"\"\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def parse_law_docx(file_path, src_title, priority, effective_date):\n",
    "    \"\"\"ê·œì¹™ DOCX íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì ì ˆí•œ í¬ê¸°ë¡œ ì²­í‚¹\"\"\"\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # ì „ì²´ í…ìŠ¤íŠ¸ ìˆ˜ì§‘\n",
    "    full_text = \"\\n\".join([para.text.strip() for para in doc.paragraphs if para.text.strip()])\n",
    "    \n",
    "    # ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬\n",
    "    if not full_text or len(full_text) < 10:\n",
    "        print(f\"âš ï¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # RecursiveCharacterTextSplitterë¡œ ì²­í‚¹\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = text_splitter.split_text(full_text)\n",
    "    \n",
    "    rows = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        if not chunk.strip() or len(chunk.strip()) < 10:  # ë¹ˆ ì²­í¬ ì œì™¸\n",
    "            continue\n",
    "            \n",
    "        # ì¡°ë¬¸ ë²ˆí˜¸ ì¶”ì¶œ (ì²« ë²ˆì§¸ ë°œê²¬ëœ ê²ƒ)\n",
    "        article_match = ARTICLE_PATTERN.search(chunk)\n",
    "        article = article_match.group(1).replace(\" \", \"\") if article_match else \"\"\n",
    "        \n",
    "        categories = categorize_content(chunk, top_k=3)\n",
    "        \n",
    "        rows.append({\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"chunk_id\": f\"chunk_{idx:03d}\",\n",
    "            \"text\": chunk.strip(),\n",
    "            \"src_title\": src_title,\n",
    "            \"article\": article,\n",
    "            \"title\": extract_article_title(chunk) if article else \"\",\n",
    "            \"category\": \", \".join(categories),\n",
    "            \"priority\": priority,\n",
    "            \"effective_date\": effective_date,\n",
    "            \"source\": str(file_path),\n",
    "            \"parsed_at\": datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"âœ… íŒŒì‹± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-section",
   "metadata": {},
   "source": [
    "### 6. íŒŒì¼ ê²€ìƒ‰ ë° íŒŒì‹± ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "file-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ë²•ë¥  DOCX íŒŒì¼ íŒŒì‹± ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "ğŸ“‚ ë°œê²¬ëœ DOCX íŒŒì¼: 4ê°œ\n",
      "   - ë¯¼ë²•(ë²•ë¥ )(ì œ20432í˜¸)(20260101)-ê°„ëµ.docx\n",
      "   - ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œìƒì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì„ëŒ€ì°¨ ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™(ë²•ë¬´ë¶€ë ¹)(ì œ01022í˜¸)(20220207).docx\n",
      "   - ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35947í˜¸)(20260102).docx\n",
      "   - ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20260102).docx\n"
     ]
    }
   ],
   "source": [
    "# DOCX íŒŒì¼ ì°¾ê¸°\n",
    "docx_files = list(LAW_RAW_DIR.glob(\"*.docx\"))\n",
    "docx_files = [f for f in docx_files if not f.name.startswith('~$')]  # ì„ì‹œ íŒŒì¼ ì œì™¸\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ë²•ë¥  DOCX íŒŒì¼ íŒŒì‹± ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not docx_files:\n",
    "    print(f\"\\nâš ï¸  ë²•ë¥  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸ“ ë‹¤ìŒ ê²½ë¡œì— DOCX íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”:\")\n",
    "    print(f\"   {LAW_RAW_DIR}\")\n",
    "else:\n",
    "    print(f\"\\nğŸ“‚ ë°œê²¬ëœ DOCX íŒŒì¼: {len(docx_files)}ê°œ\")\n",
    "    for f in docx_files:\n",
    "        print(f\"   - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "parsing-exec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ íŒŒì‹± ì¤‘: ë¯¼ë²•(ë²•ë¥ )(ì œ20432í˜¸)(20260101)-ê°„ëµ.docx\n",
      "   âœ… 5 ì¡°ë¬¸ íŒŒì‹± ì™„ë£Œ\n",
      "\n",
      "ğŸ”„ íŒŒì‹± ì¤‘: ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œìƒì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì„ëŒ€ì°¨ ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™(ë²•ë¬´ë¶€ë ¹)(ì œ01022í˜¸)(20220207).docx\n",
      "   âœ… 4 ì¡°ë¬¸ íŒŒì‹± ì™„ë£Œ\n",
      "\n",
      "ğŸ”„ íŒŒì‹± ì¤‘: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35947í˜¸)(20260102).docx\n",
      "   âœ… 10 ì¡°ë¬¸ íŒŒì‹± ì™„ë£Œ\n",
      "\n",
      "ğŸ”„ íŒŒì‹± ì¤‘: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20260102).docx\n",
      "   âœ… 14 ì¡°ë¬¸ íŒŒì‹± ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "íŒŒì‹± ì™„ë£Œ\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì‹± ì‹¤í–‰\n",
    "all_dfs = []\n",
    "\n",
    "for docx_file in docx_files:\n",
    "    print(f\"\\nğŸ”„ íŒŒì‹± ì¤‘: {docx_file.name}\")\n",
    "    \n",
    "    filename = docx_file.stem\n",
    "    \n",
    "    # íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„\n",
    "    if \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•\" in filename and \"ì‹œí–‰ë ¹\" not in filename and \"ì‹œí–‰ê·œì¹™\" not in filename:\n",
    "        match = re.search(r'(\\d+)_(\\d{8})', filename)\n",
    "        if match:\n",
    "            law_no = match.group(1)\n",
    "            date = match.group(2)\n",
    "            src_title = f\"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ{law_no}í˜¸)({date})\"\n",
    "            effective_date = date\n",
    "        else:\n",
    "            src_title = \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )\"\n",
    "            effective_date = \"2026-01-02\"\n",
    "        priority = 1\n",
    "        \n",
    "    elif \"ë¯¼ë²•\" in filename:\n",
    "        src_title = \"ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸\"\n",
    "        priority = 4\n",
    "        effective_date = \"2026-01-02\"\n",
    "        \n",
    "    else:\n",
    "        src_title = filename\n",
    "        priority = 1\n",
    "        effective_date = \"2026-01-02\"\n",
    "    \n",
    "    df = parse_law_docx(\n",
    "        file_path=docx_file,\n",
    "        src_title=src_title,\n",
    "        priority=priority,\n",
    "        effective_date=effective_date\n",
    "    )\n",
    "    \n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "        print(f\"   âœ… {len(df)} ì¡°ë¬¸ íŒŒì‹± ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ íŒŒì‹±ëœ ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"íŒŒì‹± ì™„ë£Œ\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-section",
   "metadata": {},
   "source": [
    "### 7. ê²°ê³¼ ì €ì¥ ë° í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save-csv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… law.csv ìƒì„± ì™„ë£Œ!\n",
      "ğŸ“Š ì´ 33 ì¡°ë¬¸ ì €ì¥\n",
      "ğŸ“ ì €ì¥ ê²½ë¡œ: c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\processed\\csv\\law.csv\n"
     ]
    }
   ],
   "source": [
    "if all_dfs:\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    final_df.to_csv(LAW_CSV_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "    \n",
    "    print(f\"âœ… law.csv ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š ì´ {len(final_df)} ì¡°ë¬¸ ì €ì¥\")\n",
    "    print(f\"ğŸ“ ì €ì¥ ê²½ë¡œ: {LAW_CSV_PATH}\")\n",
    "else:\n",
    "    print(\"âŒ íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "law-stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ ë²•ë¥ ë³„ í†µê³„:\n",
      "   - ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸: 5ê°œ\n",
      "   - ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œìƒì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì„ëŒ€ì°¨ ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™(ë²•ë¬´ë¶€ë ¹)(ì œ01022í˜¸)(20220207): 4ê°œ\n",
      "   - ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35947í˜¸)(20260102): 10ê°œ\n",
      "   - ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ ): 14ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ë²•ë¥ ë³„ í†µê³„\n",
    "if all_dfs:\n",
    "    print(\"\\nğŸ“ˆ ë²•ë¥ ë³„ í†µê³„:\")\n",
    "    stats = final_df.groupby('src_title').size()\n",
    "    for law, count in stats.items():\n",
    "        print(f\"   - {law}: {count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "category-stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í†µê³„:\n",
      "   - ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥: 19ê°œ\n",
      "   - ë¶„ìŸí•´ê²°: 14ê°œ\n",
      "   - ì„ëŒ€ë£Œ_ì¦ê°: 14ê°œ\n",
      "   - ê³„ì•½í•´ì§€: 10ê°œ\n",
      "   - í–‰ì •ì ˆì°¨: 9ê°œ\n",
      "   - ê³„ì•½ê°±ì‹ : 7ê°œ\n",
      "   - ì„ì°¨ê¶Œ_ìŠ¹ê³„: 7ê°œ\n",
      "   - ê¶Œë¦¬_ë¦¬ìŠ¤í¬: 6ê°œ\n",
      "   - ìˆ˜ì„ _ì›ìƒíšŒë³µ: 2ê°œ\n",
      "   - ê¸°íƒ€: 1ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì¹´í…Œê³ ë¦¬ë³„ í†µê³„\n",
    "if all_dfs:\n",
    "    print(\"\\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í†µê³„:\")\n",
    "    all_categories = []\n",
    "    for cats in final_df['category']:\n",
    "        all_categories.extend([c.strip() for c in cats.split(',')])\n",
    "    \n",
    "    category_counts = Counter(all_categories)\n",
    "    for cat, count in category_counts.most_common():\n",
    "        print(f\"   - {cat}: {count}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview-section",
   "metadata": {},
   "source": [
    "### 8. ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "preview-head",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ CSV ë¯¸ë¦¬ë³´ê¸° (ì²« 5ê°œ):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>src_title</th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>effective_date</th>\n",
       "      <th>source</th>\n",
       "      <th>parsed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2cbc1359-4c34-44a3-b98c-a94c327accc7</td>\n",
       "      <td>chunk_000</td>\n",
       "      <td>ë¯¼ë²•\\n[ì‹œí–‰ 2026. 1. 1.] [ë²•ë¥  ì œ20432í˜¸, 2024. 9. 20....</td>\n",
       "      <td>ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸</td>\n",
       "      <td>ì œ390ì¡°</td>\n",
       "      <td>ë²•ë¬´ì‹¬ì˜ê´€ì‹¤</td>\n",
       "      <td>ìˆ˜ì„ _ì›ìƒíšŒë³µ, ë¶„ìŸí•´ê²°, ê³„ì•½í•´ì§€</td>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-02</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...</td>\n",
       "      <td>2026-01-19T17:28:38.102011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2eca7d8f-fcdb-418e-9425-aa08c39e8d1c</td>\n",
       "      <td>chunk_001</td>\n",
       "      <td>â‘¡ì„ì°¨ì¸ì´ ìœ ìµë¹„ë¥¼ ì§€ì¶œí•œ ê²½ìš°ì—ëŠ” ì„ëŒ€ì¸ì€ ì„ëŒ€ì°¨ì¢…ë£Œì‹œì— ê·¸ ê°€ì•¡ì˜ ì¦ê°€ê°€ í˜„ì¡´í•œ...</td>\n",
       "      <td>ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸</td>\n",
       "      <td>ì œ627ì¡°</td>\n",
       "      <td>ì¼ë¶€ë©¸ì‹¤ ë“±ê³¼ ê°ì•¡ì²­êµ¬, í•´ì§€ê¶Œ</td>\n",
       "      <td>ì„ëŒ€ë£Œ_ì¦ê°, ê³„ì•½í•´ì§€, ìˆ˜ì„ _ì›ìƒíšŒë³µ</td>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-02</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...</td>\n",
       "      <td>2026-01-19T17:28:38.102011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f35a3434-916c-478e-b8bb-0120a9ebe446</td>\n",
       "      <td>chunk_002</td>\n",
       "      <td>ì œ637ì¡°(ì„ì°¨ì¸ì˜ íŒŒì‚°ê³¼ í•´ì§€í†µê³ ) â‘ ì„ì°¨ì¸ì´ íŒŒì‚°ì„ ê³ ë¥¼ ë°›ì€ ê²½ìš°ì—ëŠ” ì„ëŒ€ì°¨ê¸°ê°„...</td>\n",
       "      <td>ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸</td>\n",
       "      <td>ì œ637ì¡°</td>\n",
       "      <td>ì„ì°¨ì¸ì˜ íŒŒì‚°ê³¼ í•´ì§€í†µê³ </td>\n",
       "      <td>ê³„ì•½í•´ì§€, ì„ëŒ€ë£Œ_ì¦ê°, ê³„ì•½ê°±ì‹ </td>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-02</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...</td>\n",
       "      <td>2026-01-19T17:28:38.103012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44c837fe-8b61-453d-b991-4772e9e86703</td>\n",
       "      <td>chunk_003</td>\n",
       "      <td>ì œ646ì¡°(ì„ì°¨ì¸ì˜ ë¶€ì†ë¬¼ë§¤ìˆ˜ì²­êµ¬ê¶Œ) â‘ ê±´ë¬¼ ê¸°íƒ€ ê³µì‘ë¬¼ì˜ ì„ì°¨ì¸ì´ ê·¸ ì‚¬ìš©ì˜ í¸ìµ...</td>\n",
       "      <td>ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸</td>\n",
       "      <td>ì œ646ì¡°</td>\n",
       "      <td>ì„ì°¨ì¸ì˜ ë¶€ì†ë¬¼ë§¤ìˆ˜ì²­êµ¬ê¶Œ</td>\n",
       "      <td>ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ì„ì°¨ê¶Œ_ìŠ¹ê³„, ì„ëŒ€ë£Œ_ì¦ê°</td>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-02</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...</td>\n",
       "      <td>2026-01-19T17:28:38.103012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8535924d-6c53-4014-9863-ee68948e9237</td>\n",
       "      <td>chunk_004</td>\n",
       "      <td>ì œ2ì¡°(ìƒì†ê¶Œ ìƒì‹¤ ì„ ê³ ì— ê´€í•œ ì ìš©ë¡€) ì œ1004ì¡°ì˜2ì˜ ê°œì •ê·œì •ì€ 2024ë…„ 4...</td>\n",
       "      <td>ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸</td>\n",
       "      <td>ì œ2ì¡°</td>\n",
       "      <td>ìƒì†ê¶Œ ìƒì‹¤ ì„ ê³ ì— ê´€í•œ ì ìš©ë¡€</td>\n",
       "      <td>ì„ì°¨ê¶Œ_ìŠ¹ê³„, ë¶„ìŸí•´ê²°</td>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-02</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...</td>\n",
       "      <td>2026-01-19T17:28:38.103012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   chunk_id  \\\n",
       "0  2cbc1359-4c34-44a3-b98c-a94c327accc7  chunk_000   \n",
       "1  2eca7d8f-fcdb-418e-9425-aa08c39e8d1c  chunk_001   \n",
       "2  f35a3434-916c-478e-b8bb-0120a9ebe446  chunk_002   \n",
       "3  44c837fe-8b61-453d-b991-4772e9e86703  chunk_003   \n",
       "4  8535924d-6c53-4014-9863-ee68948e9237  chunk_004   \n",
       "\n",
       "                                                text      src_title article  \\\n",
       "0  ë¯¼ë²•\\n[ì‹œí–‰ 2026. 1. 1.] [ë²•ë¥  ì œ20432í˜¸, 2024. 9. 20....  ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸   ì œ390ì¡°   \n",
       "1  â‘¡ì„ì°¨ì¸ì´ ìœ ìµë¹„ë¥¼ ì§€ì¶œí•œ ê²½ìš°ì—ëŠ” ì„ëŒ€ì¸ì€ ì„ëŒ€ì°¨ì¢…ë£Œì‹œì— ê·¸ ê°€ì•¡ì˜ ì¦ê°€ê°€ í˜„ì¡´í•œ...  ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸   ì œ627ì¡°   \n",
       "2  ì œ637ì¡°(ì„ì°¨ì¸ì˜ íŒŒì‚°ê³¼ í•´ì§€í†µê³ ) â‘ ì„ì°¨ì¸ì´ íŒŒì‚°ì„ ê³ ë¥¼ ë°›ì€ ê²½ìš°ì—ëŠ” ì„ëŒ€ì°¨ê¸°ê°„...  ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸   ì œ637ì¡°   \n",
       "3  ì œ646ì¡°(ì„ì°¨ì¸ì˜ ë¶€ì†ë¬¼ë§¤ìˆ˜ì²­êµ¬ê¶Œ) â‘ ê±´ë¬¼ ê¸°íƒ€ ê³µì‘ë¬¼ì˜ ì„ì°¨ì¸ì´ ê·¸ ì‚¬ìš©ì˜ í¸ìµ...  ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸   ì œ646ì¡°   \n",
       "4  ì œ2ì¡°(ìƒì†ê¶Œ ìƒì‹¤ ì„ ê³ ì— ê´€í•œ ì ìš©ë¡€) ì œ1004ì¡°ì˜2ì˜ ê°œì •ê·œì •ì€ 2024ë…„ 4...  ë¯¼ë²•(ë²•ë¥ ) - ì„ëŒ€ì°¨í¸     ì œ2ì¡°   \n",
       "\n",
       "               title                category  priority effective_date  \\\n",
       "0             ë²•ë¬´ì‹¬ì˜ê´€ì‹¤     ìˆ˜ì„ _ì›ìƒíšŒë³µ, ë¶„ìŸí•´ê²°, ê³„ì•½í•´ì§€         4     2026-01-02   \n",
       "1  ì¼ë¶€ë©¸ì‹¤ ë“±ê³¼ ê°ì•¡ì²­êµ¬, í•´ì§€ê¶Œ   ì„ëŒ€ë£Œ_ì¦ê°, ê³„ì•½í•´ì§€, ìˆ˜ì„ _ì›ìƒíšŒë³µ         4     2026-01-02   \n",
       "2      ì„ì°¨ì¸ì˜ íŒŒì‚°ê³¼ í•´ì§€í†µê³       ê³„ì•½í•´ì§€, ì„ëŒ€ë£Œ_ì¦ê°, ê³„ì•½ê°±ì‹          4     2026-01-02   \n",
       "3      ì„ì°¨ì¸ì˜ ë¶€ì†ë¬¼ë§¤ìˆ˜ì²­êµ¬ê¶Œ  ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ì„ì°¨ê¶Œ_ìŠ¹ê³„, ì„ëŒ€ë£Œ_ì¦ê°         4     2026-01-02   \n",
       "4  ìƒì†ê¶Œ ìƒì‹¤ ì„ ê³ ì— ê´€í•œ ì ìš©ë¡€            ì„ì°¨ê¶Œ_ìŠ¹ê³„, ë¶„ìŸí•´ê²°         4     2026-01-02   \n",
       "\n",
       "                                              source  \\\n",
       "0  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...   \n",
       "1  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...   \n",
       "2  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...   \n",
       "3  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...   \n",
       "4  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\law\\ë¯¼ë²•(ë²•ë¥ )(ì œ2043...   \n",
       "\n",
       "                    parsed_at  \n",
       "0  2026-01-19T17:28:38.102011  \n",
       "1  2026-01-19T17:28:38.102011  \n",
       "2  2026-01-19T17:28:38.103012  \n",
       "3  2026-01-19T17:28:38.103012  \n",
       "4  2026-01-19T17:28:38.103012  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì²« 5ê°œ í–‰ í™•ì¸\n",
    "if all_dfs:\n",
    "    print(\"\\nğŸ“‹ CSV ë¯¸ë¦¬ë³´ê¸° (ì²« 5ê°œ):\")\n",
    "    display(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "preview-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” íŠ¹ì • ì¡°ë¬¸ ìƒ˜í”Œ:\n",
      "ì¡°ë¬¸: ì œ1ì¡°\n",
      "ì œëª©: ë²•ë¬´ì‹¬ì˜ê´€ì‹¤\n",
      "ì¹´í…Œê³ ë¦¬: ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, í–‰ì •ì ˆì°¨, ì„ëŒ€ë£Œ_ì¦ê°\n",
      "ìš°ì„ ìˆœìœ„: 1\n",
      "ë³¸ë¬¸(ì• 200ì): ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œìƒì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì„ëŒ€ì°¨ ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™\n",
      "[ì‹œí–‰ 2022. 2. 7.] [ë²•ë¬´ë¶€ë ¹ ì œ1022í˜¸, 2022. 2. 7., íƒ€ë²•ê°œì •]\n",
      "ë²•ë¬´ë¶€(ë²•ë¬´ì‹¬ì˜ê´€ì‹¤) 02-2110-3164\n",
      "ì œ1ì¡°(ëª©ì ) ì´ ê·œì¹™ì€ ã€Œì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ã€ ì œ3ì¡°ì˜6ì— ë”°ë¥¸ ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œìƒì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì„ëŒ€ì°¨ ì •ë³´ì œê³µì— ê´€í•œ ì‚¬í•­ì„ ê·œì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤....\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ì • ì¡°ë¬¸ í™•ì¸\n",
    "if all_dfs:\n",
    "    print(\"\\nğŸ” íŠ¹ì • ì¡°ë¬¸ ìƒ˜í”Œ:\")\n",
    "    sample = final_df[final_df['article'].str.contains('ì œ1ì¡°', na=False)].iloc[0]\n",
    "    print(f\"ì¡°ë¬¸: {sample['article']}\")\n",
    "    print(f\"ì œëª©: {sample['title']}\")\n",
    "    print(f\"ì¹´í…Œê³ ë¦¬: {sample['category']}\")\n",
    "    print(f\"ìš°ì„ ìˆœìœ„: {sample['priority']}\")\n",
    "    print(f\"ë³¸ë¬¸(ì• 200ì): {sample['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "info-section",
   "metadata": {},
   "source": [
    "### 9. ì»¬ëŸ¼ ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df-info",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ ë°ì´í„°í”„ë ˆì„ ì •ë³´:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              33 non-null     object\n",
      " 1   chunk_id        33 non-null     object\n",
      " 2   text            33 non-null     object\n",
      " 3   src_title       33 non-null     object\n",
      " 4   article         33 non-null     object\n",
      " 5   title           33 non-null     object\n",
      " 6   category        33 non-null     object\n",
      " 7   priority        33 non-null     int64 \n",
      " 8   effective_date  33 non-null     object\n",
      " 9   source          33 non-null     object\n",
      " 10  parsed_at       33 non-null     object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 3.0+ KB\n",
      "None\n",
      "\n",
      "ì»¬ëŸ¼ ëª©ë¡:\n",
      "['id', 'chunk_id', 'text', 'src_title', 'article', 'title', 'category', 'priority', 'effective_date', 'source', 'parsed_at']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mí˜„ì¬ ì…€ ë˜ëŠ” ì´ì „ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆ Kernelì´ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤. \n",
      "\u001b[1;31mì…€ì˜ ì½”ë“œë¥¼ ê²€í† í•˜ì—¬ ê°€ëŠ¥í•œ ì˜¤ë¥˜ ì›ì¸ì„ ì‹ë³„í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì„ ë³´ë ¤ë©´ <a href='https://aka.ms/vscodeJupyterKernelCrash'>ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì€ Jupyter <a href='command:jupyter.viewOutput'>ë¡œê·¸</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
     ]
    }
   ],
   "source": [
    "if all_dfs:\n",
    "    print(\"\\nğŸ“‹ ë°ì´í„°í”„ë ˆì„ ì •ë³´:\")\n",
    "    print(final_df.info())\n",
    "    print(\"\\nì»¬ëŸ¼ ëª©ë¡:\")\n",
    "    print(final_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f1320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
