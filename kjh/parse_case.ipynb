{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# íŒë¡€/ì‚¬ë¡€ íŒŒì‹± í…ŒìŠ¤íŠ¸ ë…¸íŠ¸ë¶\n",
    "## ì£¼íƒì„ëŒ€ì°¨ RAG - ëŒ€ë²•ì›íŒë¡€, í•˜ê¸‰ì‹¬íŒë¡€, ìƒë‹´ì‚¬ë¡€ íŒŒì‹±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-section",
   "metadata": {},
   "source": [
    "### 1. í•„ìš” íŒ¨í‚¤ì§€ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import PyPDF2\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "category-section",
   "metadata": {},
   "source": [
    "### 2. ì¹´í…Œê³ ë¦¬ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "category-def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¹´í…Œê³ ë¦¬ ì •ì˜ ì™„ë£Œ\n",
      "ì´ 9ê°œ ì¹´í…Œê³ ë¦¬\n"
     ]
    }
   ],
   "source": [
    "def get_law_category():\n",
    "    \"\"\"ì£¼íƒì„ëŒ€ì°¨ RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì¹´í…Œê³ ë¦¬-í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì‚¬ì „\"\"\"\n",
    "    return {\n",
    "        'ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥': {\n",
    "            'ë³´ì¦ê¸ˆ': 3, 'ëŒ€í•­ë ¥': 3, 'ìš°ì„ ë³€ì œê¶Œ': 3, 'ìµœìš°ì„ ë³€ì œ': 3,\n",
    "            'ë³´ì¦ê¸ˆë°˜í™˜': 3, 'ì „ì„¸ê¸ˆ': 2, 'ì†Œì•¡ì„ì°¨ì¸': 2, 'í™•ì •ì¼ì': 2,\n",
    "            'ì „ì…ì‹ ê³ ': 2, 'ì ìœ ': 2, 'ì„ì°¨ê¶Œë“±ê¸°': 3, 'ë°°ë‹¹': 2,\n",
    "            'ë°˜í™˜ë³´ì¦': 2, 'HUG': 1, 'ë³´ì¦ë³´í—˜': 2\n",
    "        },\n",
    "        'ê³„ì•½ê°±ì‹ ': {\n",
    "            'ê³„ì•½ê°±ì‹ ': 3, 'ê°±ì‹ ìš”êµ¬': 3, 'ê°±ì‹ ê±°ì ˆ': 3, 'ë¬µì‹œì ê°±ì‹ ': 3,\n",
    "            'ê³„ì•½ì—°ì¥': 2, 'ì‹¤ê±°ì£¼': 3, 'ì¡´ì†ê¸°ê°„': 2, '2ë…„': 1,\n",
    "            'ì¬ê³„ì•½': 2, 'ê°±ì‹ ì²­êµ¬': 2, 'ê±°ì ˆì‚¬ìœ ': 2, 'ë³µë¹„': 1\n",
    "        },\n",
    "        'ê³„ì•½í•´ì§€': {\n",
    "            'ê³„ì•½í•´ì§€': 3, 'í•´ì§€í†µê³ ': 3, 'ì¤‘ë„í•´ì§€': 3, 'ê¸°ê°„ë§Œë£Œ': 2,\n",
    "            'ê³„ì•½ì¢…ë£Œ': 2, 'í‡´ê±°': 2, 'ì´ì‚¬': 1, 'ëª…ë„': 2,\n",
    "            'í•©ì˜í•´ì§€': 2, 'í†µì§€': 1, '3ê°œì›”': 2, 'ì¦‰ì‹œí•´ì§€': 3\n",
    "        },\n",
    "        'ì„ëŒ€ë£Œ_ì¦ê°': {\n",
    "            'ì°¨ì„': 3, 'ì›”ì„¸': 2, 'ì¦ì•¡': 3, 'ê°ì•¡': 2, 'ì¸ìƒ': 2,\n",
    "            '5í¼ì„¼íŠ¸': 3, '5%': 3, '20ë¶„ì˜ 1': 2, 'ìƒí•œ': 2,\n",
    "            'ì „í™˜ìœ¨': 2, 'ì›”ì°¨ì„': 2, 'ê²½ì œì‚¬ì •': 1, 'ë¶€ë‹´': 1\n",
    "        },\n",
    "        'ìˆ˜ì„ _ì›ìƒíšŒë³µ': {\n",
    "            'ìˆ˜ì„ ': 3, 'ìˆ˜ë¦¬': 3, 'ì›ìƒíšŒë³µ': 3, 'íŒŒì†': 2, 'í›¼ì†': 2,\n",
    "            'ëˆ„ìˆ˜': 2, 'ê³°íŒ¡ì´': 2, 'ë³´ì¼ëŸ¬': 2, 'í•„ìš”ë¹„': 3, 'ìœ ìµë¹„': 3,\n",
    "            'ë¹„ìš©ìƒí™˜': 2, 'ë³´ì¡´í–‰ìœ„': 2, 'ê´€ë¦¬ë¹„': 1\n",
    "        },\n",
    "        'ê¶Œë¦¬_ë¦¬ìŠ¤í¬': {\n",
    "            'ì „ì„¸ì‚¬ê¸°': 3, 'ê¹¡í†µì „ì„¸': 3, 'ì‹ íƒ': 3, 'ê·¼ì €ë‹¹': 3, 'ì €ë‹¹ê¶Œ': 3,\n",
    "            'ì„ ìˆœìœ„': 3, 'ê°€ì••ë¥˜': 3, 'ì••ë¥˜': 3, 'êµ­ì„¸': 2, 'ì§€ë°©ì„¸': 2,\n",
    "            'ì²´ë‚©': 3, 'ë‚©ì„¸ì¦ëª…': 2, 'ìœ„ë°˜ê±´ì¶•ë¬¼': 2, 'ë¶ˆë²•ê±´ì¶•ë¬¼': 2,\n",
    "            'íŠ¹ì•½': 2, 'ë…ì†Œì¡°í•­': 2, 'ê°•í–‰ê·œì •': 3, 'íš¨ë ¥ì´ ì—†ë‹¤': 3,\n",
    "            'ë¬´íš¨': 3, 'ë¶ˆë¦¬í•œ ì•½ì •': 3, 'í¸ë©´ì  ê°•í–‰ê·œì •': 2\n",
    "        },\n",
    "        'í–‰ì •ì ˆì°¨': {\n",
    "            'í™•ì •ì¼ìë¶€ì—¬': 3, 'ë™ì£¼ë¯¼ì„¼í„°': 2, 'ë“±ê¸°ì†Œ': 2, 'ì¸í„°ë„·ë“±ê¸°ì†Œ': 3,\n",
    "            'ìˆ˜ìˆ˜ë£Œ': 1, 'ì—´ëŒ': 2, 'ì œê³µìš”ì²­': 2, 'ì´í•´ê´€ê³„ì¸': 2,\n",
    "            'ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ': 2, 'ì „ìê³„ì•½': 2, 'ì‹ ë¶„ì¦': 1\n",
    "        },\n",
    "        'ë¶„ìŸí•´ê²°': {\n",
    "            'ë¶„ìŸì¡°ì •': 3, 'ì¡°ì •ìœ„ì›íšŒ': 2, 'ì§€ê¸‰ëª…ë ¹': 3, 'ì†Œì†¡': 3,\n",
    "            'íŒê²°': 2, 'ì§‘í–‰ê¶Œì›': 2, 'ê²½ë§¤': 3, 'ê³µë§¤': 2,\n",
    "            'ë‚´ìš©ì¦ëª…': 2, 'ì†í•´ë°°ìƒ': 3, 'ì§€ì—°ì´ì': 2\n",
    "        },\n",
    "        'ì„ì°¨ê¶Œ_ìŠ¹ê³„': {\n",
    "            'ì„ì°¨ê¶ŒìŠ¹ê³„': 3, 'ìŠ¹ê³„': 3, 'ì‚¬ë§': 3, 'ìƒì†': 3, 'ìƒì†ì¸': 3,\n",
    "            'ì‚¬ì‹¤í˜¼': 3, 'ë°°ìš°ì': 2, 'ê°€ì •ê³µë™ìƒí™œ': 3, '2ì´Œ': 2,\n",
    "            'ê³µë™ìƒì†': 2, 'ë°˜í™˜ì²­êµ¬ê¶Œ': 2\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"âœ… ì¹´í…Œê³ ë¦¬ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"ì´ {len(get_law_category())}ê°œ ì¹´í…Œê³ ë¦¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "categorize-section",
   "metadata": {},
   "source": [
    "### 3. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "categorize-func",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def categorize_content(content, top_k=None):\n",
    "    \"\"\"ë‚´ìš© ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\"\"\"\n",
    "    category_keywords = get_law_category()\n",
    "    category_scores = {}\n",
    "    \n",
    "    for category, weighted_keywords in category_keywords.items():\n",
    "        score = 0\n",
    "        for keyword, weight in weighted_keywords.items():\n",
    "            count = content.count(keyword)\n",
    "            score += count * weight\n",
    "        if score > 0:\n",
    "            category_scores[category] = score\n",
    "    \n",
    "    sorted_categories = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    all_categories = [category[0] for category in sorted_categories]\n",
    "    \n",
    "    if not all_categories:\n",
    "        all_categories = [\"ê¸°íƒ€\"]\n",
    "    \n",
    "    if top_k is not None:\n",
    "        return all_categories[:top_k]\n",
    "    else:\n",
    "        return all_categories\n",
    "\n",
    "print(\"âœ… ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "path-section",
   "metadata": {},
   "source": [
    "### 4. ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "path-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ê²½ë¡œ ì„¤ì • ì™„ë£Œ\n",
      "Raw ë””ë ‰í† ë¦¬: c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\n",
      "CSV ì €ì¥ ê²½ë¡œ: c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\processed\\csv\\case.csv\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.cwd().parents[1]\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "CSV_DIR = PROCESSED_DIR / \"csv\"\n",
    "LOG_DIR = PROCESSED_DIR / \"log\"\n",
    "\n",
    "CASE_RAW_DIR = RAW_DIR / \"case\"\n",
    "CASE_CSV_PATH = CSV_DIR / \"case.csv\"\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "CSV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CASE_RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“ ê²½ë¡œ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"Raw ë””ë ‰í† ë¦¬: {CASE_RAW_DIR}\")\n",
    "print(f\"CSV ì €ì¥ ê²½ë¡œ: {CASE_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pdf-section",
   "metadata": {},
   "source": [
    "### 5. PDF íŒŒì‹± í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pdf-extract",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ PDF ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "case-info-extract",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ê±´ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def extract_case_info(text, filename):\n",
    "    \"\"\"PDF í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ê±´ë²ˆí˜¸, ì œëª©, ë‚ ì§œ ë“± ì¶”ì¶œ\"\"\"\n",
    "    case_no = \"ë¯¸ìƒ\"\n",
    "    ruling_date = \"ë¯¸ìƒ\"\n",
    "    src_title = filename\n",
    "    \n",
    "    # ì‚¬ê±´ë²ˆí˜¸ íŒ¨í„´\n",
    "    case_pattern = re.search(r'(\\d{4}[ë‹¤ê°€ë‚˜ë§ˆì]í•©?\\d+)', text[:500])\n",
    "    if case_pattern:\n",
    "        case_no = case_pattern.group(1)\n",
    "    \n",
    "    # ë‚ ì§œ íŒ¨í„´\n",
    "    date_pattern = re.search(r'(\\d{4})[\\.\\-ë…„]\\s*(\\d{1,2})[\\.\\-ì›”]\\s*(\\d{1,2})', text[:500])\n",
    "    if date_pattern:\n",
    "        year, month, day = date_pattern.groups()\n",
    "        ruling_date = f\"{year}{month.zfill(2)}{day.zfill(2)}\"\n",
    "    \n",
    "    return case_no, ruling_date, src_title\n",
    "\n",
    "def extract_related_articles(text):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ì—ì„œ ì°¸ì¡° ë²•ë ¹ ì¡°í•­ ì¶”ì¶œ\"\"\"\n",
    "    articles = []\n",
    "    \n",
    "    law_pattern = re.findall(r'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•\\s*ì œ\\s*(\\d+)ì¡°', text)\n",
    "    for art in law_pattern:\n",
    "        articles.append(f\"ì£¼ì„ë²• ì œ{art}ì¡°\")\n",
    "    \n",
    "    civil_pattern = re.findall(r'ë¯¼ë²•\\s*ì œ\\s*(\\d+)ì¡°', text)\n",
    "    for art in civil_pattern:\n",
    "        articles.append(f\"ë¯¼ë²• ì œ{art}ì¡°\")\n",
    "    \n",
    "    unique_articles = list(set(articles))\n",
    "    return \", \".join(unique_articles) if unique_articles else \"ë¯¸ìƒ\"\n",
    "\n",
    "print(\"âœ… ì‚¬ê±´ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chunk-func",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í…ìŠ¤íŠ¸ ì²­í‚¹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_text(text, chunk_size=1500, overlap=200):\n",
    "    \"\"\"RecursiveCharacterTextSplitterë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì²­í‚¹\"\"\"\n",
    "    \n",
    "    # ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬\n",
    "    if not text or len(text.strip()) < 10:\n",
    "        return []\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    # ë¹ˆ ì²­í¬ í•„í„°ë§\n",
    "    chunks = [chunk.strip() for chunk in chunks if chunk.strip() and len(chunk.strip()) >= 10]\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "print(\"âœ… í…ìŠ¤íŠ¸ ì²­í‚¹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parse-case-func",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒë¡€ íŒŒì‹± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def parse_case_pdf(file_path, priority=7, chunk_size=1000):\n",
    "    \"\"\"íŒë¡€/ì‚¬ë¡€ PDF íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„ë¦¬\"\"\"\n",
    "    print(f\"   ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...\")\n",
    "    full_text = extract_text_from_pdf(file_path)\n",
    "    \n",
    "    if not full_text:\n",
    "        print(f\"   âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    filename = file_path.stem\n",
    "    case_no, ruling_date, src_title = extract_case_info(full_text, filename)\n",
    "    related_article = extract_related_articles(full_text)\n",
    "    \n",
    "    # ìš°ì„ ìˆœìœ„ ìë™ íŒë‹¨\n",
    "    if \"ëŒ€ë²•ì›\" in full_text[:500] or \"ëŒ€ë²•ì›\" in filename:\n",
    "        priority = 5\n",
    "        src_title = f\"ëŒ€ë²•ì› íŒë¡€ - {case_no}\"\n",
    "    elif \"ì§€ë°©ë²•ì›\" in full_text[:500] or \"ì§€ë²•\" in filename:\n",
    "        priority = 6\n",
    "        src_title = f\"í•˜ê¸‰ì‹¬ íŒë¡€ - {case_no}\"\n",
    "    elif \"ìƒë‹´\" in filename or \"ì‚¬ë¡€\" in filename:\n",
    "        priority = 7\n",
    "        src_title = f\"ìƒë‹´ì‚¬ë¡€ - {filename}\"\n",
    "    \n",
    "    chunks = chunk_text(full_text, chunk_size=chunk_size)\n",
    "    \n",
    "    rows = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        categories = categorize_content(chunk, top_k=3)\n",
    "        \n",
    "        rows.append({\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"chunk_id\": f\"chunk_{idx:03d}\",\n",
    "            \"text\": chunk,\n",
    "            \"src_title\": src_title,\n",
    "            \"case_no\": case_no,\n",
    "            \"ruling_date\": ruling_date,\n",
    "            \"related_article\": related_article,\n",
    "            \"category\": \", \".join(categories),\n",
    "            \"priority\": priority,\n",
    "            \"source\": str(file_path),\n",
    "            \"parsed_at\": datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    print(f\"   âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"âœ… íŒë¡€ íŒŒì‹± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-section",
   "metadata": {},
   "source": [
    "### 6. íŒŒì¼ ê²€ìƒ‰ ë° íŒŒì‹± ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "file-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "íŒë¡€/ì‚¬ë¡€ PDF íŒŒì¼ íŒŒì‹± ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "ğŸ“‚ ë°œê²¬ëœ PDF íŒŒì¼: 2ê°œ\n",
      "   - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘.pdf\n",
      "   - ì „ì„¸í”¼í•´ë²•ë¥ ìƒë‹´ì‚¬ë¡€ì§‘_250102.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_files = list(CASE_RAW_DIR.glob(\"*.pdf\"))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"íŒë¡€/ì‚¬ë¡€ PDF íŒŒì¼ íŒŒì‹± ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not pdf_files:\n",
    "    print(f\"\\nâš ï¸  íŒë¡€/ì‚¬ë¡€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸ“ ë‹¤ìŒ ê²½ë¡œì— PDF íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”:\")\n",
    "    print(f\"   {CASE_RAW_DIR}\")\n",
    "else:\n",
    "    print(f\"\\nğŸ“‚ ë°œê²¬ëœ PDF íŒŒì¼: {len(pdf_files)}ê°œ\")\n",
    "    for f in pdf_files:\n",
    "        print(f\"   - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "parsing-exec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ íŒŒì‹± ì¤‘: 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘.pdf\n",
      "   ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...\n",
      "   âœ… 50ê°œ ì²­í¬ ìƒì„±\n",
      "\n",
      "ğŸ”„ íŒŒì‹± ì¤‘: ì „ì„¸í”¼í•´ë²•ë¥ ìƒë‹´ì‚¬ë¡€ì§‘_250102.pdf\n",
      "   ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...\n",
      "   âœ… 110ê°œ ì²­í¬ ìƒì„±\n",
      "\n",
      "============================================================\n",
      "íŒŒì‹± ì™„ë£Œ\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì‹± ì‹¤í–‰\n",
    "all_dfs = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    print(f\"\\nğŸ”„ íŒŒì‹± ì¤‘: {pdf_file.name}\")\n",
    "    \n",
    "    df = parse_case_pdf(\n",
    "        file_path=pdf_file,\n",
    "        priority=7,\n",
    "        chunk_size=1000\n",
    "    )\n",
    "    \n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "    else:\n",
    "        print(f\"   âš ï¸ íŒŒì‹± ì‹¤íŒ¨\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"íŒŒì‹± ì™„ë£Œ\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-section",
   "metadata": {},
   "source": [
    "### 7. ê²°ê³¼ ì €ì¥ ë° í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "save-csv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… case.csv ìƒì„± ì™„ë£Œ!\n",
      "ğŸ“Š ì´ 160 ì²­í¬ ì €ì¥\n",
      "ğŸ“ ì €ì¥ ê²½ë¡œ: c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\processed\\csv\\case.csv\n"
     ]
    }
   ],
   "source": [
    "if all_dfs:\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    final_df.to_csv(CASE_CSV_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "    \n",
    "    print(f\"âœ… case.csv ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š ì´ {len(final_df)} ì²­í¬ ì €ì¥\")\n",
    "    print(f\"ğŸ“ ì €ì¥ ê²½ë¡œ: {CASE_CSV_PATH}\")\n",
    "else:\n",
    "    print(\"âŒ íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "file-stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ íŒŒì¼ë³„ í†µê³„:\n",
      "   - ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘: 50ê°œ ì²­í¬\n",
      "   - ìƒë‹´ì‚¬ë¡€ - ì „ì„¸í”¼í•´ë²•ë¥ ìƒë‹´ì‚¬ë¡€ì§‘_250102: 110ê°œ ì²­í¬\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ë³„ í†µê³„\n",
    "if all_dfs:\n",
    "    print(\"\\nğŸ“ˆ íŒŒì¼ë³„ í†µê³„:\")\n",
    "    stats = final_df.groupby('src_title').size()\n",
    "    for title, count in stats.items():\n",
    "        print(f\"   - {title}: {count}ê°œ ì²­í¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "priority-stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ìš°ì„ ìˆœìœ„ë³„ í†µê³„:\n",
      "   - ìƒë‹´ì‚¬ë¡€: 160ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ìš°ì„ ìˆœìœ„ë³„ í†µê³„\n",
    "if all_dfs:\n",
    "    print(\"\\nğŸ“Š ìš°ì„ ìˆœìœ„ë³„ í†µê³„:\")\n",
    "    priority_stats = final_df.groupby('priority').size()\n",
    "    priority_names = {5: \"ëŒ€ë²•ì›íŒë¡€\", 6: \"í•˜ê¸‰ì‹¬íŒë¡€\", 7: \"ìƒë‹´ì‚¬ë¡€\"}\n",
    "    for priority, count in priority_stats.items():\n",
    "        print(f\"   - {priority_names.get(priority, f'Priority {priority}')}: {count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "category-stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í†µê³„:\n",
      "   - ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥: 145ê°œ\n",
      "   - ê¶Œë¦¬_ë¦¬ìŠ¤í¬: 130ê°œ\n",
      "   - ë¶„ìŸí•´ê²°: 104ê°œ\n",
      "   - ì„ëŒ€ë£Œ_ì¦ê°: 26ê°œ\n",
      "   - ì„ì°¨ê¶Œ_ìŠ¹ê³„: 19ê°œ\n",
      "   - ê³„ì•½í•´ì§€: 17ê°œ\n",
      "   - ê³„ì•½ê°±ì‹ : 6ê°œ\n",
      "   - ìˆ˜ì„ _ì›ìƒíšŒë³µ: 3ê°œ\n",
      "   - í–‰ì •ì ˆì°¨: 2ê°œ\n",
      "   - ê¸°íƒ€: 2ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì¹´í…Œê³ ë¦¬ë³„ í†µê³„\n",
    "if all_dfs:\n",
    "    print(\"\\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í†µê³„:\")\n",
    "    all_categories = []\n",
    "    for cats in final_df['category']:\n",
    "        all_categories.extend([c.strip() for c in cats.split(',')])\n",
    "    \n",
    "    category_counts = Counter(all_categories)\n",
    "    for cat, count in category_counts.most_common():\n",
    "        print(f\"   - {cat}: {count}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview-section",
   "metadata": {},
   "source": [
    "### 8. ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "preview-head",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ CSV ë¯¸ë¦¬ë³´ê¸° (ì²« 5ê°œ):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>src_title</th>\n",
       "      <th>case_no</th>\n",
       "      <th>ruling_date</th>\n",
       "      <th>related_article</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>source</th>\n",
       "      <th>parsed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11b18b5c-0e7b-4ba4-8662-336ad7054ad7</td>\n",
       "      <td>chunk_000</td>\n",
       "      <td>ì „ì„¸í”¼í•´ì§€ì› í”„ë¡œê·¸ë¨ ë°\\nì „ì„¸í”¼í•´ ìƒë‹´ ì‚¬ë¡€ì§‘\\n  êµ­í† ë¶€ ì „ì„¸ì‚¬ê¸°í”¼í•´ì ë° HU...</td>\n",
       "      <td>ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ì£¼ì„ë²• ì œ8ì¡°</td>\n",
       "      <td>ë¶„ìŸí•´ê²°, ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ê¶Œë¦¬_ë¦¬ìŠ¤í¬</td>\n",
       "      <td>7</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...</td>\n",
       "      <td>2026-01-19T17:30:57.170122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab27340e-a006-4c30-ae17-ba4361fcbdfd</td>\n",
       "      <td>chunk_001</td>\n",
       "      <td>8.   ì „ì„¸ì‚¬ê¸°í”¼í•´ì ê²°ì • ì´ì „ ê¸´ê¸‰ ê²½Â·ê³µë§¤ ìœ ì˜ˆÂ·ì •ì§€ 32 \\nì•„ì§ êµ­í† ë¶€ ì „...</td>\n",
       "      <td>ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ì£¼ì„ë²• ì œ8ì¡°</td>\n",
       "      <td>ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ë¶„ìŸí•´ê²°, ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥</td>\n",
       "      <td>7</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...</td>\n",
       "      <td>2026-01-19T17:30:57.171122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbf7fff7-3914-477e-9e00-001ee97c3b3c</td>\n",
       "      <td>chunk_002</td>\n",
       "      <td>16.   ê²½Â·ê³µë§¤ ì…€í”„ë‚™ì°°ë¡œ ì¸í•œ ì „ì„¸ëŒ€ì¶œ ì—°ì²´ 38 \\ní”¼í•´ì£¼íƒì„ ì§ì ‘ ë‚™ì°° ë°›...</td>\n",
       "      <td>ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ì£¼ì„ë²• ì œ8ì¡°</td>\n",
       "      <td>ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ì„ì°¨ê¶Œ_ìŠ¹ê³„</td>\n",
       "      <td>7</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...</td>\n",
       "      <td>2026-01-19T17:30:57.171122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2a88410-4ed9-49b2-b415-12014ca8093f</td>\n",
       "      <td>chunk_003</td>\n",
       "      <td>l   â€˜ì „ì„¸ì‚¬ê¸°í”¼í•´ì ì§€ì› ë° ì£¼ê±°ì•ˆì •ì„ ìœ„í•œ íŠ¹ë³„ë²• (ì´í•˜ ì „ì„¸ì‚¬ê¸° íŠ¹ë³„ë²•) â€™...</td>\n",
       "      <td>ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ì£¼ì„ë²• ì œ8ì¡°</td>\n",
       "      <td>ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ë¶„ìŸí•´ê²°</td>\n",
       "      <td>7</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...</td>\n",
       "      <td>2026-01-19T17:30:57.171122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48665737-a0fa-4d00-87dd-7e3b32841b89</td>\n",
       "      <td>chunk_004</td>\n",
       "      <td>ë³´ì¦ ê°€ì…ì„ì°¨ì¸ì´ ì£¼íƒì„ì°¨ë³´ì¦ê¸ˆ ë°˜í™˜ ë³´ì¦ë³´í—˜ì— ê°€ì…í–ˆê±°ë‚˜, ì„ëŒ€ì¸ì´ ì„ëŒ€ë³´ì¦ê¸ˆ ë°˜...</td>\n",
       "      <td>ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ë¯¸ìƒ</td>\n",
       "      <td>ì£¼ì„ë²• ì œ8ì¡°</td>\n",
       "      <td>ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ì„ëŒ€ë£Œ_ì¦ê°</td>\n",
       "      <td>7</td>\n",
       "      <td>c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...</td>\n",
       "      <td>2026-01-19T17:30:57.171122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   chunk_id  \\\n",
       "0  11b18b5c-0e7b-4ba4-8662-336ad7054ad7  chunk_000   \n",
       "1  ab27340e-a006-4c30-ae17-ba4361fcbdfd  chunk_001   \n",
       "2  bbf7fff7-3914-477e-9e00-001ee97c3b3c  chunk_002   \n",
       "3  b2a88410-4ed9-49b2-b415-12014ca8093f  chunk_003   \n",
       "4  48665737-a0fa-4d00-87dd-7e3b32841b89  chunk_004   \n",
       "\n",
       "                                                text             src_title  \\\n",
       "0  ì „ì„¸í”¼í•´ì§€ì› í”„ë¡œê·¸ë¨ ë°\\nì „ì„¸í”¼í•´ ìƒë‹´ ì‚¬ë¡€ì§‘\\n  êµ­í† ë¶€ ì „ì„¸ì‚¬ê¸°í”¼í•´ì ë° HU...  ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘   \n",
       "1  8.   ì „ì„¸ì‚¬ê¸°í”¼í•´ì ê²°ì • ì´ì „ ê¸´ê¸‰ ê²½Â·ê³µë§¤ ìœ ì˜ˆÂ·ì •ì§€ 32 \\nì•„ì§ êµ­í† ë¶€ ì „...  ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘   \n",
       "2  16.   ê²½Â·ê³µë§¤ ì…€í”„ë‚™ì°°ë¡œ ì¸í•œ ì „ì„¸ëŒ€ì¶œ ì—°ì²´ 38 \\ní”¼í•´ì£¼íƒì„ ì§ì ‘ ë‚™ì°° ë°›...  ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘   \n",
       "3  l   â€˜ì „ì„¸ì‚¬ê¸°í”¼í•´ì ì§€ì› ë° ì£¼ê±°ì•ˆì •ì„ ìœ„í•œ íŠ¹ë³„ë²• (ì´í•˜ ì „ì„¸ì‚¬ê¸° íŠ¹ë³„ë²•) â€™...  ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘   \n",
       "4  ë³´ì¦ ê°€ì…ì„ì°¨ì¸ì´ ì£¼íƒì„ì°¨ë³´ì¦ê¸ˆ ë°˜í™˜ ë³´ì¦ë³´í—˜ì— ê°€ì…í–ˆê±°ë‚˜, ì„ëŒ€ì¸ì´ ì„ëŒ€ë³´ì¦ê¸ˆ ë°˜...  ìƒë‹´ì‚¬ë¡€ - 2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘   \n",
       "\n",
       "  case_no ruling_date related_article                 category  priority  \\\n",
       "0      ë¯¸ìƒ          ë¯¸ìƒ         ì£¼ì„ë²• ì œ8ì¡°    ë¶„ìŸí•´ê²°, ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ê¶Œë¦¬_ë¦¬ìŠ¤í¬         7   \n",
       "1      ë¯¸ìƒ          ë¯¸ìƒ         ì£¼ì„ë²• ì œ8ì¡°    ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ë¶„ìŸí•´ê²°, ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥         7   \n",
       "2      ë¯¸ìƒ          ë¯¸ìƒ         ì£¼ì„ë²• ì œ8ì¡°  ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ì„ì°¨ê¶Œ_ìŠ¹ê³„         7   \n",
       "3      ë¯¸ìƒ          ë¯¸ìƒ         ì£¼ì„ë²• ì œ8ì¡°    ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ë¶„ìŸí•´ê²°         7   \n",
       "4      ë¯¸ìƒ          ë¯¸ìƒ         ì£¼ì„ë²• ì œ8ì¡°  ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ê¶Œë¦¬_ë¦¬ìŠ¤í¬, ì„ëŒ€ë£Œ_ì¦ê°         7   \n",
       "\n",
       "                                              source  \\\n",
       "0  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...   \n",
       "1  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...   \n",
       "2  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...   \n",
       "3  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...   \n",
       "4  c:\\project-AI2\\ì‹¤í”„ë¡œì íŠ¸\\data\\raw\\case\\2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬...   \n",
       "\n",
       "                    parsed_at  \n",
       "0  2026-01-19T17:30:57.170122  \n",
       "1  2026-01-19T17:30:57.171122  \n",
       "2  2026-01-19T17:30:57.171122  \n",
       "3  2026-01-19T17:30:57.171122  \n",
       "4  2026-01-19T17:30:57.171122  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if all_dfs:\n",
    "    print(\"\\nğŸ“‹ CSV ë¯¸ë¦¬ë³´ê¸° (ì²« 5ê°œ):\")\n",
    "    display(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "preview-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ì²­í¬ ìƒ˜í”Œ:\n",
      "ì‚¬ê±´ë²ˆí˜¸: ë¯¸ìƒ\n",
      "ì„ ê³ ì¼: ë¯¸ìƒ\n",
      "ì°¸ì¡°ì¡°í•­: ì£¼ì„ë²• ì œ8ì¡°\n",
      "ì¹´í…Œê³ ë¦¬: ë¶„ìŸí•´ê²°, ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥, ê¶Œë¦¬_ë¦¬ìŠ¤í¬\n",
      "ìš°ì„ ìˆœìœ„: 7\n",
      "ë³¸ë¬¸(ì• 200ì): ì „ì„¸í”¼í•´ì§€ì› í”„ë¡œê·¸ë¨ ë°\n",
      "ì „ì„¸í”¼í•´ ìƒë‹´ ì‚¬ë¡€ì§‘\n",
      "  êµ­í† ë¶€ ì „ì„¸ì‚¬ê¸°í”¼í•´ì ë° HUG ì „ì„¸í”¼í•´í™•ì¸ì„œ \n",
      "1. êµ­í† ë¶€ ì „ì„¸ì‚¬ê¸°í”¼í•´ì ì„ ì •ê¸°ì¤€ 05\n",
      "2. HUG ì „ì„¸í”¼í•´í™•ì¸ì„œ ë°œê¸‰ê¸°ì¤€ 07\n",
      "  ì „ì„¸í”¼í•´ì§€ì› í”„ë¡œê·¸ë¨ \n",
      "1. ì „ì„¸í”¼í•´ ì§€ì›í”„ë¡œê·¸ë¨ ìš”ì•½  10\n",
      "2. ì „ì„¸í”¼í•´ ì§€ì›í”„ë¡œê·¸ë¨ í˜„í™©  12\n",
      "  ì£¼ìš” í”¼í•´ì§€ì› ìƒë‹´ ì‚¬ë¡€ \n",
      "1.   ì „ì„¸ëŒ€ì¶œ ì—°ì²´ ë¬¸ì œ  27 \n",
      "ì „ì„¸...\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ì • ì²­í¬ í™•ì¸\n",
    "if all_dfs:\n",
    "    print(\"\\nğŸ” ì²­í¬ ìƒ˜í”Œ:\")\n",
    "    sample = final_df.iloc[0]\n",
    "    print(f\"ì‚¬ê±´ë²ˆí˜¸: {sample['case_no']}\")\n",
    "    print(f\"ì„ ê³ ì¼: {sample['ruling_date']}\")\n",
    "    print(f\"ì°¸ì¡°ì¡°í•­: {sample['related_article']}\")\n",
    "    print(f\"ì¹´í…Œê³ ë¦¬: {sample['category']}\")\n",
    "    print(f\"ìš°ì„ ìˆœìœ„: {sample['priority']}\")\n",
    "    print(f\"ë³¸ë¬¸(ì• 200ì): {sample['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "info-section",
   "metadata": {},
   "source": [
    "### 9. ì»¬ëŸ¼ ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df-info",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ ë°ì´í„°í”„ë ˆì„ ì •ë³´:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160 entries, 0 to 159\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               160 non-null    object\n",
      " 1   chunk_id         160 non-null    object\n",
      " 2   text             160 non-null    object\n",
      " 3   src_title        160 non-null    object\n",
      " 4   case_no          160 non-null    object\n",
      " 5   ruling_date      160 non-null    object\n",
      " 6   related_article  160 non-null    object\n",
      " 7   category         160 non-null    object\n",
      " 8   priority         160 non-null    int64 \n",
      " 9   source           160 non-null    object\n",
      " 10  parsed_at        160 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 13.9+ KB\n",
      "None\n",
      "\n",
      "ì»¬ëŸ¼ ëª©ë¡:\n",
      "['id', 'chunk_id', 'text', 'src_title', 'case_no', 'ruling_date', 'related_article', 'category', 'priority', 'source', 'parsed_at']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mí˜„ì¬ ì…€ ë˜ëŠ” ì´ì „ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆ Kernelì´ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤. \n",
      "\u001b[1;31mì…€ì˜ ì½”ë“œë¥¼ ê²€í† í•˜ì—¬ ê°€ëŠ¥í•œ ì˜¤ë¥˜ ì›ì¸ì„ ì‹ë³„í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì„ ë³´ë ¤ë©´ <a href='https://aka.ms/vscodeJupyterKernelCrash'>ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì€ Jupyter <a href='command:jupyter.viewOutput'>ë¡œê·¸</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
     ]
    }
   ],
   "source": [
    "if all_dfs:\n",
    "    print(\"\\nğŸ“‹ ë°ì´í„°í”„ë ˆì„ ì •ë³´:\")\n",
    "    print(final_df.info())\n",
    "    print(\"\\nì»¬ëŸ¼ ëª©ë¡:\")\n",
    "    print(final_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb226f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
