{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d979adf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e9024",
   "metadata": {},
   "source": [
    "# 0. í™˜ê²½ë³€ìˆ˜ ë° íŒ¨í‚¤ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83ac912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40949a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "OPENAI_LLM_MODEL = 'gpt-4o-mini'\n",
    "OPENAI_EMBEDDIGN_MODEL = 'text-embedding-3-large' \n",
    "UPSTAGE_EMBEDDIGN_MODEL = 'solar-embedding-1-large-passage'\n",
    "OLLAMA_EMBEDDING_MODEL = 'bge-m3'\n",
    "\n",
    "PINECONE_INDEX_NAME_LAW = 'law'\n",
    "PINECONE_INDEX_NAME_RULE = 'rule'\n",
    "PINECONE_INDEX_NAME_CASE = 'case'\n",
    "\n",
    "COHERE_API_KEY = os.getenv('COHERE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f6071",
   "metadata": {},
   "source": [
    "# 1. í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "674d55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# ìƒìš©ë‹˜ ì¹´í…Œê³ ë¦¬\n",
    "# ==============\n",
    "\n",
    "def get_law_category():\n",
    "    \"\"\"\n",
    "    ì£¼íƒì„ëŒ€ì°¨ RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì¹´í…Œê³ ë¦¬-í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì‚¬ì „\n",
    "    Returns:\n",
    "        dict: {ì¹´í…Œê³ ë¦¬ëª…: {í‚¤ì›Œë“œ: ê°€ì¤‘ì¹˜}}\n",
    "    \"\"\"\n",
    "    return {\n",
    "        # 1. ë³´ì¦ê¸ˆ ë³´í˜¸ (ê°€ì¥ ì¹˜ëª…ì ì¸ ë¦¬ìŠ¤í¬)\n",
    "        'ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥': {\n",
    "            'ë³´ì¦ê¸ˆ': 3, 'ëŒ€í•­ë ¥': 3, 'ìš°ì„ ë³€ì œê¶Œ': 3, 'ìµœìš°ì„ ë³€ì œ': 3,\n",
    "            'ë³´ì¦ê¸ˆë°˜í™˜': 3, 'ì „ì„¸ê¸ˆ': 2, 'ì†Œì•¡ì„ì°¨ì¸': 2, 'í™•ì •ì¼ì': 2,\n",
    "            'ì „ì…ì‹ ê³ ': 2, 'ì ìœ ': 2, 'ì„ì°¨ê¶Œë“±ê¸°': 3, 'ë°°ë‹¹': 2,\n",
    "            'ë°˜í™˜ë³´ì¦': 2, 'HUG': 1, 'ë³´ì¦ë³´í—˜': 2\n",
    "        },\n",
    "\n",
    "        # 2. ê³„ì•½ ê°±ì‹  ë° ê±°ì ˆ (ê°€ì¥ ë¹ˆë²ˆí•œ ë¶„ìŸ)\n",
    "        'ê³„ì•½ê°±ì‹ ': {\n",
    "            'ê³„ì•½ê°±ì‹ ': 3, 'ê°±ì‹ ìš”êµ¬': 3, 'ê°±ì‹ ê±°ì ˆ': 3, 'ë¬µì‹œì ê°±ì‹ ': 3,\n",
    "            'ê³„ì•½ì—°ì¥': 2, 'ì‹¤ê±°ì£¼': 3, 'ì¡´ì†ê¸°ê°„': 2, '2ë…„': 1,\n",
    "            'ì¬ê³„ì•½': 2, 'ê°±ì‹ ì²­êµ¬': 2, 'ê±°ì ˆì‚¬ìœ ': 2, 'ë³µë¹„': 1\n",
    "        },\n",
    "\n",
    "        # 3. ê³„ì•½ í•´ì§€ ë° ì¢…ë£Œ (íƒˆì¶œ ì „ëµ)\n",
    "        'ê³„ì•½í•´ì§€': {\n",
    "            'ê³„ì•½í•´ì§€': 3, 'í•´ì§€í†µê³ ': 3, 'ì¤‘ë„í•´ì§€': 3, 'ê¸°ê°„ë§Œë£Œ': 2,\n",
    "            'ê³„ì•½ì¢…ë£Œ': 2, 'í‡´ê±°': 2, 'ì´ì‚¬': 1, 'ëª…ë„': 2,\n",
    "            'í•©ì˜í•´ì§€': 2, 'í†µì§€': 1, '3ê°œì›”': 2, 'ì¦‰ì‹œí•´ì§€': 3\n",
    "        },\n",
    "\n",
    "        # 4. ì°¨ì„(ì›”ì„¸) ë° ë³´ì¦ê¸ˆ ì¦ê°\n",
    "        'ì„ëŒ€ë£Œ_ì¦ê°': {\n",
    "            'ì°¨ì„': 3, 'ì›”ì„¸': 2, 'ì¦ì•¡': 3, 'ê°ì•¡': 2, 'ì¸ìƒ': 2,\n",
    "            '5í¼ì„¼íŠ¸': 3, '5%': 3, '20ë¶„ì˜ 1': 2, 'ìƒí•œ': 2,\n",
    "            'ì „í™˜ìœ¨': 2, 'ì›”ì°¨ì„': 2, 'ê²½ì œì‚¬ì •': 1, 'ë¶€ë‹´': 1\n",
    "        },\n",
    "\n",
    "        # 5. ìœ ì§€ë³´ìˆ˜ ë° ì›ìƒíšŒë³µ (ë¯¼ë²• ì˜ì—­)\n",
    "        'ìˆ˜ì„ _ì›ìƒíšŒë³µ': {\n",
    "            'ìˆ˜ì„ ': 3, 'ìˆ˜ë¦¬': 3, 'ì›ìƒíšŒë³µ': 3, 'íŒŒì†': 2, 'í›¼ì†': 2,\n",
    "            'ëˆ„ìˆ˜': 2, 'ê³°íŒ¡ì´': 2, 'ë³´ì¼ëŸ¬': 2, 'í•„ìš”ë¹„': 3, 'ìœ ìµë¹„': 3,\n",
    "            'ë¹„ìš©ìƒí™˜': 2, 'ë³´ì¡´í–‰ìœ„': 2, 'ê´€ë¦¬ë¹„': 1\n",
    "        },\n",
    "\n",
    "        # 6. ì „ì„¸ì‚¬ê¸° ë° ê¶Œë¦¬ ë¦¬ìŠ¤í¬ (ë…ì†Œì¡°í•­ íƒì§€ìš©)\n",
    "        'ê¶Œë¦¬_ë¦¬ìŠ¤í¬': {\n",
    "            'ì „ì„¸ì‚¬ê¸°': 3, 'ê¹¡í†µì „ì„¸': 3, 'ì‹ íƒ': 3, 'ê·¼ì €ë‹¹': 3, 'ì €ë‹¹ê¶Œ': 3,\n",
    "            'ì„ ìˆœìœ„': 3, 'ê°€ì••ë¥˜': 3, 'ì••ë¥˜': 3, 'êµ­ì„¸': 2, 'ì§€ë°©ì„¸': 2,\n",
    "            'ì²´ë‚©': 3, 'ë‚©ì„¸ì¦ëª…': 2, 'ìœ„ë°˜ê±´ì¶•ë¬¼': 2, 'ë¶ˆë²•ê±´ì¶•ë¬¼': 2,\n",
    "            'íŠ¹ì•½': 2, 'ë…ì†Œì¡°í•­': 2, 'ê°•í–‰ê·œì •': 3, 'íš¨ë ¥ì´ ì—†ë‹¤': 3, \n",
    "            'ë¬´íš¨': 3, 'ë¶ˆë¦¬í•œ ì•½ì •': 3, 'í¸ë©´ì  ê°•í–‰ê·œì •': 2\n",
    "        },\n",
    "\n",
    "        # 7. í–‰ì • ì ˆì°¨ (Rules Index ì—°ê²°)\n",
    "        'í–‰ì •ì ˆì°¨': {\n",
    "            'í™•ì •ì¼ìë¶€ì—¬': 3, 'ë™ì£¼ë¯¼ì„¼í„°': 2, 'ë“±ê¸°ì†Œ': 2, 'ì¸í„°ë„·ë“±ê¸°ì†Œ': 3,\n",
    "            'ìˆ˜ìˆ˜ë£Œ': 1, 'ì—´ëŒ': 2, 'ì œê³µìš”ì²­': 2, 'ì´í•´ê´€ê³„ì¸': 2,\n",
    "            'ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ': 2, 'ì „ìê³„ì•½': 2, 'ì‹ ë¶„ì¦': 1\n",
    "        },\n",
    "\n",
    "        # 8. ì†Œì†¡ ë° ë¶„ìŸ í•´ê²° (ìµœí›„ ìˆ˜ë‹¨)\n",
    "        'ë¶„ìŸí•´ê²°': {\n",
    "            'ë¶„ìŸì¡°ì •': 3, 'ì¡°ì •ìœ„ì›íšŒ': 2, 'ì§€ê¸‰ëª…ë ¹': 3, 'ì†Œì†¡': 3,\n",
    "            'íŒê²°': 2, 'ì§‘í–‰ê¶Œì›': 2, 'ê²½ë§¤': 3, 'ê³µë§¤': 2,\n",
    "            'ë‚´ìš©ì¦ëª…': 2, 'ì†í•´ë°°ìƒ': 3, 'ì§€ì—°ì´ì': 2\n",
    "        },\n",
    "        # [ì‹ ì„¤] 9. ì„ì°¨ê¶Œ ìŠ¹ê³„ ë° ê°€ì¡± (ì œ9ì¡° íƒ€ê²ŸíŒ…)\n",
    "        'ì„ì°¨ê¶Œ_ìŠ¹ê³„': {\n",
    "            'ì„ì°¨ê¶ŒìŠ¹ê³„': 3, 'ìŠ¹ê³„': 3, 'ì‚¬ë§': 3, 'ìƒì†': 3, 'ìƒì†ì¸': 3,\n",
    "            'ì‚¬ì‹¤í˜¼': 3, 'ë°°ìš°ì': 2, 'ê°€ì •ê³µë™ìƒí™œ': 3, '2ì´Œ': 2, \n",
    "            'ê³µë™ìƒì†': 2, 'ë°˜í™˜ì²­êµ¬ê¶Œ': 2\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def categorize_content(content, top_k=None):\n",
    "    '''\n",
    "    ë‚´ìš© ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ - ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ì ìˆ˜ ìˆœìœ¼ë¡œ ë°˜í™˜\n",
    "    Parameters : \n",
    "        - content : ë¶„ë¥˜í•  í…ìŠ¤íŠ¸ ë‚´ìš©\n",
    "        - top_k : ìƒìœ„ ëª‡ê°œê¹Œì§€ ì¹´í…Œê³ ë¦¬ë¥¼ ë°˜í™˜í• ì§€(Noneì´ë©´ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë°˜í™˜)\n",
    "        \n",
    "    Returns :\n",
    "        - ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸(ì ìˆ˜ ë†’ì€ ìˆœ)\n",
    "    '''\n",
    "    category_keywords = get_law_category()\n",
    "    category_scores = {}\n",
    "    \n",
    "    # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°\n",
    "    for category, weighted_keywords in category_keywords.items():\n",
    "        # print(category, weighted_keywords)\n",
    "        score = 0\n",
    "        for keyword, weight in weighted_keywords.items():\n",
    "            # if keyword in content: # contentì— keywordê°€ í¬í•¨ë˜ì–´ìˆëŠ”ì§€ ì—¬ë¶€\n",
    "                # score += weight\n",
    "            count = content.count(keyword) # contentì— keywordê°€ ëª‡ë²ˆ ë‚˜ì˜¤ëŠ”ì§€\n",
    "            score += count * weight\n",
    "        if score > 0 :\n",
    "            category_scores[category] = score\n",
    "    # print(category_scores)\n",
    "    \n",
    "    # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•œ ì¹´í…Œê³ ë¦¬ ì´ë¦„ë§Œ ì¶”ì¶œ\n",
    "    sorted_categories = sorted(category_scores.items(), key=lambda x : x[1], reverse=True)\n",
    "    all_categories = [category[0] for category in sorted_categories]\n",
    "    # print(all_categories)\n",
    "    \n",
    "    # ë§¤ì¹­ë˜ëŠ” ì¹´í…Œê³ ë¦¬ê°€ ì—†ìœ¼ë©´ 'ê¸°íƒ€' ë°˜í™˜\n",
    "    if not all_categories:\n",
    "        all_categories = ['ê¸°íƒ€']\n",
    "        \n",
    "    # top_kê°€ ì§€ì •ë˜ë©´ ìƒìœ„ top_kê°œë§Œ, ì•„ë‹ˆë©´ ì „ì²´ ë°˜í™˜\n",
    "    if top_k is not None:\n",
    "        return all_categories[:top_k]\n",
    "    return all_categories\n",
    "\n",
    "\n",
    "# =====================\n",
    "# ì°¸ì¡°ì¡°í•­ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "# =====================\n",
    "\n",
    "def extract_articles_from_docs(documents):\n",
    "    '''ê²€ìƒ‰ëœ ë¬¸ì„œë“¤(documents)ì—ì„œ aritcle ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "    Returns : ì¤‘ë³µì´ ì œê±°ëœ ì¡°í•­ ë¦¬ìŠ¤íŠ¸ ex : ['ì œ4ì¡°', 'ì œ16ì¡°']'''\n",
    "    articles = []\n",
    "    for doc in documents:\n",
    "        article = doc.metadata.get('article', 'ì¡°í•­ì—†ìŒ')\n",
    "        \n",
    "        # ã€Œã€ì œê±°. ë¬¸ìë¥¼ listë¡œ ë¶„ë¦¬\n",
    "        if article != 'ì¡°í•­ì—†ìŒ':\n",
    "            article = article.replace('ã€Œ','').replace('ã€','')\n",
    "            article_list = article.split(', ')\n",
    "            articles.extend(article_list)\n",
    "            \n",
    "    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬\n",
    "    unique_articles = list(set(articles))\n",
    "    unique_articles.sort(key=lambda x : int(x[:-1]))\n",
    "    final_articles = ['ì œ'+article for article in unique_articles] \n",
    "    return 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•' + ','.join(final_articles)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# ê²€ìƒ‰ëœ documentë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "# ====================================\n",
    "\n",
    "def format_documents(documents):\n",
    "    return '\\n\\n---\\n\\n'.join([doc.page_content for doc in documents])\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# title+text ê¸°ë°˜ì˜ rerankí•¨ìˆ˜\n",
    "# ===========================\n",
    "\n",
    "import cohere\n",
    "import numpy as np\n",
    "\n",
    "def rerank_by_title(query:str, documents:list, top_k:int=4) -> list:\n",
    "    '''\n",
    "    cohereì˜ rerank APIë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ì¬ì •ë ¬\n",
    "    '''\n",
    "    # cohere client ì´ˆê¸°í™”\n",
    "    co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "    docs_text = [doc.metadata.get('title','') + ' ' + doc.page_content for doc in documents]\n",
    "    \n",
    "    # cohere API í˜¸ì¶œ\n",
    "    results = co.rerank(model='rerank-multilingual-v3.0', # í•œêµ­ì–´ ì§€ì› ëª¨ë¸\n",
    "                        query=query,\n",
    "                        documents=docs_text,\n",
    "                        top_n=top_k)\n",
    "    \n",
    "    # ì¬ì¡°ì •ëœ ë¬¸ì„œ ë°˜í™˜\n",
    "    idxs = [r.index for r in results.results] # ì¬ì¡°ì •ëœ ë¬¸ì„œ index\n",
    "    reranked_docs = [documents[i] for i in idxs]\n",
    "    return reranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c215c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_usage(llm, llm_response):\n",
    "    \"\"\"\n",
    "    langchain_openai.ChatOpenAI ì‘ë‹µì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ.\n",
    "    - ìš°ì„ : llm_response.usage_metadata (ë„¤ ë¡œê·¸ì—ì„œ ì‹¤ì œ ì¡´ì¬)\n",
    "    - ì°¨ì„ : llm_response.response_metadata[\"token_usage\"]\n",
    "    - ê·¸ ì™¸: None\n",
    "    \"\"\"\n",
    "    # OpenAIê°€ ì•„ë‹ˆë©´ None (Ollama ë“±)\n",
    "    if llm.__class__.__module__ != \"langchain_openai.chat_models.base\":\n",
    "        return None\n",
    "\n",
    "    # 1) âœ… ë„¤ í™˜ê²½ì—ì„œ í™•ì‹¤íˆ ì¡´ì¬í•˜ëŠ” usage_metadata\n",
    "    usage_meta = getattr(llm_response, \"usage_metadata\", None)\n",
    "    if isinstance(usage_meta, dict) and usage_meta:\n",
    "        return {\n",
    "            \"input_tokens\": usage_meta.get(\"input_tokens\"),\n",
    "            \"output_tokens\": usage_meta.get(\"output_tokens\"),\n",
    "            \"total_tokens\": usage_meta.get(\"total_tokens\"),\n",
    "        }\n",
    "\n",
    "    # 2) ì¼ë¶€ ì¼€ì´ìŠ¤: response_metadata ì•ˆ token_usage\n",
    "    meta = getattr(llm_response, \"response_metadata\", None) or {}\n",
    "    token_usage = meta.get(\"token_usage\")\n",
    "    if isinstance(token_usage, dict) and token_usage:\n",
    "        # token_usageëŠ” ë³´í†µ prompt_tokens / completion_tokens í˜•íƒœì¼ ìˆ˜ ìˆìŒ\n",
    "        prompt = token_usage.get(\"prompt_tokens\") or token_usage.get(\"input_tokens\")\n",
    "        completion = token_usage.get(\"completion_tokens\") or token_usage.get(\"output_tokens\")\n",
    "        total = token_usage.get(\"total_tokens\")\n",
    "        if total is None and prompt is not None and completion is not None:\n",
    "            total = prompt + completion\n",
    "        return {\n",
    "            \"input_tokens\": prompt,\n",
    "            \"output_tokens\": completion,\n",
    "            \"total_tokens\": total,\n",
    "        }\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def sanitize_for_upstage(text: str, max_len: int = 500) -> str:\n",
    "    \"\"\"Upstage embedding input ì•ˆì „ ì •ì œ: str ë³´ì¥, ê³µë°±/ê°œí–‰ ì •ë¦¬, ê¸¸ì´ ì œí•œ\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    # ì´ìƒí•œ í”„ë¡¬í”„íŠ¸ ì”ì¬ ì œê±°(ê°€ë” 'ì§ˆë¬¸ :' ê°™ì€ prefixê°€ ì„ì„)\n",
    "    text = re.sub(r\"^\\s*(ì§ˆë¬¸\\s*:|question\\s*:|q\\s*:)\\s*\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # ê°œí–‰/íƒ­ ê³¼ë‹¤ë¥¼ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°\n",
    "    if len(text) > max_len:\n",
    "        text = text[:max_len].strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def safe_embedding_query(normalized_query: str, original_query: str) -> str:\n",
    "    q = sanitize_for_upstage(normalized_query)\n",
    "    if not q:  # ë¹ˆ ë¬¸ìì—´ì´ë©´ ì›ë¬¸ìœ¼ë¡œ í´ë°±\n",
    "        q = sanitize_for_upstage(original_query)\n",
    "    return q\n",
    "\n",
    "\n",
    "def retrieve_law_docs_by_priority(\n",
    "    law_db: PineconeVectorStore,\n",
    "    embedding: UpstageEmbeddings,\n",
    "    query_for_embed: str,\n",
    "    categories: list,\n",
    "    k_total: int = 4,\n",
    "    k_each: int = 4,\n",
    "    priorities: list = [1,2,3,4,5,6,7],\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    law ì¸ë±ìŠ¤ì—ì„œ priority=1ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ í™•ì¸í•˜ë©° ë¬¸ì„œë¥¼ ëˆ„ì  ìˆ˜ì§‘.\n",
    "    - embeddingì€ 1íšŒë§Œ ìƒì„±\n",
    "    - priorityê°€ ë‚®ì„ìˆ˜ë¡(1ì´ ê°€ì¥ ì¤‘ìš”) ìš°ì„ ì ìœ¼ë¡œ ì±„ì›€\n",
    "    \"\"\"\n",
    "    # Upstageì— ë„£ëŠ” queryëŠ” ë°˜ë“œì‹œ ì •ì œëœ ê°’ì„ ì‚¬ìš©\n",
    "    clean_q = safe_embedding_query(query_for_embed, query_for_embed)\n",
    "    qvec = embedding.embed_query(clean_q)\n",
    "\n",
    "    collected = []\n",
    "    seen = set()\n",
    "\n",
    "    for p in priorities:\n",
    "        flt = {\n",
    "            \"category\": {\"$in\": categories},\n",
    "            \"priority\": {\"$eq\": p},\n",
    "        }\n",
    "\n",
    "        docs = law_db.similarity_search_by_vector(\n",
    "            qvec,\n",
    "            k=k_each,\n",
    "            filter=flt\n",
    "        )\n",
    "\n",
    "        for d in docs:\n",
    "            # ì¤‘ë³µ ì œê±°(ê°„ë‹¨ key)\n",
    "            key = (d.metadata.get(\"id\"), d.metadata.get(\"source\"), d.page_content[:120])\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            d.metadata.setdefault(\"priority\", p)\n",
    "            collected.append(d)\n",
    "\n",
    "        if len(collected) >= k_total:\n",
    "            break\n",
    "\n",
    "    return collected[:k_total]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2aa537",
   "metadata": {},
   "source": [
    "# 1. ë¹„ìš©ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e426ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_PRICES = {\n",
    "    \"gpt-4o-mini\": {\n",
    "        \"input\": 0.15 / 1000000,\n",
    "        \"output\": 0.60 / 1000000,\n",
    "    },\n",
    "    \"gpt-4.1-mini\": {\n",
    "        \"input\": 0.40 / 1000000,\n",
    "        \"output\": 1.60 / 1000000,\n",
    "    },\n",
    "}\n",
    "\n",
    "def calculate_openai_cost(model_name: str, token_usage: dict) -> float | None:\n",
    "    if token_usage is None:\n",
    "        return None\n",
    "    price = OPENAI_PRICES.get(model_name)\n",
    "    if not price:\n",
    "        return None\n",
    "\n",
    "    return (\n",
    "        token_usage[\"input_tokens\"]  * price[\"input\"] +\n",
    "        token_usage[\"output_tokens\"] * price[\"output\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5020e",
   "metadata": {},
   "source": [
    "# 2. LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099458a7",
   "metadata": {},
   "source": [
    "## index law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a71445b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë¡œ ë§Œë“¤ê¸°\n",
    "\n",
    "def ask_with_reference(query:str, k:int=4, top_k:int=4):\n",
    "    'query, í‘œì¤€í™”ëœ query, ë‹µë³€, ì°¸ì¡°ì‚¬í•­ ì¶œë ¥'\n",
    "    \n",
    "    # 1. llm, embedding\n",
    "    # llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "    # llm = ChatOpenAI(model='gpt-4.1-mini')\n",
    "    llm = ChatOllama(model=\"exaone3.5:2.4b\", temperature=0.1)\n",
    "    # llm = ChatOllama(model=\"bsahane/Qwen2.5-VL-7B-Instruct:Q4_K_M_benxh\", temperature=0.1)\n",
    "    # llm = ChatOllama(model=\"mervinpraison/llama3.1-instruct:8b\", temperature=0.1)\n",
    "    \n",
    "    up_embedding = UpstageEmbeddings(model=UPSTAGE_EMBEDDIGN_MODEL)\n",
    "    ol_embedding = OllamaEmbeddings(model=OLLAMA_EMBEDDING_MODEL)\n",
    "\n",
    "    # 2. ì—…ë¡œë“œí•œ ë²¡í„° DBì—ì„œ ê°€ì ¸ì˜¬ ë•Œ\n",
    "    law_database= PineconeVectorStore(\n",
    "        embedding=up_embedding,\n",
    "        # embedding=ol_embedding,\n",
    "        index_name=PINECONE_INDEX_NAME_LAW)\n",
    "\n",
    "    rule_database = PineconeVectorStore(\n",
    "        embedding=up_embedding,\n",
    "        # embedding=ol_embedding,\n",
    "        index_name=PINECONE_INDEX_NAME_RULE)\n",
    "\n",
    "    case_database = PineconeVectorStore(\n",
    "        embedding=up_embedding,\n",
    "        # embedding=ol_embedding,\n",
    "        index_name=PINECONE_INDEX_NAME_CASE)\n",
    "    \n",
    "    # 3. keyword_chain \n",
    "    keyword_dict = [\n",
    "        # ì‚¬ëŒ\n",
    "        \"ì„¸ì…ì -> ì„ì°¨ì¸\",\n",
    "        \"ì›”ì„¸ì…ì -> ì„ì°¨ì¸\",\n",
    "        \"ì„¸ë“¤ì–´ì‚¬ëŠ”ì‚¬ëŒ -> ì„ì°¨ì¸\",\n",
    "        \"ì„ì°¨ì -> ì„ì°¨ì¸\",\n",
    "        \"ì…ì£¼ì -> ì„ì°¨ì¸\",          \n",
    "\n",
    "        \"ì§‘ì£¼ì¸ -> ì„ëŒ€ì¸\",          \n",
    "        \"ì„ëŒ€ì¸ -> ì„ëŒ€ì¸\",\n",
    "        \"ì£¼ì¸ -> ì„ëŒ€ì¸\",\n",
    "        \"ê±´ë¬¼ì£¼ -> ì„ëŒ€ì¸\", \n",
    "        \"ì„ëŒ€ì—…ì -> ì„ëŒ€ì¸\",\n",
    "        \n",
    "        \"ë¶€ë™ì‚° -> ê³µì¸ì¤‘ê°œì‚¬\", \n",
    "        \"ì¤‘ê°œì¸ -> ê³µì¸ì¤‘ê°œì‚¬\",\n",
    "\n",
    "        # ê¸ˆì•¡/ì§€ê¸‰\n",
    "        \"ì „ì„¸ê¸ˆ -> ì„ì°¨ë³´ì¦ê¸ˆ\",  \n",
    "        \"ë³´ì¦ê¸ˆ -> ì„ì°¨ë³´ì¦ê¸ˆ\",  \n",
    "        \"ì›”ì„¸ -> ì°¨ì„\",    \n",
    "        \"ì›”ì„ëŒ€ë£Œ -> ì°¨ì„\",\n",
    "        \"ì„ëŒ€ë£Œ -> ì°¨ì„\",\n",
    "        \"ë ŒíŠ¸ë¹„ -> ì°¨ì„\",\n",
    "        \"ë°©ì„¸ -> ì°¨ì„\",\n",
    "        \"ê´€ë¦¬ë¹„ -> ê´€ë¦¬ë¹„ìš©\",\n",
    "\n",
    "        \"ë³´ì¦ê¸ˆëŒë ¤ë°›ê¸° -> ë³´ì¦ê¸ˆ ë°˜í™˜\",\n",
    "        \"ë³´ì¦ê¸ˆë°˜í™˜ -> ë³´ì¦ê¸ˆ ë°˜í™˜\",\n",
    "        \"ë³´ì¦ê¸ˆëª»ë°›ìŒ -> ë³´ì¦ê¸ˆ ë°˜í™˜\",\n",
    "\n",
    "        # ê¶Œë¦¬/ìš”ê±´\n",
    "        \"ì „ì…ì‹ ê³  -> ì£¼ë¯¼ë“±ë¡\",     \n",
    "        \"ì „ì… -> ì£¼ë¯¼ë“±ë¡\",\n",
    "        \"í™•ì •ì¼ì -> í™•ì •ì¼ì\",    \n",
    "        \"ëŒ€í•­ìš”ê±´ -> ëŒ€í•­ìš”ê±´\",\n",
    "        \"ëŒ€í•­ë ¥ -> ëŒ€í•­ë ¥\",         \n",
    "        \"ìš°ì„ ë³€ì œ -> ìš°ì„ ë³€ì œ\",\n",
    "        \"ìš°ì„ ë³€ì œê¶Œ -> ìš°ì„ ë³€ì œê¶Œ\",\n",
    "\n",
    "        # ì ˆì°¨/ì‚¬ê±´\n",
    "        \"ì¡°ì •ìœ„ -> ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ\",  \n",
    "        \"ë¶„ìŸì¡°ì • -> ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ\",\n",
    "        \n",
    "        # [í–‰ìœ„ - ëˆ]\n",
    "        \"ì˜¬ë ¤ -> ì¦ì•¡\", \"ì¸ìƒ -> ì¦ì•¡\", \"ë” ë‹¬ë¼ê³  -> ì¦ì•¡\", \"ë” ë‚´ë¼ê³  -> ì¦ì•¡\",\n",
    "        \"ê¹ì•„ -> ê°ì•¡\", \"ë‚´ë ¤ -> ê°ì•¡\", \"í• ì¸ -> ê°ì•¡\",\n",
    "        \"ëŒë ¤ì£¼ì§€ -> ë°˜í™˜\", \"ì•ˆ ì¤˜ -> ë°˜í™˜ê±°ë¶€\", \"ë–¼ë¨¹ -> ë¯¸ë°˜í™˜\",\n",
    "        \n",
    "        # [í–‰ìœ„ - ê±°ì£¼/ê³„ì•½]\n",
    "        \"ê³„ì•½ì„œ -> ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ\", \"íŠ¹ì•½ -> íŠ¹ì•½ì‚¬í•­\",\n",
    "        \"ì´ì‚¬ -> ì£¼íƒì˜ì¸ë„\", \"ì „ì… -> ì£¼ë¯¼ë“±ë¡/ëŒ€í•­ë ¥\",\n",
    "        \"ì‚´ê³  -> ì ìœ \", \"ê±°ì£¼ -> ì ìœ \",\n",
    "        \"ë‚˜ê°€ë¼ -> ê³„ì•½ê°±ì‹ ê±°ì ˆ/ëª…ë„\", \"ë‚˜ê°€ë¼ê³  -> ê³„ì•½ê°±ì‹ ê±°ì ˆ/ëª…ë„\", \"ë¹„ì›Œ -> ëª…ë„\", \"ì«“ê²¨ -> ëª…ë„/ëŒ€í•­ë ¥\",\n",
    "        \"ë°© ë¹¼ -> ê³„ì•½í•´ì§€\", \"ë‚˜ê°ˆê²Œ -> ê³„ì•½í•´ì§€\", \"í•´ì§€ -> ê³„ì•½í•´ì§€\",\n",
    "        \"ì—°ì¥ -> ê³„ì•½ê°±ì‹ \", \"ë” ì‚´ -> ê³„ì•½ê°±ì‹ \", \"ì¬ê³„ì•½ -> ê³„ì•½ê°±ì‹ \",\n",
    "        \"ìˆ˜ë¦¬ -> ìˆ˜ì„ ì˜ë¬´/í•„ìš”ë¹„\", \"ê³ ì³ -> ìˆ˜ì„ ì˜ë¬´\", \"ë¬¼ ìƒˆ -> ëˆ„ìˆ˜\", \"ê³°íŒ¡ì´ -> í•˜ì\",\n",
    "        \"ì²­ì†Œë¹„ -> ì›ìƒíšŒë³µë¹„ìš©\", \"ì›ìƒë³µêµ¬ -> ì›ìƒíšŒë³µ\"\n",
    "    ]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(f'''ì•„ë˜ ì§ˆë¬¸ì—ì„œ ë‹¨ì–´ë§Œ ì‚¬ì „ì„ ê¸°ì¤€ìœ¼ë¡œ ì¹˜í™˜í•˜ì„¸ìš”.ë¬¸ì¥ êµ¬ì¡°, ì‹œì œ, ì˜ë¬¸í˜• ì—¬ë¶€ëŠ” ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”\n",
    "    ì‚¬ì „ : {keyword_dict}\n",
    "    ì§ˆë¬¸ : {{question}}\n",
    "    ì¶œë ¥ì€ ì§ˆë¬¸ ë¬¸ì¥ë§Œ í•˜ì„¸ìš”''')\n",
    "\n",
    "    keyword_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    # 4. ì§ˆë¬¸ì„ í‘œì¤€í™”\n",
    "    normalized_query = keyword_chain.invoke({'question':query}) # ì¶œë ¥í•¨\n",
    "\n",
    "    # 5. ê´€ë ¨ë¬¸ì„œ ê²€ìƒ‰\n",
    "    retriever = law_database.as_retriever(search_kwargs = {'k':k, 'filter':{'category':{'$in':categorize_content(query)}}})\n",
    "    # ê´€ë ¨ë¬¸ì„œ  rerank\n",
    "    embed_query = safe_embedding_query(normalized_query, query)\n",
    "    categories = categorize_content(query)\n",
    "    retrieved_docs = retrieve_law_docs_by_priority(\n",
    "        law_db=law_database,\n",
    "        embedding=up_embedding,\n",
    "        query_for_embed=embed_query,\n",
    "        categories=categories,\n",
    "        k_total=k,         # ìµœì¢… ë¬¸ì„œ ìˆ˜ëŠ” ê¸°ì¡´ kë¥¼ ë”°ë¦„\n",
    "        k_each=max(k, 4),  # ê° priorityì—ì„œ ëª‡ ê°œì”© ë³¼ì§€(ë„‰ë„‰íˆ)\n",
    "        priorities=[1,2,3,4,5,6,7]\n",
    "    )\n",
    "    reranked_docs = rerank_by_title(embed_query, retrieved_docs, top_k) # ìµœì¢… documents\n",
    "    referenced_articles = extract_articles_from_docs(reranked_docs) # ì°¸ì¡°ì¡°í•­ ì¶œë ¥\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ìœ„ì—ê²ƒ ê·¸ëŒ€ë¡œ)ì„ ì´ìš©í•œ ragì²´ì¸ êµ¬ì„±\n",
    "    # template = f'ë‹¹ì‹ ì€ ìµœê³ ì˜ í•œêµ­ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. ë‹µì„ ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ì„¸ìš”. ìµœëŒ€ 3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. ì§ˆë¬¸ : {{query}} / ë¬¸ë§¥ : {{context}} / ë‹µë³€ :'\n",
    "    template = f\"\"\"\n",
    "    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë¶€ë™ì‚° ë²•ë¥ (ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•, ë¯¼ë²• ë“±)ì— ì •í†µí•œ 'AI ë²•ë¥  ë¹„ì„œ'ì…ë‹ˆë‹¤.\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ì—ëŠ” ë²•ë¥ ì  ë§¥ë½ì„ ë•ê¸° ìœ„í•´ '(ë²•ë¥ ìš©ì–´)'ê°€ ë³‘ê¸°ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê²Œ ë¶„ì„í•˜ì„¸ìš”.\n",
    "\n",
    "    [ì§€ì‹œì‚¬í•­]\n",
    "    1. **ê·¼ê±° ê¸°ë°˜**: ë°˜ë“œì‹œ [ì°¸ê³  ë²•ë ¹]ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n",
    "    2. **ì…ë ¥ ë¶„ì„**: ì§ˆë¬¸ì— í¬í•¨ëœ ê´„í˜¸ ì•ˆì˜ ë²•ë¥  ìš©ì–´(ì˜ˆ: ëª…ë„, ëŒ€í•­ë ¥ ë“±)ë¥¼ í•µì‹¬ í‚¤ì›Œë“œë¡œ í™œìš©í•˜ì„¸ìš”.\n",
    "    3. **ë‹µë³€ êµ¬ì¡°**:\n",
    "       - ê²°ë¡ ë¶€í„° ëª…í™•íˆ(ê°€ëŠ¥/ë¶ˆê°€ëŠ¥) ì œì‹œ\n",
    "       - ğŸ“– ë²•ì  ê·¼ê±°(ì œNì¡°) ìƒì„¸ ì„¤ëª…\n",
    "       - ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸\n",
    "    4. **ğŸš¨ ìœ„í—˜ ê²½ê³ **: ë¶ˆë¦¬í•œ íŠ¹ì•½ì´ë‚˜ ë²• ìœ„ë°˜ ì‚¬í•­(ê°•í–‰ê·œì • ìœ„ë°˜)ì€ ê°•ë ¥í•˜ê²Œ ê²½ê³ í•˜ì„¸ìš”.\n",
    "    5. **â— ë©´ì±…**: ë²•ì  íš¨ë ¥ì´ ì—†ìŒì„ ë°íˆì„¸ìš”.\n",
    "\n",
    "    [ì°¸ê³  ë²•ë ¹]\n",
    "    {{context}}\n",
    "    ì§ˆë¬¸ : {{query}}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    # prompt_chain = prompt | llm | StrOutputParser()\n",
    "    # result = prompt_chain.invoke({'context':format_documents(retrieved_docs),\n",
    "                                  # 'query':query})\n",
    "    prompt_chain = prompt | llm\n",
    "    llm_response = prompt_chain.invoke({'context':format_documents(reranked_docs),\n",
    "                                        'query':query})\n",
    "    result = llm_response.content\n",
    "    \n",
    "    \n",
    "    print('ì›ë³¸ ì§ˆë¬¸ :', query)\n",
    "    print('í‘œì¤€í™”ëœ ì§ˆë¬¸ :', normalized_query)\n",
    "    print('='*90)\n",
    "    print('\\nâœ…', result)\n",
    "    # print('\\nğŸ“Œ ì°¸ì¡°ì‚¬í•­ :', referenced_articles)\n",
    "    # print('\\nâ— ìœ„ ë‹µë³€ì€ AIì— ì˜í•´ ìƒì„±ëœ ë‹µë³€ì´ë¯€ë¡œ ì•½ê°„ì˜ ì˜¤ì°¨ê°€ ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤ â—')\n",
    "    \n",
    "    token_usage = get_token_usage(llm, llm_response)\n",
    "    cost = calculate_openai_cost(\"gpt-4.1-mini\", token_usage)\n",
    "    \n",
    "    print(\"\\nğŸ“Š í† í° ì‚¬ìš©ëŸ‰\")\n",
    "    if token_usage is None:\n",
    "        print(\"- Input tokens  : None\")\n",
    "        print(\"- Output tokens : None\")\n",
    "        print(\"- Total tokens  : None\")\n",
    "    else:\n",
    "        print(f\"- Input tokens  : {token_usage['input_tokens']}\")\n",
    "        print(f\"- Output tokens : {token_usage['output_tokens']}\")\n",
    "        print(f\"- Total tokens  : {token_usage['total_tokens']}\")\n",
    "        \n",
    "    print(\"\\nğŸ’° ì¶”ì • ë¹„ìš©\")\n",
    "    print(cost if cost is not None else \"None\")\n",
    "    \n",
    "#     print(\"LAW picked priorities:\", [d.metadata.get(\"priority\") for d in retrieved_docs])\n",
    "\n",
    "    print(\"LAW picked priorities:\", [d.metadata.get(\"priority\") for d in retrieved_docs])\n",
    "    for i, d in enumerate(reranked_docs):\n",
    "        title = d.metadata.get(\"title\") or d.metadata.get(\"source\") or \"\"\n",
    "        snippet = d.page_content[:120].replace(\"\\n\",\" \")\n",
    "        print(i, d.metadata.get(\"priority\"), title, \"|\", snippet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8465d",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "784b5b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì§ˆë¬¸ : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”\n",
      "í‘œì¤€í™”ëœ ì§ˆë¬¸ : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì„ì°¨ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”\n",
      "==========================================================================================\n",
      "\n",
      "âœ… ### ê²°ë¡ \n",
      "**ë¶ˆê°€ëŠ¥**: í˜„ì¬ ê³„ì•½ ê¸°ê°„ì´ 1ë‹¬ ë‚¨ì•„ ìˆëŠ” ìƒí™©ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ê³„ì•½ í•´ì§€ë¥¼ ìš”êµ¬í•˜ëŠ” ê²ƒì€ ë²•ì ìœ¼ë¡œ ì œí•œì ì…ë‹ˆë‹¤. íŠ¹íˆ, ëŒ€í•œë¯¼êµ­ì˜ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ì— ë”°ë¥´ë©´ ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•œ ê³„ì•½ í•´ì§€ ìš”êµ¬ëŠ” ê°•í–‰ê·œì • ìœ„ë°˜ìœ¼ë¡œ ê°„ì£¼ë˜ì–´ íš¨ë ¥ì´ ì—†ì„ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.\n",
      "\n",
      "### ë²•ì  ê·¼ê±° (ì œ10ì¡° ê°•í–‰ê·œì •)\n",
      "**ì œ10ì¡°(ê°•í–‰ê·œì •)**: ì´ ë²•ì— ìœ„ë°˜ëœ ì•½ì •ìœ¼ë¡œì„œ ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•œ ê²ƒì€ ê·¸ íš¨ë ¥ì´ ì—†ë‹¤.\n",
      "\n",
      "- **ìƒì„¸ ì„¤ëª…**:\n",
      "  - **ê°•í–‰ê·œì •**: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ10ì¡°ëŠ” ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•œ ê³„ì•½ ì¡°ê±´ì´ë‚˜ í•´ì§€ ìš”êµ¬ë¥¼ ë²•ì ìœ¼ë¡œ ê°•ì œí•  ìˆ˜ ì—†ìŒì„ ëª…ì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¦‰, ì§‘ì£¼ì¸ì´ ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•œ ì¡°ê±´ìœ¼ë¡œ ê³„ì•½ í•´ì§€ë¥¼ ê°•ìš”í•˜ëŠ” ê²ƒì€ ë²•ì ìœ¼ë¡œ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "  - **ì ìš© ì‚¬ë¡€**: ê³„ì•½ ê¸°ê°„ ì¤‘ì¸ ì„ì°¨ì¸ì—ê²Œ ê°‘ì‘ìŠ¤ëŸ½ê³  ë¶€ë‹¹í•œ í•´ì§€ ìš”êµ¬ëŠ” ë²•ì  ë³´í˜¸ë¥¼ ë°›ì„ ìˆ˜ ìˆìœ¼ë©°, ì´ëŸ¬í•œ ìš”êµ¬ê°€ ìˆì„ ê²½ìš° ì„ì°¨ì¸ì€ ë²•ì  ì¡°ì¹˜ë¥¼ ì·¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸\n",
      "1. **ì¦‰ì‹œ ëŒ€ì‘**:\n",
      "   - **ì—°ë½**: ì¦‰ì‹œ ì§‘ì£¼ì¸ì—ê²Œ ìƒí™©ì„ ì„¤ëª…í•˜ê³  í•©ë¦¬ì ì¸ í•´ê²°ì±…ì„ ëª¨ìƒ‰í•˜ì‹­ì‹œì˜¤. ì˜ˆë¥¼ ë“¤ì–´, ê³„ì•½ ì¡°ê±´ ì¬í™•ì¸, ì¤‘ë„ í•´ì§€ ê°€ëŠ¥ì„± ê²€í†  ë“±ì„ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "   \n",
      "2. **ë²•ë¥  ìƒë‹´**:\n",
      "   - **ì „ë¬¸ê°€ ìƒë‹´**: ë¶€ë™ì‚° ë²•ë¥  ì „ë¬¸ê°€ë‚˜ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì—¬ êµ¬ì²´ì ì¸ ë²•ì  ê¶Œë¦¬ì™€ ëŒ€ì‘ ë°©ì•ˆì„ í™•ì¸í•˜ì„¸ìš”. íŠ¹íˆ, ê³„ì•½ í•´ì§€ì˜ ì ë²•ì„±ê³¼ ê´€ë ¨ëœ ì¦ê±° ìˆ˜ì§‘ ë° ë²•ì  ì ˆì°¨ì— ëŒ€í•´ ì¡°ì–¸ì„ êµ¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì¦ê±° ìˆ˜ì§‘**:\n",
      "   - **ë¬¸ì„œí™”**: ê³„ì•½ ì¡°ê±´, ì´ì „ í†µì‹  ê¸°ë¡, ê³„ì•½ì„œ ì‚¬ë³¸ ë“± ëª¨ë“  ê´€ë ¨ ë¬¸ì„œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë³´ê´€í•˜ì„¸ìš”. ì´ëŠ” í–¥í›„ ë²•ì  ë¶„ìŸ ì‹œ ì¤‘ìš”í•œ ì¦ê±°ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ìœ„í—˜ ê²½ê³  ë° ë©´ì±…\n",
      "**ìœ„í—˜ ê²½ê³ **:\n",
      "- **ê°•í–‰ê·œì • ìœ„ë°˜**: ì§‘ì£¼ì¸ì´ ê°•í–‰ê·œì •ì„ ë¬´ì‹œí•˜ê³  ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•œ ì¡°ê±´ìœ¼ë¡œ ê³„ì•½ í•´ì§€ë¥¼ ê°•ìš”í•˜ëŠ” ê²½ìš°, ì´ëŠ” ë²•ì ìœ¼ë¡œ ë¬´íš¨í™”ë  ìˆ˜ ìˆìœ¼ë©°, ì„ì°¨ì¸ì€ ë²•ì  êµ¬ì œë¥¼ ì²­êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  \n",
      "**ë©´ì±…**:\n",
      "- **ë²•ë¥  ì¡°ì–¸ì˜ í•œê³„**: ë³¸ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì¡°ì–¸ì„ ì œê³µí•˜ë©°, êµ¬ì²´ì ì¸ ìƒí™©ì— ë”°ë¥¸ ë²•ë¥ ì  íŒë‹¨ê³¼ ì¡°ì–¸ì€ ì „ë¬¸ê°€ì™€ì˜ ìƒë‹´ì„ í†µí•´ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ë‹µë³€ì€ ë²•ì  íš¨ë ¥ì´ ì—†ìœ¼ë©°, ê°œì¸ì˜ ìƒí™©ì— ë§ëŠ” ì „ë¬¸ì ì¸ ë²•ë¥  ì„œë¹„ìŠ¤ë¥¼ ë°›ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š í† í° ì‚¬ìš©ëŸ‰\n",
      "- Input tokens  : None\n",
      "- Output tokens : None\n",
      "- Total tokens  : None\n",
      "\n",
      "ğŸ’° ì¶”ì • ë¹„ìš©\n",
      "None\n",
      "LAW picked priorities: [1.0, 1.0, 1.0, 2.0]\n",
      "0 1.0 C:/Users/Admin/AI/lecNote/10_2ndProject/data/raw/law | ì œ10ì¡°(ê°•í–‰ê·œì •) ì´ ë²•ì— ìœ„ë°˜ëœ ì•½ì •(ç´„å®š)ìœ¼ë¡œì„œ ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•œ ê²ƒì€ ê·¸ íš¨ë ¥ì´ ì—†ë‹¤.  [ì „ë¬¸ê°œì • 2008. 3. 21.]\n",
      "1 1.0 C:/Users/Admin/AI/lecNote/10_2ndProject/data/raw/law | ì œ5ì¡° ì‚­ì œ <1989. 12. 30.>\n",
      "2 2.0 C:/Users/Admin/AI/lecNote/10_2ndProject/data/raw/law | ì œ2ì¡°ì˜2  [ì œ9ì¡°ë¡œ ì´ë™ <2013. 12. 30.>]\n",
      "3 1.0 C:/Users/Admin/AI/lecNote/10_2ndProject/data/raw/law | ì œ18ì¡°(ì¡°ì •ìœ„ì›ì˜ ê²°ê²©ì‚¬ìœ ) ã€Œêµ­ê°€ê³µë¬´ì›ë²•ã€ ì œ33ì¡° ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ì‚¬ëŒì€ ì¡°ì •ìœ„ì›ì´ ë  ìˆ˜ ì—†ë‹¤.  [ë³¸ì¡°ì‹ ì„¤ 2016. 5. 29.]\n",
      "CPU times: total: 500 ms\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì‚¬ìš©ì˜ˆì‹œ : exaone3.5:2.4b\n",
    "# query 1 : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”(ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ 6ì¡°(ê³„ì•½ì˜ ê°±ì‹ ) ì–¸ê¸‰í•´ì•¼í•¨)\n",
    "\n",
    "ask_with_reference('ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c243645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì§ˆë¬¸ : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”\n",
      "í‘œì¤€í™”ëœ ì§ˆë¬¸ : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì„ëŒ€ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”\n",
      "==========================================================================================\n",
      "\n",
      "âœ… ê²°ë¡ : **ë¶ˆê°€ëŠ¥**ì…ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“– ë²•ì  ê·¼ê±°:\n",
      "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ10ì¡°(ê°•í–‰ê·œì •)ì—ì„œëŠ” ì„ëŒ€ì°¨ ê³„ì•½ì— ê´€í•œ ì•½ì •ì´ ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•˜ê²Œ ë˜ì–´ì„œëŠ” ì•ˆ ëœë‹¤ê³  ê·œì •í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¦‰, ì„ëŒ€ì¸ì´ ì„ëŒ€ì°¨ ê³„ì•½ì˜ ì¢…ë£Œë¥¼ ì¼ë°©ì ìœ¼ë¡œ í†µë³´í•  ìˆ˜ ìˆëŠ” ê¶Œë¦¬ëŠ” ì—†ìŠµë‹ˆë‹¤. ì„ëŒ€ì°¨ ê³„ì•½ì´ ë§Œë£Œë˜ê¸° ì „ì—ëŠ” ì„ì°¨ì¸ì´ ê³„ì•½ì„ ìœ ì§€í•  ìˆ˜ ìˆëŠ” ê¶Œë¦¬ê°€ ìˆìœ¼ë©°, ì§‘ì£¼ì¸ì€ ê³„ì•½ì´ ë§Œë£Œë  ë•Œê¹Œì§€ ì„ì°¨ì¸ì„ ë‚´ë³´ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸:\n",
      "ê³„ì•½ì´ ë§Œë£Œë˜ê¸° 1ê°œì›” ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ë‚˜ê°€ë¼ê³  ìš”êµ¬í•˜ëŠ” ê²ƒì€ ë²•ì ìœ¼ë¡œ ë¬´íš¨ì…ë‹ˆë‹¤. ë§Œì•½ ì´ì™€ ê°™ì€ ìƒí™©ì´ ê³„ì†ëœë‹¤ë©´, ì§‘ì£¼ì¸ê³¼ì˜ ëŒ€í™”ë¥¼ í†µí•´ ê³„ì•½ ì¡°ê±´ì„ ë‹¤ì‹œ ì„¤ëª…í•˜ê³ , í•„ìš”í•  ê²½ìš° ì„ëŒ€ì°¨ ê³„ì•½ì˜ ë‚´ìš©ì„ ì„œë©´ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ì¦ê±°ë¡œ í™•ë³´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. \n",
      "\n",
      "ğŸš¨ ìœ„í—˜ ê²½ê³ :\n",
      "ì„ëŒ€ì°¨ ê³„ì•½ì—ì„œ ë¶ˆë¦¬í•œ ì•½ì •ì´ë‚˜ íŠ¹ì•½ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ì´ëŠ” ë²•ì ìœ¼ë¡œ ë¬´íš¨ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì œ10ì¡°). ë”°ë¼ì„œ ê³„ì•½ì„œì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì ê²€í•˜ì‹œê³ , ë¶ˆë¦¬í•œ ì¡°í•­ì´ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ì§€ì í•˜ê³  ìˆ˜ì •í•˜ë„ë¡ ìš”êµ¬í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "â— ë©´ì±…:\n",
      "ì´ ë‹µë³€ì€ ë²•ì  íš¨ë ¥ì´ ì—†ìœ¼ë©°, êµ¬ì²´ì ì¸ ë²•ë¥  ë¬¸ì œì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š í† í° ì‚¬ìš©ëŸ‰\n",
      "- Input tokens  : 447\n",
      "- Output tokens : 324\n",
      "- Total tokens  : 771\n",
      "\n",
      "ğŸ’° ì¶”ì • ë¹„ìš©\n",
      "0.00026145\n",
      "LAW picked priorities: [1.0, 1.0, 1.0, 2.0]\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì‚¬ìš©ì˜ˆì‹œ : gpt-4o-mini\n",
    "# query 1 : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”(ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ 6ì¡°(ê³„ì•½ì˜ ê°±ì‹ ) ì–¸ê¸‰í•´ì•¼í•¨)\n",
    "\n",
    "ask_with_reference('ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04d881cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì§ˆë¬¸ : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”\n",
      "í‘œì¤€í™”ëœ ì§ˆë¬¸ : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì„ëŒ€ì¸ì´ ê°‘ìê¸° ê³„ì•½ê°±ì‹ ê±°ì ˆ/ëª…ë„ë˜ìš”\n",
      "==========================================================================================\n",
      "\n",
      "âœ… ê²°ë¡ :  \n",
      "ê³„ì•½ ì¢…ë£Œ 1ë‹¬ ì „ì— ì§‘ì£¼ì¸ì´ ì¼ë°©ì ìœ¼ë¡œ ê³„ì•½ í•´ì§€ë¥¼ í†µë³´í•˜ê³  í‡´ê±° ìš”êµ¬í•˜ëŠ” ê²ƒì€ **ì›ì¹™ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥**í•©ë‹ˆë‹¤. íŠ¹íˆ ì„ëŒ€ì°¨ê³„ì•½ì´ ì¢…ë£Œë˜ê¸° ì „ ì„ì°¨ì¸ì˜ ê±°ì£¼ê¶Œì„ ì¹¨í•´í•˜ëŠ” í–‰ìœ„ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“– ë²•ì  ê·¼ê±°:  \n",
      "- ã€Œì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ã€ ì œ10ì¡°: ë³¸ ë²•ì— ìœ„ë°˜ëœ ì•½ì •ìœ¼ë¡œì„œ ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•œ ì‚¬í•­ì€ íš¨ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.  \n",
      "- ê³„ì•½ ê¸°ê°„ì´ ë‚¨ì•„ ìˆì„ ê²½ìš°, ì„ëŒ€ì¸ì€ ì •ë‹¹í•œ ì‚¬ìœ  ì—†ì´ ì„ì°¨ì¸ì„ ë‚´ë³´ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  \n",
      "- ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ ì‹œ ì„ì°¨ì¸ì€ ê³„ì•½ ë§Œë£Œì¼ê¹Œì§€ ê±°ì£¼í•  ê¶Œë¦¬ê°€ ë³´ì¥ë©ë‹ˆë‹¤. ì§‘ì£¼ì¸ì˜ ì¼ë°©ì  í‡´ê±° ìš”êµ¬ëŠ” ëª…ë„ì˜ ì‚¬ì „ ë²•ì  ì ˆì°¨ ì—†ì´ ì„ì°¨ì¸ì˜ ëŒ€í•­ë ¥ì„ ë¬´ì‹œí•˜ëŠ” í–‰ìœ„ë¡œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "ì¡°ì–¸:  \n",
      "- ê³„ì•½ ì¢…ë£Œì¼ê¹Œì§€ ì•ˆì •ì ìœ¼ë¡œ ê±°ì£¼í•  ê¶Œë¦¬ê°€ ìˆìœ¼ë¯€ë¡œ ê¶Œë¦¬ë¥¼ ì¹¨í•´ë‹¹í–ˆë‹¤ê³  ìƒê°ë˜ë©´ ê³„ì•½ì„œì™€ ê´€ë ¨ ì¦ê±°(ì›”ì„¸ ë‚©ì… ì˜ìˆ˜ì¦ ë“±)ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.  \n",
      "- ì„ëŒ€ì¸ì˜ ë¬´ë¦¬í•œ í‡´ê±° ìš”êµ¬ê°€ ì§€ì†ë˜ê±°ë‚˜ ê°•ì••ì ì¸ ê²½ìš°, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ë° ë¯¼ë²•ìƒ ëª…ë„ ì†Œì†¡ì„ í†µí•´ ê¶Œë¦¬ ë³´í˜¸ ì¡°ì¹˜ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.  \n",
      "- ì„ëŒ€ì°¨ ì¢…ë£Œ ì´í›„ ìƒí™©ì„ ëŒ€ë¹„í•´ ì§‘ì£¼ì¸ê³¼ ëª…í™•í•œ í•©ì˜ì™€ í‡´ê±° ì¼ì •ì„ ë¬¸ì„œí™”í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.  \n",
      "- ë¶ˆë¦¬í•œ ë‚´ìš©ì˜ íŠ¹ì•½ì´ ìˆë”ë¼ë„ ì œ10ì¡°ì— ë”°ë¼ ë²•ì  íš¨ë ¥ì€ ì—†ìœ¼ë¯€ë¡œ ê°•ì••ì— êµ´ë³µí•˜ì§€ ë§ˆì„¸ìš”.  \n",
      "\n",
      "ğŸš¨ ìœ„í—˜ ê²½ê³ :  \n",
      "ì§‘ì£¼ì¸ì´ ì„ì°¨ì¸ì˜ ë™ì˜ ì—†ì´ ì„ëŒ€ì°¨ ê¸°ê°„ ì¤‘ ì¼ë°©ì ìœ¼ë¡œ í‡´ê±°ë¥¼ ìš”êµ¬í•˜ê±°ë‚˜, ë²•ì  ì ˆì°¨ë¥¼ ê±°ì¹˜ì§€ ì•Šì€ ê°•ì œ ëª…ë„ ì‹œë„ëŠ” ë¶ˆë²•ì´ë©° í˜•ì‚¬ì , ë¯¼ì‚¬ì  ì±…ì„ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ê°ë³„íˆ ì£¼ì˜í•˜ì„¸ìš”.  \n",
      "\n",
      "â— ë©´ì±…:  \n",
      "ë³¸ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•˜ë©°, êµ¬ì²´ì  ì‚¬ì‹¤ê´€ê³„ì— ë”°ë¥¸ ë²•ë¥ ì  íŒë‹¨ì„ ëŒ€ì‹ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•„ìš”ì‹œ ì „ë¬¸ ë³€í˜¸ì‚¬ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š í† í° ì‚¬ìš©ëŸ‰\n",
      "- Input tokens  : 447\n",
      "- Output tokens : 491\n",
      "- Total tokens  : 938\n",
      "\n",
      "ğŸ’° ì¶”ì • ë¹„ìš©\n",
      "0.0009644000000000001\n",
      "CPU times: total: 109 ms\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì‚¬ìš©ì˜ˆì‹œ : gpt-4.1-mini\n",
    "# query 1 : ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”(ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ 6ì¡°(ê³„ì•½ì˜ ê°±ì‹ ) ì–¸ê¸‰í•´ì•¼í•¨)\n",
    "\n",
    "ask_with_reference('ê³„ì•½ì´ 1ë‹¬ ë‚¨ì€ ì‹œì ì—ì„œ ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë‚˜ê°€ë˜ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfdd090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151cf06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ebba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8110e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35c8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f5481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ae7b5b",
   "metadata": {},
   "source": [
    "## index ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07ab1062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# =======================================\n",
    "# ìœ í‹¸: ë¬¸ì„œ ì¤‘ë³µ ì œê±° (ë‚´ìš©+ë©”íƒ€ ê¸°ë°˜ ê°„ë‹¨ í‚¤)\n",
    "# =======================================\n",
    "\n",
    "def dedupe_docs(docs: List[Document]) -> List[Document]:\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for d in docs:\n",
    "        key = (\n",
    "            d.metadata.get(\"id\") or d.metadata.get(\"source\") or \"\",\n",
    "            d.metadata.get(\"article\") or \"\",\n",
    "            d.metadata.get(\"priority\") or \"\",\n",
    "            d.page_content[:200],  # ë„ˆë¬´ ê¸¸ë©´ ë¶€ë‹´, ì•ë¶€ë¶„ë§Œ\n",
    "        )\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(d)\n",
    "    return out\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# ìœ í‹¸: priorityë³„ë¡œ ì—¬ëŸ¬ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰\n",
    "# =======================================\n",
    "\n",
    "def retrieve_by_priority(\n",
    "    query: str,\n",
    "    vectorstores: Dict[str, \"PineconeVectorStore\"],  # {\"law\": law_db, \"rule\": rule_db, \"case\": case_db}\n",
    "    categories: List[str],\n",
    "    priorities: List[int] = [1,2,3,4,5,6,7],\n",
    "    k_per_store: int = 4,\n",
    "    use_priority_filter: bool = True,\n",
    ") -> Dict[int, List[Document]]:\n",
    "    \"\"\"\n",
    "    ë°˜í™˜: {priority: [docs...]}  (law/rule/case í†µí•©)\n",
    "    \"\"\"\n",
    "    results: Dict[int, List[Document]] = {p: [] for p in priorities}\n",
    "\n",
    "    # Pinecone ë©”íƒ€ í•„í„° \n",
    "    # priority í•„ë“œëŠ” int\n",
    "    for p in priorities:\n",
    "        for store_name, store in vectorstores.items():\n",
    "            # í•„í„° êµ¬ì„±\n",
    "            base_filter = {\"category\": {\"$in\": categories}}\n",
    "            if use_priority_filter:\n",
    "                base_filter[\"priority\"] = {\"$eq\": p}\n",
    "\n",
    "            retriever = store.as_retriever(search_kwargs={\"k\": k_per_store, \"filter\": base_filter})\n",
    "            docs = retriever.invoke(query)\n",
    "\n",
    "            # ì¶œì²˜/ì¸ë±ìŠ¤ ì •ë³´ íƒœê¹…(ë‚˜ì¤‘ì— ì¶œë ¥/ë””ë²„ê¹…ì— ìœ ìš©)\n",
    "            for d in docs:\n",
    "                d.metadata[\"index\"] = store_name\n",
    "                # priorityê°€ ë¬¸ì„œ ë©”íƒ€ì— ì—†ë‹¤ë©´ pë¡œ ë³´ì •\n",
    "                d.metadata.setdefault(\"priority\", p)\n",
    "\n",
    "            results[p].extend(docs)\n",
    "\n",
    "        results[p] = dedupe_docs(results[p])\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# ë©”ì¸: ask_with_reference (ë©€í‹° ì¸ë±ìŠ¤ + priority ìš°ì„ )\n",
    "# ===================================================\n",
    "\n",
    "def ask_with_reference(query: str, k: int = 4):\n",
    "    \"\"\"\n",
    "    query, í‘œì¤€í™”ëœ query, ë‹µë³€, (priorityë³„) ì°¸ì¡°ì‚¬í•­ ì¶œë ¥\n",
    "    - ë‹µë³€ ì»¨í…ìŠ¤íŠ¸: priority=1 ë¬¸ì„œë§Œ ìš°ì„  ì‚¬ìš©\n",
    "    - ì¶”ê°€ì°¸ê³ : priority=2~7 ë¬¸ì„œê°€ ìˆìœ¼ë©´ í•¨ê»˜ ì¶œë ¥\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) llm, embedding\n",
    "    # llm = ChatOpenAI(model=OPENAI_LLM_MODEL)\n",
    "    # llm = ChatOllama(model=\"exaone3.5:2.4b\", temperature=0.1)\n",
    "    # llm = ChatOpenAI(model='gpt-4.1-mini')\n",
    "    # llm = ChatOllama(model=\"bsahane/Qwen2.5-VL-7B-Instruct:Q4_K_M_benxh\", temperature=0.1)\n",
    "    llm = ChatOllama(model=\"mervinpraison/llama3.1-instruct:8b\", temperature=0.1)\n",
    "    \n",
    "    up_embedding = UpstageEmbeddings(model=UPSTAGE_EMBEDDIGN_MODEL)\n",
    "\n",
    "    # 2) vector DB ì—°ê²° (3ê°œ ë‹¤)\n",
    "    law_database = PineconeVectorStore(embedding=up_embedding, index_name=PINECONE_INDEX_NAME_LAW)\n",
    "    rule_database = PineconeVectorStore(embedding=up_embedding, index_name=PINECONE_INDEX_NAME_RULE)\n",
    "    case_database = PineconeVectorStore(embedding=up_embedding, index_name=PINECONE_INDEX_NAME_CASE)\n",
    "\n",
    "    vectorstores = {\n",
    "        \"law\": law_database,\n",
    "        \"rule\": rule_database,\n",
    "        \"case\": case_database,\n",
    "    }\n",
    "\n",
    "    # 3) keyword_chain \n",
    "    keyword_dict = [\n",
    "        # ì‚¬ëŒ\n",
    "        \"ì„¸ì…ì -> ì„ì°¨ì¸\",\n",
    "        \"ì›”ì„¸ì…ì -> ì„ì°¨ì¸\",\n",
    "        \"ì„¸ë“¤ì–´ì‚¬ëŠ”ì‚¬ëŒ -> ì„ì°¨ì¸\",\n",
    "        \"ì„ì°¨ì -> ì„ì°¨ì¸\",\n",
    "        \"ì…ì£¼ì -> ì„ì°¨ì¸\",          \n",
    "\n",
    "        \"ì§‘ì£¼ì¸ -> ì„ëŒ€ì¸\",          \n",
    "        \"ì„ëŒ€ì¸ -> ì„ëŒ€ì¸\",\n",
    "        \"ì£¼ì¸ -> ì„ëŒ€ì¸\",\n",
    "        \"ê±´ë¬¼ì£¼ -> ì„ëŒ€ì¸\", \n",
    "        \"ì„ëŒ€ì—…ì -> ì„ëŒ€ì¸\",\n",
    "        \n",
    "        \"ë¶€ë™ì‚° -> ê³µì¸ì¤‘ê°œì‚¬\", \n",
    "        \"ì¤‘ê°œì¸ -> ê³µì¸ì¤‘ê°œì‚¬\",\n",
    "\n",
    "        # ê¸ˆì•¡/ì§€ê¸‰\n",
    "        \"ì „ì„¸ê¸ˆ -> ì„ì°¨ë³´ì¦ê¸ˆ\",  \n",
    "        \"ë³´ì¦ê¸ˆ -> ì„ì°¨ë³´ì¦ê¸ˆ\",  \n",
    "        \"ì›”ì„¸ -> ì°¨ì„\",    \n",
    "        \"ì›”ì„ëŒ€ë£Œ -> ì°¨ì„\",\n",
    "        \"ì„ëŒ€ë£Œ -> ì°¨ì„\",\n",
    "        \"ë ŒíŠ¸ë¹„ -> ì°¨ì„\",\n",
    "        \"ë°©ì„¸ -> ì°¨ì„\",\n",
    "        \"ê´€ë¦¬ë¹„ -> ê´€ë¦¬ë¹„ìš©\",\n",
    "\n",
    "        \"ë³´ì¦ê¸ˆëŒë ¤ë°›ê¸° -> ë³´ì¦ê¸ˆ ë°˜í™˜\",\n",
    "        \"ë³´ì¦ê¸ˆë°˜í™˜ -> ë³´ì¦ê¸ˆ ë°˜í™˜\",\n",
    "        \"ë³´ì¦ê¸ˆëª»ë°›ìŒ -> ë³´ì¦ê¸ˆ ë°˜í™˜\",\n",
    "\n",
    "        # ê¶Œë¦¬/ìš”ê±´\n",
    "        \"ì „ì…ì‹ ê³  -> ì£¼ë¯¼ë“±ë¡\",     \n",
    "        \"ì „ì… -> ì£¼ë¯¼ë“±ë¡\",\n",
    "        \"í™•ì •ì¼ì -> í™•ì •ì¼ì\",    \n",
    "        \"ëŒ€í•­ìš”ê±´ -> ëŒ€í•­ìš”ê±´\",\n",
    "        \"ëŒ€í•­ë ¥ -> ëŒ€í•­ë ¥\",         \n",
    "        \"ìš°ì„ ë³€ì œ -> ìš°ì„ ë³€ì œ\",\n",
    "        \"ìš°ì„ ë³€ì œê¶Œ -> ìš°ì„ ë³€ì œê¶Œ\",\n",
    "\n",
    "        # ì ˆì°¨/ì‚¬ê±´\n",
    "        \"ì¡°ì •ìœ„ -> ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ\",  \n",
    "        \"ë¶„ìŸì¡°ì • -> ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ\",\n",
    "        \n",
    "        # [í–‰ìœ„ - ëˆ]\n",
    "        \"ì˜¬ë ¤ -> ì¦ì•¡\", \"ì¸ìƒ -> ì¦ì•¡\", \"ë” ë‹¬ë¼ê³  -> ì¦ì•¡\", \"ë” ë‚´ë¼ê³  -> ì¦ì•¡\",\n",
    "        \"ê¹ì•„ -> ê°ì•¡\", \"ë‚´ë ¤ -> ê°ì•¡\", \"í• ì¸ -> ê°ì•¡\",\n",
    "        \"ëŒë ¤ì£¼ì§€ -> ë°˜í™˜\", \"ì•ˆ ì¤˜ -> ë°˜í™˜ê±°ë¶€\", \"ë–¼ë¨¹ -> ë¯¸ë°˜í™˜\",\n",
    "        \n",
    "        # [í–‰ìœ„ - ê±°ì£¼/ê³„ì•½]\n",
    "        \"ê³„ì•½ì„œ -> ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ\", \"íŠ¹ì•½ -> íŠ¹ì•½ì‚¬í•­\",\n",
    "        \"ì´ì‚¬ -> ì£¼íƒì˜ì¸ë„\", \"ì „ì… -> ì£¼ë¯¼ë“±ë¡/ëŒ€í•­ë ¥\",\n",
    "        \"ì‚´ê³  -> ì ìœ \", \"ê±°ì£¼ -> ì ìœ \",\n",
    "        \"ë‚˜ê°€ë¼ -> ê³„ì•½ê°±ì‹ ê±°ì ˆ/ëª…ë„\", \"ë‚˜ê°€ë¼ê³  -> ê³„ì•½ê°±ì‹ ê±°ì ˆ/ëª…ë„\", \"ë¹„ì›Œ -> ëª…ë„\", \"ì«“ê²¨ -> ëª…ë„/ëŒ€í•­ë ¥\",\n",
    "        \"ë°© ë¹¼ -> ê³„ì•½í•´ì§€\", \"ë‚˜ê°ˆê²Œ -> ê³„ì•½í•´ì§€\", \"í•´ì§€ -> ê³„ì•½í•´ì§€\",\n",
    "        \"ì—°ì¥ -> ê³„ì•½ê°±ì‹ \", \"ë” ì‚´ -> ê³„ì•½ê°±ì‹ \", \"ì¬ê³„ì•½ -> ê³„ì•½ê°±ì‹ \",\n",
    "        \"ìˆ˜ë¦¬ -> ìˆ˜ì„ ì˜ë¬´/í•„ìš”ë¹„\", \"ê³ ì³ -> ìˆ˜ì„ ì˜ë¬´\", \"ë¬¼ ìƒˆ -> ëˆ„ìˆ˜\", \"ê³°íŒ¡ì´ -> í•˜ì\",\n",
    "        \"ì²­ì†Œë¹„ -> ì›ìƒíšŒë³µë¹„ìš©\", \"ì›ìƒë³µêµ¬ -> ì›ìƒíšŒë³µ\"\n",
    "    ]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(f\"\"\"\n",
    "ì•„ë˜ ì§ˆë¬¸ì—ì„œ ë‹¨ì–´ë§Œ ì‚¬ì „ì„ ê¸°ì¤€ìœ¼ë¡œ ì¹˜í™˜í•˜ì„¸ìš”.\n",
    "ë¬¸ì¥ êµ¬ì¡°, ì‹œì œ, ì˜ë¬¸í˜• ì—¬ë¶€ëŠ” ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "ì‚¬ì „ : {keyword_dict}\n",
    "ì§ˆë¬¸ : {{question}}\n",
    "ì¶œë ¥ì€ ì§ˆë¬¸ ë¬¸ì¥ë§Œ í•˜ì„¸ìš”.\n",
    "\"\"\")\n",
    "\n",
    "    keyword_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 4) ì§ˆë¬¸ í‘œì¤€í™”\n",
    "    normalized_query = keyword_chain.invoke({\"question\": query})\n",
    "\n",
    "    # 5) ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì›ë³¸/í‘œì¤€í™” ì¤‘ íƒ1)\n",
    "    categories = categorize_content(query)\n",
    "\n",
    "    # 6) priority ìš°ì„  ê²€ìƒ‰: ëª¨ë“  ì¸ë±ìŠ¤(law/rule/case)ë¥¼ priority=1ë¶€í„° ê²€ìƒ‰\n",
    "    #    - k_per_storeë¥¼ í‚¤ìš°ë©´ priority=1 ê·¼ê±°ê°€ ë” ì˜ ì¡í˜\n",
    "    grouped_docs = retrieve_by_priority(\n",
    "        query=normalized_query,\n",
    "        vectorstores=vectorstores,\n",
    "        categories=categories,\n",
    "        priorities=[1,2,3,4,5,6,7],\n",
    "        k_per_store=max(2, k // 2) if k else 4,  # ëŒ€ì¶© ê· í˜•\n",
    "        use_priority_filter=True,\n",
    "    )\n",
    "\n",
    "    # 7) ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ëŠ” priority=1ë§Œ ìš°ì„  ì‚¬ìš© (ì—†ìœ¼ë©´ 2,3...ë¡œ í´ë°±)\n",
    "    context_docs = grouped_docs.get(1, [])\n",
    "    used_priority = 1\n",
    "    if len(context_docs) == 0:\n",
    "        for p in [2,3,4,5,6,7]:\n",
    "            if grouped_docs.get(p):\n",
    "                context_docs = grouped_docs[p]\n",
    "                used_priority = p\n",
    "                break\n",
    "\n",
    "    # (ì„ íƒ) ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ: ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ kê°œë§Œ\n",
    "    context_docs = context_docs[:k]\n",
    "\n",
    "    # 8) ì°¸ì¡°ì¡°í•­ ì¶”ì¶œ (priorityë³„ë¡œë„ ë½‘ê³  ì‹¶ìœ¼ë©´ ë°˜ë³µí•˜ë©´ ë¨)\n",
    "    referenced_articles_main = extract_articles_from_docs(context_docs)\n",
    "\n",
    "    # 9) RAG í”„ë¡¬í”„íŠ¸\n",
    "    template = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë¶€ë™ì‚° ë²•ë¥ (ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•, ë¯¼ë²• ë“±)ì— ì •í†µí•œ 'AI ë²•ë¥  ë¹„ì„œ'ì…ë‹ˆë‹¤.\n",
    "ì‚¬ìš©ì ì§ˆë¬¸ì—ëŠ” ë²•ë¥ ì  ë§¥ë½ì„ ë•ê¸° ìœ„í•´ '(ë²•ë¥ ìš©ì–´)'ê°€ ë³‘ê¸°ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê²Œ ë¶„ì„í•˜ì„¸ìš”.\n",
    "\n",
    "[ì§€ì‹œì‚¬í•­]\n",
    "1. **ê·¼ê±° ê¸°ë°˜**: ë°˜ë“œì‹œ [ì°¸ê³  ë²•ë ¹]ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n",
    "2. **ì…ë ¥ ë¶„ì„**: ì§ˆë¬¸ì— í¬í•¨ëœ ê´„í˜¸ ì•ˆì˜ ë²•ë¥  ìš©ì–´(ì˜ˆ: ëª…ë„, ëŒ€í•­ë ¥ ë“±)ë¥¼ í•µì‹¬ í‚¤ì›Œë“œë¡œ í™œìš©í•˜ì„¸ìš”.\n",
    "3. **ë‹µë³€ êµ¬ì¡°**:\n",
    "   - ê²°ë¡ ë¶€í„° ëª…í™•íˆ(ê°€ëŠ¥/ë¶ˆê°€ëŠ¥) ì œì‹œ\n",
    "   - ğŸ“– ë²•ì  ê·¼ê±°(ì œNì¡°) ìƒì„¸ ì„¤ëª…\n",
    "   - ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸\n",
    "4. **ğŸš¨ ìœ„í—˜ ê²½ê³ **: ë¶ˆë¦¬í•œ íŠ¹ì•½ì´ë‚˜ ë²• ìœ„ë°˜ ì‚¬í•­(ê°•í–‰ê·œì • ìœ„ë°˜)ì€ ê°•ë ¥í•˜ê²Œ ê²½ê³ í•˜ì„¸ìš”.\n",
    "5. **â— ë©´ì±…**: ë²•ì  íš¨ë ¥ì´ ì—†ìŒì„ ë°íˆì„¸ìš”.\n",
    "\n",
    "[ì°¸ê³  ë²•ë ¹] (priority={used_priority} ìš°ì„  ê·¼ê±°)\n",
    "{{context}}\n",
    "\n",
    "ì§ˆë¬¸ : {{query}}\n",
    "ë‹µë³€ :\n",
    "\"\"\"\n",
    "    rag_prompt = ChatPromptTemplate.from_template(template)\n",
    "    prompt_chain = rag_prompt | llm | StrOutputParser()\n",
    "\n",
    "    result = prompt_chain.invoke({\n",
    "        \"context\": format_documents(context_docs),\n",
    "        \"query\": query\n",
    "    })\n",
    "\n",
    "    # 10) ì¶œë ¥: priority=1 ë‹µë³€ + ì¶”ê°€ê·¼ê±°(priority 2~7)\n",
    "    print(\"ì›ë³¸ ì§ˆë¬¸ :\", query)\n",
    "    print(\"í‘œì¤€í™”ëœ ì§ˆë¬¸ :\", normalized_query)\n",
    "    print(\"=\" * 90)\n",
    "    print(\"\\nâœ…\", result)\n",
    "\n",
    "#     # ë©”ì¸ ê·¼ê±°\n",
    "#     print(\"\\nğŸ“Œ ë©”ì¸ ê·¼ê±°(priority=%d) :\" % used_priority, referenced_articles_main)\n",
    "\n",
    "#     # ì¶”ê°€ ê·¼ê±°(ë¶€ê°€ì ìœ¼ë¡œ ê°™ì´ ì¶œë ¥)\n",
    "#     extra_refs = {}\n",
    "#     for p in [1,2,3,4,5,6,7]:\n",
    "#         if p == used_priority:\n",
    "#             continue\n",
    "#         if grouped_docs.get(p):\n",
    "#             extra_refs[p] = extract_articles_from_docs(grouped_docs[p])\n",
    "\n",
    "#     if extra_refs:\n",
    "#         print(\"\\nğŸ§© ì¶”ê°€ ì°¸ê³ (ë¶€ê°€ ê·¼ê±°) :\")\n",
    "#         for p in sorted(extra_refs.keys()):\n",
    "#             print(f\"  - priority={p} :\", extra_refs[p])\n",
    "\n",
    "    # print(\"\\nâ— ìœ„ ë‹µë³€ì€ AIì— ì˜í•´ ìƒì„±ëœ ë‹µë³€ì´ë¯€ë¡œ ì•½ê°„ì˜ ì˜¤ì°¨ê°€ ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤ â—\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a866496",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1601929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì§ˆë¬¸ : ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”\n",
      "í‘œì¤€í™”ëœ ì§ˆë¬¸ : ì§ˆë¬¸ : ë²½ì§€ ì†ìƒ ì‹œ ì„ì°¨ì¸ì´ ì „ì²´ ìˆ˜ë¦¬ ë¹„ìš©ì„ ë¶€ë‹´í•˜ê³  ê³„ì•½ì„ í•´ì§€í•œë‹¤ê³  ëª…ì‹œë˜ì–´ ìˆë‚˜ìš”?\n",
      "==========================================================================================\n",
      "\n",
      "âœ… ë‹µë³€ : ### ë‹µë³€ ìš”ì•½\n",
      "**ê²°ë¡ **: ë¶ˆê°€ëŠ¥ (ë²•ë¥  ìœ„ë°˜ ê°€ëŠ¥ì„±)\n",
      "\n",
      "**ë²•ì  ê·¼ê±°**:\n",
      "- **ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ6ì¡° (ì„ëŒ€ì°¨ì˜ í•´ì§€ ë° í•´ì§€ì˜ íš¨ë ¥)** ë° **ì œ10ì¡° (ì„ëŒ€ì°¨ê³„ì•½ì˜ í•´ì§€ ì‚¬ìœ )**\n",
      "  - **ì œ6ì¡°**: ì„ëŒ€ì°¨ê³„ì•½ì˜ í•´ì§€ ì‚¬ìœ  ì¤‘ í•˜ë‚˜ë¡œ 'ì„ëŒ€ì¸ì˜ ì¤‘ëŒ€í•œ ê³¼ì‹¤'ì´ ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë²½ì§€ ì†ìƒê³¼ ê°™ì€ ì„ì°¨ì¸ì˜ ì±…ì„ ë²”ìœ„ë¥¼ ë„˜ì–´ì„œëŠ” ì„ëŒ€ì¸ì˜ ê³¼ì‹¤ì´ ì¸ì •ë  ê²½ìš°, ì„ì°¨ì¸ì€ ê³„ì•½ í•´ì§€ë¥¼ ì£¼ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - **ì œ10ì¡°**: ê³„ì•½ í•´ì§€ ì‹œ ì„ëŒ€ì¸ì€ ì„ì°¨ì¸ì—ê²Œ ì ì ˆí•œ ë³´ìƒì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¨ìˆœíˆ ì„ì°¨ì¸ì´ ëª¨ë“  ìˆ˜ë¦¬ ë¹„ìš©ì„ ë¶€ë‹´í•˜ê³  ê³„ì•½ì„ ì¢…ë£Œí•˜ëŠ” ê²ƒì€ ì„ëŒ€ì¸ì˜ ì˜ë¬´ ì´í–‰ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ìƒì„¸ ì„¤ëª…**:\n",
      "- **ì„ëŒ€ì¸ì˜ ì±…ì„**: ë²½ì§€ ì†ìƒê³¼ ê°™ì€ ë¬¸ì œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì„ëŒ€ì¸ì˜ ê´€ë¦¬ ë¶€ì‹¤ì´ë‚˜ ë¶€ì£¼ì˜ë¡œ ì¸í•œ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ë§Œì•½ ì„ëŒ€ì¸ì´ ì´ëŸ¬í•œ ìœ ì§€ë³´ìˆ˜ ì±…ì„ì„ ì¶©ë¶„íˆ ì´í–‰í•˜ì§€ ì•Šì•˜ë‹¤ë©´, ì„ì°¨ì¸ì€ ê³„ì•½ í•´ì§€ë¥¼ ì£¼ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ì„ì°¨ì¸ì˜ ê¶Œë¦¬**: ì„ì°¨ì¸ì€ ê³„ì•½ ì¡°ê±´ì— ëª…ì‹œëœ ì±…ì„ ë²”ìœ„ ë‚´ì—ì„œë§Œ ìˆ˜ë¦¬ ë¹„ìš©ì„ ë¶€ë‹´í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ ê³„ì•½ì„œì— ëª…ì‹œëœ ë‚´ìš©ì´ ë²•ë¥ ìƒ í—ˆìš©ë˜ëŠ” ë²”ìœ„ë¥¼ ë²—ì–´ë‚œë‹¤ë©´, ì´ëŠ” ë²•ì ìœ¼ë¡œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸**:\n",
      "- **ë²•ë¥  ê²€í† **: ê³„ì•½ì„œ ë‚´ìš©ì„ ë²•ë¥  ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ì—¬ í˜„ì¬ ì¡°í•­ì˜ ì ë²•ì„±ì„ í™•ì¸í•˜ì„¸ìš”. íŠ¹íˆ ì„ëŒ€ì¸ì˜ ì±…ì„ ë²”ìœ„ì™€ ì„ì°¨ì¸ì˜ ì˜ë¬´ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "- **í•©ì˜ ì‹œë„**: ì„ëŒ€ì¸ê³¼ì˜ ì§ì ‘ì ì¸ í˜‘ì˜ë¥¼ í†µí•´ í•©ë¦¬ì ì¸ í•´ê²°ì±…ì„ ëª¨ìƒ‰í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, ì¼ë¶€ ë¹„ìš© ë¶„ë‹´ì´ë‚˜ ìˆ˜ë¦¬ ë²”ìœ„ ì¡°ì • ë“±ì´ ê³ ë ¤ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ìœ„í—˜ ê²½ê³ **:\n",
      "- **ê°•í–‰ê·œì • ìœ„ë°˜**: ê³„ì•½ì„œì— ëª…ì‹œëœ ë‚´ìš©ì´ ë²•ë¥ ìƒ ê°•í–‰ê·œì • ìœ„ë°˜ìœ¼ë¡œ ê°„ì£¼ë  ê²½ìš°, ì„ì°¨ì¸ì€ ë²•ì  êµ¬ì œë¥¼ ì²­êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ì„ëŒ€ì¸ì˜ ê³¼ì‹¤ì´ ì¸ì •ë˜ëŠ” ê²½ìš°, ì„ì°¨ì¸ì˜ ê³„ì•½ í•´ì§€ ì£¼ì¥ì´ ë°›ì•„ë“¤ì—¬ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n",
      "\n",
      "** ë©´ì±…**:\n",
      "- **ë²•ë¥  ìë¬¸ í•„ìš”**: ë³¸ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì¡°ì–¸ì„ ì œê³µí•˜ëŠ” ê²ƒì´ë©°, êµ¬ì²´ì ì¸ ìƒí™©ì— ë”°ë¥¸ ë²•ë¥ ì  íŒë‹¨ê³¼ ì¡°ì–¸ì€ ë°˜ë“œì‹œ ë²•ë¥  ì „ë¬¸ê°€ì™€ ìƒë‹´í•´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ë‹µë³€ì€ ë²•ì  íš¨ë ¥ì´ ì—†ìŒì„ ëª…ì‹œí•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Œ ë©”ì¸ ê·¼ê±°(priority=1) : ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•\n",
      "CPU times: total: 1.06 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì‚¬ìš©ì˜ˆì‹œ : exaone3.5:2.4b\n",
    "\n",
    "ask_with_reference('ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9fc145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì§ˆë¬¸ : ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”\n",
      "í‘œì¤€í™”ëœ ì§ˆë¬¸ : ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„ì°¨ì¸ì´ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”\n",
      "==========================================================================================\n",
      "\n",
      "âœ… ë‹µë³€ : ê²°ë¡ : ë¶ˆê°€ëŠ¥\n",
      "\n",
      "ğŸ“– ë²•ì  ê·¼ê±°:\n",
      "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ8ì¡°ì— ë”°ë¥´ë©´, ì„ì°¨ì¸ì€ ê³„ì•½ ê¸°ê°„ ì¤‘ ì •ìƒì ì¸ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ë¬¼ê±´ì˜ ìì—°ì  ë§ˆëª¨ë‚˜ ì†ìƒì— ëŒ€í•´ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ë˜í•œ, ë¯¼ë²• ì œ618ì¡°ì—ì„œëŠ” ì„ëŒ€ì¸ì˜ ì‚¬ìš©ê³¼ ìˆ˜ìµì— ëŒ€í•œ ê¶Œë¦¬ì™€ ì˜ë¬´ë¥¼ ê·œì •í•˜ê³  ìˆìœ¼ë©°, ì„ëŒ€ì¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ì„ì°¨ì¸ì´ ì‚¬ìš© ì¤‘ ìƒê¸´ ì •ìƒì ì¸ ì†ìƒì— ëŒ€í•´ ì±…ì„ì§€ì§€ ì•Šë„ë¡ ë•ëŠ” ì˜ë¬´ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸:\n",
      "ê³„ì•½ì„œì— â€œì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤â€ëŠ” ì¡°í•­ì´ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°, ì´ëŠ” ë²•ì— ì €ì´‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë²½ì§€ì™€ ê°™ì€ ì¼ë°˜ì ì¸ ë§ˆëª¨ì— ëŒ€í•œ ìˆ˜ë¦¬ì— ëŒ€í•´ ì„¸ì…ìê°€ ì±…ì„ì„ ì§€ëŠ” ê²ƒì€ ë¶ˆë¦¬í•œ íŠ¹ì•½ìœ¼ë¡œ í•´ì„ë  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ë²•ì ìœ¼ë¡œ ì¸ì •ë˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ê³„ì•½ì„œì˜ í•´ë‹¹ ì¡°í•­ì´ ê°•í–‰ê·œì •ì— ìœ„ë°˜ëœë‹¤ë©´, ë²•ì›ì—ì„œ ë¬´íš¨ë¡œ íŒë‹¨ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸš¨ ìœ„í—˜ ê²½ê³ : ê³„ì•½ì„œì— ë¶€ì ì ˆí•œ íŠ¹ì•½ì´ í¬í•¨ëœ ê²½ìš°, ì„¸ì…ìì—ê²Œ ë¶ˆë¦¬í•œ ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ë²•ì ìœ¼ë¡œ ë¶ˆë¦¬í•œ ìƒí™©ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¼­ ë²•ë¥  ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì—¬ ê³„ì•½ì„œì˜ ë‚´ìš©ì„ ì¡°ì •í•˜ê±°ë‚˜ ê²€í† ë°›ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â— ë©´ì±…: ë³¸ ë‹µë³€ì€ ë²•ë¥ ì  ì¡°ì–¸ì´ ì•„ë‹ˆë©°, ë²•ì  íš¨ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìƒë‹´ì„ ìœ„í•´ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Œ ë©”ì¸ ê·¼ê±°(priority=1) : ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•\n",
      "CPU times: total: 875 ms\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì‚¬ìš©ì˜ˆì‹œ : gpt-4o-mini\n",
    "\n",
    "ask_with_reference('ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc047a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì§ˆë¬¸ : ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”\n",
      "í‘œì¤€í™”ëœ ì§ˆë¬¸ : ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„ì°¨ì¸ì´ ì „ë¶€ ìˆ˜ì„ ì˜ë¬´í•˜ê³  ì£¼íƒì˜ì¸ë„í•œë‹¤ê³  ë˜ì–´ìˆì–´ìš”\n",
      "==========================================================================================\n",
      "\n",
      "âœ… ë‹µë³€ : ê²°ë¡ :  \n",
      "ê³„ì•½ì„œì— â€˜ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤â€™ëŠ” íŠ¹ì•½ ì¡°í•­ì€ ì¼ë¶€ ì¸ì •ë˜ë‚˜, ì„¸ì…ìì—ê²Œ ì§€ë‚˜ì¹˜ê²Œ ê³¼ë„í•œ ìˆ˜ë¦¬ ì˜ë¬´ë¥¼ ë¶€ê³¼í•˜ëŠ” ê²½ìš°(í†µìƒì ì¸ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ì†ìƒ í¬í•¨)ì—ëŠ” ë²•ì ìœ¼ë¡œ ë¬´íš¨ ë˜ëŠ” ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì „ë¶€ ìˆ˜ë¦¬ ì˜ë¬´ê°€ ë¬´ì¡°ê±´ì ìœ¼ë¡œ ì ìš©ëœë‹¤ê³  ë³´ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“– ë²•ì  ê·¼ê±°:  \n",
      "- **ë¯¼ë²• ì œ623ì¡°(ì„ëŒ€ì¸ì˜ ìˆ˜ë¦¬ì˜ë¬´ ë“±)**: ì„ëŒ€ì°¨ ëª©ì ë¬¼ì˜ ê´€ë¦¬Â·ìˆ˜ë¦¬ëŠ” ì›ì¹™ì ìœ¼ë¡œ ì„ëŒ€ì¸ì´ ë¶€ë‹´í•©ë‹ˆë‹¤. ë‹¤ë§Œ ê³¼ì‹¤ì´ë‚˜ ê³ ì˜ë¡œ ì¸í•œ ì†ìƒì— í•œí•´ ì„ì°¨ì¸ì´ ë°°ìƒí•  ì±…ì„ì´ ìˆìŠµë‹ˆë‹¤.  \n",
      "- **ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡°(ëŒ€í•­ë ¥)**: ì„ì°¨ì¸ì˜ ì£¼ê±° ì•ˆì • ë³´í˜¸ ì°¨ì›ì—ì„œ í†µìƒì ì¸ ì‚¬ìš©ì— ë”°ë¥¸ ì†ìƒì´ë‚˜ ë§ˆëª¨ëŠ” ì„ì°¨ì¸ ì±…ì„ìœ¼ë¡œ ë³´ê¸° ì–´ë µìŠµë‹ˆë‹¤.  \n",
      "- ëŒ€ë²•ì› íŒë¡€ì— ë”°ë¥´ë©´, í†µìƒì ì¸ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ë²½ì§€ ë³€ìƒ‰, ë…¸í›„ëœ ë²½ì§€ ì†ìƒì— ëŒ€í•´ ì„¸ì…ìì—ê²Œ ì „ë¶€ ìˆ˜ë¦¬ë¥¼ ìš”êµ¬í•˜ëŠ” ê²ƒì€ ë¶€ë‹¹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸:  \n",
      "- ê³„ì•½ì„œì˜ â€˜ì „ë¶€ ìˆ˜ë¦¬â€™ ì¡°í•­ì´ í†µìƒì ì¸ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ì†ìƒê¹Œì§€ í¬í•¨í•˜ì—¬ ê³¼ë„í•˜ê²Œ í•´ì„ë  ê²½ìš°, ì„ì°¨ì¸ì—ê²Œ ë¶ˆë¦¬í•˜ê²Œ ì‘ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.  \n",
      "- ì…ì£¼ ì‹œ ë²½ì§€ ìƒíƒœë¥¼ ìƒì„¸íˆ ì‚¬ì§„ ë“±ìœ¼ë¡œ ê¸°ë¡í•˜ì—¬ â€˜ê¸°ì¡´ ì†ìƒâ€™ê³¼ â€˜ì„ì°¨ì¸ ì±…ì„ ì†ìƒâ€™ì„ êµ¬ë¶„í•˜ì„¸ìš”.  \n",
      "- ê³¼ë„í•œ ìˆ˜ë¦¬ ë¶€ë‹´ì´ ì˜ˆìƒë  ê²½ìš° ì„ëŒ€ì¸ê³¼ í˜‘ì˜í•˜ê±°ë‚˜ ë²•ë¥  ìƒë‹´ì„ ë°›ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸš¨ ìœ„í—˜ ê²½ê³ :  \n",
      "- ê³„ì•½ì„œì— í†µìƒì ì¸ ë§ˆëª¨ë‚˜ ë…¸í›„ì— ëŒ€í•œ ìˆ˜ë¦¬ ì±…ì„ê¹Œì§€ ì„ì°¨ì¸ì—ê²Œ ì „ê°€í•˜ëŠ” ê²ƒì€ **ë¯¼ë²•ê³¼ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ìƒ ê°•í–‰ê·œì • ìœ„ë°˜ì´ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë§¤ìš° ìœ„í—˜**í•©ë‹ˆë‹¤.  \n",
      "- ë¶ˆë¦¬í•œ íŠ¹ì•½ì€ ë¶„ìŸ ì‹œ ë¬´íš¨ ë˜ëŠ” ì œí•œë  ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë‹ˆ ê³„ì•½ ì „ ë©´ë°€íˆ ê²€í† í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "â— ë©´ì±…:  \n",
      "ë³¸ ë‹µë³€ì€ ì°¸ê³ ìš©ì´ë©°, êµ¬ì²´ ìƒí™©ì— ë”°ë¼ ë²•ì›ì˜ íŒë‹¨ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒì„ ì–‘ì§€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. ë¶„ìŸ ë°œìƒ ì‹œ ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´ì„ ê¶Œê³ ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Œ ë©”ì¸ ê·¼ê±°(priority=1) : ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•\n",
      "CPU times: total: 797 ms\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì‚¬ìš©ì˜ˆì‹œ : gpt-4.1-mini\n",
    "\n",
    "ask_with_reference('ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9555341d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì§ˆë¬¸ : ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”\n",
      "í‘œì¤€í™”ëœ ì§ˆë¬¸ : ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„ì°¨ì¸ì´ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ê³  ë˜ì–´ìˆì–´ìš”.\n",
      "==========================================================================================\n",
      "\n",
      "âœ… ë‹µë³€ : **ê²°ë¡ **: ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "**ë²•ì  ê·¼ê±°**: **ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ31ì¡°**\n",
      "\n",
      "**í•´ì„ ë° ì¡°ì–¸**: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ31ì¡°ì— ë”°ë¥´ë©´, ì„ëŒ€ì¸ì´ ì„ëŒ€ì°¨ ê³„ì•½ì„œì—ì„œ ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ëŠ” ë‚´ìš©ì„ ëª…ì‹œí•˜ëŠ” ê²ƒì€ ë¶ˆë²•ì…ë‹ˆë‹¤. ì´ëŠ” ê°•ì œê·œì • ìœ„ë°˜ì´ë©°, ë²•ì ìœ¼ë¡œ ë¬´íš¨ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.\n",
      "\n",
      "**ì£¼ì˜ì‚¬í•­**: ì´ ì¡°í•­ì€ ì„ëŒ€ì¸ê³¼ ì„¸ì…ì ëª¨ë‘ì—ê²Œ ì ìš©ë˜ë¯€ë¡œ, í•´ë‹¹ ë‚´ìš©ì´ í¬í•¨ëœ ê³„ì•½ì„œëŠ” ë¬´íš¨ë¡œ ì²˜ë¦¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ ì¬í˜‘ì˜í•˜ì—¬ í•©ë²•ì ì¸ ë‚´ìš©ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ ì´ì— ëŒ€í•œ ë¶ˆë§Œì´ ìˆë‹¤ë©´, ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´ì„ í†µí•´ ë²•ë¥ ì  ì¡°ì–¸ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "\n",
      "**ì£¼ì˜ì‚¬í•­**: ìœ„ ë‚´ìš©ì€ ì°¸ê³  ë²•ë ¹ì— ê¸°ë°˜í•œ ë¶„ì„ì´ë©°, ì‹¤ì œ ë²•ë¥  ì ìš© ì‹œì—ëŠ” ë‹¤ì–‘í•œ ìš”ì†Œê°€ ê³ ë ¤ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìƒí™©ì— ë”°ë¼ ë³€ë™ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 641 ms\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì‚¬ìš©ì˜ˆì‹œ : bsahane/Qwen2.5-VL-7B-Instruct:Q4_K_M_benxh\n",
    "\n",
    "ask_with_reference('ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a5c851e",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://developers.upstage.ai/docs/apis/embeddings\", 'type': 'invalid_request_error', 'param': 'input', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:3\u001b[0m\n",
      "Cell \u001b[1;32mIn[29], line 176\u001b[0m, in \u001b[0;36mask_with_reference\u001b[1;34m(query, k)\u001b[0m\n\u001b[0;32m    172\u001b[0m categories \u001b[38;5;241m=\u001b[39m categorize_content(query)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# 6) priority ìš°ì„  ê²€ìƒ‰: ëª¨ë“  ì¸ë±ìŠ¤(law/rule/case)ë¥¼ priority=1ë¶€í„° ê²€ìƒ‰\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m#    - k_per_storeë¥¼ í‚¤ìš°ë©´ priority=1 ê·¼ê±°ê°€ ë” ì˜ ì¡í˜\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m grouped_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_by_priority\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalized_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectorstores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpriorities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_per_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ëŒ€ì¶© ê· í˜•\u001b[39;49;00m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_priority_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# 7) ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ëŠ” priority=1ë§Œ ìš°ì„  ì‚¬ìš© (ì—†ìœ¼ë©´ 2,3...ë¡œ í´ë°±)\u001b[39;00m\n\u001b[0;32m    186\u001b[0m context_docs \u001b[38;5;241m=\u001b[39m grouped_docs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m1\u001b[39m, [])\n",
      "Cell \u001b[1;32mIn[29], line 51\u001b[0m, in \u001b[0;36mretrieve_by_priority\u001b[1;34m(query, vectorstores, categories, priorities, k_per_store, use_priority_filter)\u001b[0m\n\u001b[0;32m     48\u001b[0m     base_filter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$eq\u001b[39m\u001b[38;5;124m\"\u001b[39m: p}\n\u001b[0;32m     50\u001b[0m retriever \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: k_per_store, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m: base_filter})\n\u001b[1;32m---> 51\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# ì¶œì²˜/ì¸ë±ìŠ¤ ì •ë³´ íƒœê¹…(ë‚˜ì¤‘ì— ì¶œë ¥/ë””ë²„ê¹…ì— ìœ ìš©)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\langchain_core\\retrievers.py:216\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m kwargs_ \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28minput\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_\n\u001b[0;32m    218\u001b[0m     )\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:1040\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1038\u001b[0m kwargs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs \u001b[38;5;241m|\u001b[39m kwargs\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1040\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1042\u001b[0m     docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[0;32m   1044\u001b[0m             query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_\n\u001b[0;32m   1045\u001b[0m         )\n\u001b[0;32m   1046\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\langchain_pinecone\\vectorstores.py:676\u001b[0m, in \u001b[0;36mPineconeVectorStore.similarity_search\u001b[1;34m(self, query, k, filter, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    659\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    664\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    665\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return pinecone documents most similar to query.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \n\u001b[0;32m    667\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 676\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(\n\u001b[0;32m    677\u001b[0m         query, k\u001b[38;5;241m=\u001b[39mk, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m, namespace\u001b[38;5;241m=\u001b[39mnamespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    678\u001b[0m     )\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\langchain_pinecone\\vectorstores.py:543\u001b[0m, in \u001b[0;36mPineconeVectorStore.similarity_search_with_score\u001b[1;34m(self, query, k, filter, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    525\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    530\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m    531\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return pinecone documents most similar to query, along with scores.\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_by_vector_with_score(\n\u001b[1;32m--> 543\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    544\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[0;32m    546\u001b[0m         namespace\u001b[38;5;241m=\u001b[39mnamespace,\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    548\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\langchain_upstage\\embeddings.py:247\u001b[0m, in \u001b[0;36mUpstageEmbeddings.embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    244\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params\n\u001b[0;32m    245\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-query\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 247\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    250\u001b[0m     response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://developers.upstage.ai/docs/apis/embeddings\", 'type': 'invalid_request_error', 'param': 'input', 'code': None}}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì‚¬ìš©ì˜ˆì‹œ : mervinpraison/llama3.1-instruct:8b\n",
    "\n",
    "ask_with_reference('ê³„ì•½ì„œì— ë²½ì§€ ë“±ì´ ì†ìƒë  ê²½ìš° ì„¸ì…ìê°€ ì „ë¶€ ìˆ˜ë¦¬í•˜ê³  ë‚˜ê°„ë‹¤ë¼ê³  ë˜ì–´ìˆì–´ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb553937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm (ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
