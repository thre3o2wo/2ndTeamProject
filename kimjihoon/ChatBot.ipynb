{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0e92e1-17f1-4efd-b734-01fe499c2581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI & Pinecone ì—°ê²° ì™„ë£Œ\n",
      "   - Index: realestate\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# âœ… ë°˜ë“œì‹œ í•„ìš” (ì´ ì…€ì—ì„œ .env ë¡œë“œ)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# === í™˜ê²½ë³€ìˆ˜ ì½ê¸° ===\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "# === í™˜ê²½ë³€ìˆ˜ ê²€ì¦ (ì¤‘ìš”!) ===\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ PINECONE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "if not PINECONE_INDEX_NAME:\n",
    "    raise ValueError(\"âŒ PINECONE_INDEX_NAMEê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (.env í™•ì¸).\")\n",
    "\n",
    "# === í´ë¼ì´ì–¸íŠ¸ ìƒì„± ===\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "# === ëª¨ë¸ ì„¤ì • ===\n",
    "EMBED_MODEL = \"text-embedding-3-large\"   # 3072-dim\n",
    "CHAT_MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "print(\"âœ… OpenAI & Pinecone ì—°ê²° ì™„ë£Œ\")\n",
    "print(\"   - Index:\", PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c3b41-fae8-437a-b4e3-643ed706cc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bd50a-533a-4e54-ac33-bc2bc55b7f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e699468-e06f-4ded-8dd4-d0c525ae5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# RAG CHATBOT (CONTINUATION)\n",
    "# =========================\n",
    "\n",
    "# -------------------------\n",
    "# 1) ì„ë² ë”©\n",
    "# -------------------------\n",
    "def embed(text: str) -> list[float]:\n",
    "    return client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=text\n",
    "    ).data[0].embedding\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2) Pinecone ê²€ìƒ‰\n",
    "# -------------------------\n",
    "def retrieve(\n",
    "    query: str,\n",
    "    namespace: str = \"contracts\",\n",
    "    top_k: int = 7,\n",
    "):\n",
    "    qvec = embed(query)\n",
    "    res = index.query(\n",
    "        vector=qvec,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace,\n",
    "    )\n",
    "\n",
    "    contexts = []\n",
    "    for m in res.matches or []:\n",
    "        md = m.metadata or {}\n",
    "        contexts.append({\n",
    "            \"score\": m.score,\n",
    "            \"doc_id\": md.get(\"doc_id\"),\n",
    "            \"chunk_id\": md.get(\"chunk_id\"),\n",
    "            \"text\": md.get(\"text\", \"\"),\n",
    "        })\n",
    "    return contexts\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3) ìµœì†Œ ëŒ€í™” ë©”ëª¨ë¦¬\n",
    "# -------------------------\n",
    "class ChatMemory:\n",
    "    def __init__(self, max_turns: int = 3):\n",
    "        self.max_turns = max_turns\n",
    "        self.turns = []  # [{\"q\":..., \"a\":...}]\n",
    "\n",
    "    def add(self, q: str, a: str):\n",
    "        self.turns.append({\n",
    "            \"q\": q,\n",
    "            \"a\": a[:160]   # ìš”ì•½ë§Œ ì €ì¥ (ë¹„ìš©/í™˜ê° ë°©ì§€)\n",
    "        })\n",
    "        self.turns = self.turns[-self.max_turns:]\n",
    "\n",
    "    def brief(self) -> str:\n",
    "        if not self.turns:\n",
    "            return \"(ì´ì „ ëŒ€í™” ì—†ìŒ)\"\n",
    "        return \"\\n\".join(\n",
    "            [f\"- Q: {t['q']}\\n  Aìš”ì§€: {t['a']}\" for t in self.turns]\n",
    "        )\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 4) RAG ë‹µë³€ ìƒì„±\n",
    "# -------------------------\n",
    "SYSTEM = \"\"\"\n",
    "- ë°˜ë“œì‹œ ê·¼ê±° ë¬¸ì¥ì„ 2~3ê°œ ë”°ì˜´í‘œë¡œ ì§ì ‘ ì¸ìš©í•˜ë¼\n",
    "- ê·¼ê±° ë¬¸ì¥ì— ì—†ëŠ” í‰ê°€ëŠ” í•˜ì§€ ë§ˆë¼\n",
    "- ê·¼ê±° ë¬¸ì¥ì„ ì¬êµ¬ì„±í•˜ì—¬ ê²°ë¡ ì„ ë„ì¶œí•˜ë¼\n",
    "- í•´ì„/ì¶”ë¡ ì´ í•„ìš”í•œ ê²½ìš° ë°˜ë“œì‹œ 'ê·¼ê±° ë¶€ì¡±'ì´ë¼ê³  ë§í•˜ë¼\n",
    "\"\"\"\n",
    "\n",
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    memory: ChatMemory,\n",
    "    namespace: str = \"contracts\",\n",
    "    top_k: int = 7,\n",
    "):\n",
    "    contexts = retrieve(question, namespace=namespace, top_k=top_k)\n",
    "\n",
    "    if not contexts:\n",
    "        return \"ê·¼ê±° ë¶€ì¡±\"\n",
    "\n",
    "    context_block = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"[doc={c['doc_id']} chunk={c['chunk_id']} score={c['score']:.3f}]\\n{c['text']}\"\n",
    "            for c in contexts\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "[ì´ì „ ëŒ€í™” ìš”ì•½]\n",
    "{memory.brief()}\n",
    "\n",
    "[ê·¼ê±° context]\n",
    "{context_block}\n",
    "\n",
    "[ì§ˆë¬¸]\n",
    "{question}\n",
    "\n",
    "[ë‹µë³€ ê·œì¹™]\n",
    "- ë¦¬ìŠ¤í¬ ìœ„ì£¼ë¡œ ì •ë¦¬\n",
    "- ê·¼ê±°ì— ì—†ëŠ” ë‚´ìš© ê¸ˆì§€\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    answer = resp.choices[0].message.content\n",
    "    memory.add(question, answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32751fc3-fefb-4378-bc5f-bf2be31aa2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ac3e78-4fb0-4649-9288-af444ec44a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Q1\n",
      "ë‹¤ìŒê³¼ ê°™ì€ ë¦¬ìŠ¤í¬ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. ë³´ìƒ ìƒí•œ ì´ˆê³¼ ë¦¬ìŠ¤í¬  \n",
      "   â€œë³¸ ê³„ì•½ì˜ ì†í•´ë°°ìƒ í•œë„ëŠ” ì—°ê°„ ê³„ì•½ ê¸ˆì•¡ì˜ 100%ë¡œ í•œë‹¤.â€  \n",
      "   â†’ ì‹¤ì œ ì†í•´ì•¡ì´ ì—°ê°„ ê³„ì•½ ê¸ˆì•¡ì˜ 100%ë¥¼ ë„˜ì„ ê²½ìš° ì´ˆê³¼ë¶„ì— ëŒ€í•´ ë³´ìƒì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. ë¬´ì œí•œ ì±…ì„ ë¦¬ìŠ¤í¬  \n",
      "   â€œë‹¨, ê³ ì˜ ë˜ëŠ” ì¤‘ê³¼ì‹¤, ë¹„ë°€ìœ ì§€ ìœ„ë°˜, ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´ì˜ ê²½ìš° ì†í•´ë°°ìƒ í•œë„ë¥¼ ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.â€  \n",
      "   â†’ í•´ë‹¹ ì‚¬ìœ ê°€ ë°œìƒí•˜ë©´ ì†í•´ë°°ìƒ í•œë„ ì—†ì´ ì „ì•¡ ì±…ì„ì„ ì ¸ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ¤– Q2 (ì´ì „ ëŒ€í™” ê¸°ë°˜)\n",
      "1. ë¬´ì œí•œ ì±…ì„ ë°œìƒ ë¦¬ìŠ¤í¬  \n",
      "   ê·¼ê±°: â€œë‹¨, ê³ ì˜ ë˜ëŠ” ì¤‘ê³¼ì‹¤, ë¹„ë°€ìœ ì§€ ìœ„ë°˜, ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´ì˜ ê²½ìš° ì†í•´ë°°ìƒ í•œë„ë¥¼ ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.â€  \n",
      "   â†’ í•´ë‹¹ ì‚¬ìœ ë§Œ ë°œìƒí•˜ë©´ ì—°ê°„ ê³„ì•½ ê¸ˆì•¡ 100%ë¼ëŠ” ìƒí•œì´ ì‚¬ë¼ì ¸, ì´ë¡ ìƒ ë¬´ì œí•œì˜ ì†í•´ë°°ìƒ ì±…ì„ì„ ë¶€ë‹´í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
      "\n",
      "2. ì˜ˆì™¸ ë²”ìœ„ì˜ ê´‘ë²”ìœ„Â·ë¶ˆëª…í™• ë¦¬ìŠ¤í¬  \n",
      "   ê·¼ê±°: â€œê³ ì˜ ë˜ëŠ” ì¤‘ê³¼ì‹¤, ë¹„ë°€ìœ ì§€ ìœ„ë°˜, ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´â€  \n",
      "   â†’ â€˜ë¹„ë°€ìœ ì§€ ìœ„ë°˜â€™ì´ë‚˜ â€˜ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´â€™ ë“± íŒë‹¨ ê¸°ì¤€ì´ êµ¬ì²´ì ìœ¼ë¡œ ì •ì˜ë˜ì§€ ì•Šì•„, ì‚¬ì†Œí•œ í•´ì„ ì°¨ì´ë§Œìœ¼ë¡œë„ ìƒí•œì´ ì œì™¸ë  ì—¬ì§€ê°€ í½ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "memory = ChatMemory()\n",
    "\n",
    "print(\"ğŸ¤– Q1\")\n",
    "print(answer_with_rag(\n",
    "    \"ì†í•´ë°°ìƒ í•œë„ ì¡°í•­ì—ì„œ ì–´ë–¤ ë¦¬ìŠ¤í¬ê°€ ìˆì–´?\",\n",
    "    memory\n",
    "))\n",
    "\n",
    "print(\"\\nğŸ¤– Q2 (ì´ì „ ëŒ€í™” ê¸°ë°˜)\")\n",
    "print(answer_with_rag(\n",
    "    \"ê·¸ ì˜ˆì™¸ ì¡°í•­ì€ ì™œ ë¬¸ì œê°€ ë˜ì§€?\",\n",
    "    memory\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc3139-9539-419d-b401-2b3552340fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a1399-8dea-47a0-a0c8-24f470ff22c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e03989-d892-4ba5-bdf9-b3205bbb935a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722fdb8-3d72-4029-8afe-8f6dfdfab0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44755f9-61e3-4220-8190-13ea87be9afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d112be6f-46c4-415d-b94f-5939ebb0dc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pinecone ê¸°ë°˜ ìë£Œ í•´ì„¤í˜• ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ\n",
      "\n",
      "ğŸ¤– ì§ˆë¬¸ 1\n",
      "1. [ìë£Œ ë°œì·Œ] : \"ë³¸ ê³„ì•½ì˜ ì†í•´ë°°ìƒ í•œë„ëŠ” ì—°ê°„ ê³„ì•½ ê¸ˆì•¡ì˜ 100%ë¡œ í•œë‹¤. ë‹¨, ê³ ì˜ ë˜ëŠ” ì¤‘ê³¼ì‹¤, ë¹„ë°€ìœ ì§€ ìœ„ë°˜, ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´ì˜ ê²½ìš° ì†í•´ë°°ìƒ í•œë„ë¥¼ ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ê³„ì•½ í•´ì§€ëŠ” 30ì¼ ì „ ì„œë©´ í†µì§€ë¡œ ê°€ëŠ¥í•˜ë‹¤.\"\n",
      "\n",
      "2. [ìë£Œ ì •ë¦¬] : ì†í•´ë°°ìƒì˜ ìµœëŒ€ í•œë„ëŠ” ì—°ê°„ ê³„ì•½ ê¸ˆì•¡ì˜ 100%ë¡œ ì œí•œë˜ë©°, ê·¸ëŸ¬ë‚˜ ê³ ì˜, ì¤‘ê³¼ì‹¤, ë¹„ë°€ìœ ì§€ ìœ„ë°˜, ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´ ë“± íŠ¹ì • ê²½ìš°ì—ëŠ” ì´ í•œë„ê°€ ì ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤. ë˜í•œ ê³„ì•½ í•´ì§€ëŠ” 30ì¼ ì „ì— ì„œë©´ìœ¼ë¡œ í†µì§€í•´ì•¼ í•œë‹¤.\n",
      "\n",
      "3. [í•´ì„¤] : ê³„ì•½ì— ë”°ë¼ ì†í•´ë°°ìƒì€ ì—°ê°„ ê³„ì•½ ê¸ˆì•¡ë§Œí¼ ìµœëŒ€í•œ ì œí•œë˜ì§€ë§Œ, ê³ ì˜ë‚˜ ì¤‘ìš”í•œ ë²• ìœ„ë°˜ ì‹œì—ëŠ” ë¬´ì œí•œ ë°°ìƒì´ ê°€ëŠ¥í•¨ì„ ëª…ì‹œí•˜ì—¬ ê¸°ì—… ê°„ ì±…ì„ ë²”ìœ„ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ê·œì •í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "ğŸ¤– ì§ˆë¬¸ 2\n",
      "1. [ìë£Œ ë°œì·Œ] : \"ë³¸ ê³„ì•½ì˜ ì†í•´ë°°ìƒ í•œë„ëŠ” ì—°ê°„ ê³„ì•½ ê¸ˆì•¡ì˜ 100%ë¡œ í•œë‹¤. ë‹¨, ê³ ì˜ ë˜ëŠ” ì¤‘ê³¼ì‹¤, ë¹„ë°€ìœ ì§€ ìœ„ë°˜, ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´ì˜ ê²½ìš° ì†í•´ë°°ìƒ í•œë„ë¥¼ ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ê³„ì•½ í•´ì§€ëŠ” 30ì¼ ì „ ì„œë©´ í†µì§€ë¡œ ê°€ëŠ¥í•˜ë‹¤.\"\n",
      "\n",
      "2. [ìë£Œ ì •ë¦¬] : ê³„ì•½ì—ì„œëŠ” ì†í•´ë°°ìƒ í•œë„ë¥¼ ì—°ê°„ ê³„ì•½ ê¸ˆì•¡ì˜ 100%ë¡œ ì •í•˜ê³  ìˆì§€ë§Œ, ê³ ì˜ë‚˜ ì¤‘ê³¼ì‹¤, ë¹„ë°€ìœ ì§€ ìœ„ë°˜, ì§€ì‹ì¬ì‚°ê¶Œ ì¹¨í•´ì™€ ê°™ì€ íŠ¹ì •í•œ ê²½ìš°ì—ëŠ” ì´ í•œë„ë¥¼ ì ìš©í•˜ì§€ ì•ŠëŠ” ì˜ˆì™¸ ì¡°í•­ì´ ìˆë‹¤.\n",
      "\n",
      "3. [í•´ì„¤] : ì´ ì˜ˆì™¸ ì¡°í•­ì€ ê³„ì•½ ë‹¹ì‚¬ìê°€ ê³ ì˜ì ì´ê±°ë‚˜ ì¤‘ëŒ€í•œ ê³¼ì‹¤í–‰ìœ„, ë¹„ë°€ì •ë³´ ëˆ„ì„¤, ë˜ëŠ” ì§€ì‹ì¬ì‚°ê¶Œì„ ì¹¨í•´í–ˆì„ ë•ŒëŠ” ì†í•´ë°°ìƒì˜ í•œë„ì—ì„œ ë²—ì–´ë‚˜ ë” í° ë°°ìƒì„ ìš”êµ¬í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•œë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# =========================\n",
    "# 0) ENV & CLIENT\n",
    "# =========================\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "if not OPENAI_API_KEY or not PINECONE_API_KEY or not PINECONE_INDEX_NAME:\n",
    "    raise ValueError(\"âŒ .env ì„¤ì • í™•ì¸ í•„ìš”\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-large\"\n",
    "CHAT_MODEL  = \"gpt-4.1-mini\"   # ë¹„ì‹¼ ëª¨ë¸ ë¶ˆí•„ìš”\n",
    "\n",
    "print(\"âœ… Pinecone ê¸°ë°˜ ìë£Œ í•´ì„¤í˜• ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) EMBEDDING\n",
    "# =========================\n",
    "def embed(text: str) -> list[float]:\n",
    "    return client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=text\n",
    "    ).data[0].embedding\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) PINECONEì—ì„œ 'ìë£Œ' ê°€ì ¸ì˜¤ê¸°\n",
    "# =========================\n",
    "def fetch_sources(\n",
    "    query: str,\n",
    "    namespace: str = \"contracts\",\n",
    "    top_k: int = 8,\n",
    "):\n",
    "    qvec = embed(query)\n",
    "    res = index.query(\n",
    "        vector=qvec,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace,\n",
    "    )\n",
    "\n",
    "    sources = []\n",
    "    for m in res.matches or []:\n",
    "        md = m.metadata or {}\n",
    "        if md.get(\"text\"):\n",
    "            sources.append({\n",
    "                \"doc_id\": md.get(\"doc_id\"),\n",
    "                \"chunk_id\": md.get(\"chunk_id\"),\n",
    "                \"text\": md.get(\"text\")\n",
    "            })\n",
    "    return sources\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) ìë£Œ í•´ì„¤ ì „ìš© SYSTEM PROMPT\n",
    "# =========================\n",
    "SYSTEM = \"\"\"ë„ˆì˜ ì—­í• ì€ 'ìë£Œ í•´ì„¤ì'ë‹¤.\n",
    "\n",
    "ê·œì¹™:\n",
    "- ë°˜ë“œì‹œ ì œê³µëœ [ìë£Œ ë°œì·Œ]ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ë¼.\n",
    "- ìë£Œì— ì—†ëŠ” ì‚¬ì‹¤, í‰ê°€, ì¼ë°˜ë¡ , ì¶”ì •ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆë¼.\n",
    "- ìƒˆë¡œìš´ ë¦¬ìŠ¤í¬ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆë¼.\n",
    "- ë‹µë³€ì€ ë°˜ë“œì‹œ ì•„ë˜ êµ¬ì¡°ë¥¼ ë”°ë¥¸ë‹¤.\n",
    "\n",
    "[ì¶œë ¥ êµ¬ì¡°]\n",
    "1. [ìë£Œ ë°œì·Œ] : ì œê³µëœ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ì¸ìš©\n",
    "2. [ìë£Œ ì •ë¦¬] : ë°œì·Œ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë¬¶ì–´ ì •ë¦¬ (ìƒˆ ì •ë³´ ê¸ˆì§€)\n",
    "3. [í•´ì„¤] : ìœ„ ìë£Œê°€ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ìµœì†Œí•œìœ¼ë¡œ ì„¤ëª…\n",
    "\n",
    "ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ìë£Œê°€ ë¶€ì¡±í•˜ë©´ ë°˜ë“œì‹œ 'ìë£Œ ë¶€ì¡±'ì´ë¼ê³  ë§í•˜ë¼.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) ìë£Œ ê¸°ë°˜ í•´ì„¤ ì±—ë´‡\n",
    "# =========================\n",
    "def explain_with_sources(\n",
    "    question: str,\n",
    "    namespace: str = \"contracts\",\n",
    "    top_k: int = 8,\n",
    "):\n",
    "    sources = fetch_sources(question, namespace, top_k)\n",
    "\n",
    "    if not sources:\n",
    "        return \"ìë£Œ ë¶€ì¡±\"\n",
    "\n",
    "    source_block = \"\\n\".join(\n",
    "        [\n",
    "            f'- \"{s[\"text\"]}\" (doc={s[\"doc_id\"]}, chunk={s[\"chunk_id\"]})'\n",
    "            for s in sources\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "[ì§ˆë¬¸]\n",
    "{question}\n",
    "\n",
    "[ìë£Œ ë°œì·Œ]\n",
    "{source_block}\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) DEMO\n",
    "# =========================\n",
    "print(\"\\nğŸ¤– ì§ˆë¬¸ 1\")\n",
    "print(\n",
    "    explain_with_sources(\n",
    "        \"ì†í•´ë°°ìƒ í•œë„ ì¡°í•­ì—ì„œ ì–´ë–¤ ë‚´ìš©ì´ ê·œì •ë¼ ìˆì–´?\",\n",
    "        namespace=\"contracts\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¤– ì§ˆë¬¸ 2\")\n",
    "print(\n",
    "    explain_with_sources(\n",
    "        \"ê·¸ ì˜ˆì™¸ ì¡°í•­ì€ ì–´ë–¤ ì˜ë¯¸ì•¼?\",\n",
    "        namespace=\"contracts\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ccd41f-0441-40c9-a7e9-7335676f4451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304dbba-1eea-428b-a9f9-a23566a5bd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25c06303-af9e-4287-a72f-c76a9af2a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë²•ë ¹ ê·¼ê±° í•´ì„¤ ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ\n",
      "   - Index: realestate\n",
      "   - Namespace: __default__\n",
      "\n",
      "ğŸ¤– ë°ëª¨\n",
      "1) [ë²•ë ¹ ë°œì·Œ] : \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• :ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ì€ ì£¼ê±°ìš© ê±´ë¬¼ì˜ ì„ëŒ€ì°¨ì— ê´€í•˜ì—¬ ë¯¼ë²•ì—ëŒ€í•œ íŠ¹ë¡€ë¥¼ ê·œì •í•¨ìœ¼ë¡œì¨ ì„ëŒ€ì¸ê³¼ ì„ì°¨ì¸ì„ ë³´í˜¸í•˜ê³  êµ­ë¯¼ì£¼ê±°ìƒí™œì˜ ì•ˆì •ì„ ë³´ì¥í•¨ì„ëª©ì ìœ¼ë¡œ í•˜ì—¬ ì œì •ëœ ë²•ë¥ ì…ë‹ˆë‹¤(1981. ë²•ë¥  ì œ3379í˜¸). ì´ ë²•ë¥ ì€ ì‚¬ì‹¤ìƒ ì£¼íƒì—ëŒ€í•œ ì±„ê¶Œì  ì „ì„¸ë‚˜ ì„ëŒ€ì°¨ê´€ê³„ë¥¼ ê·œì •í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ, ì„ì°¨ì¸ì˜ ê¶Œë¦¬ë¥¼ ë³´í˜¸í•˜ê¸° ìœ„í•œì¤‘ìš”í•œ ë²•ë¥ ì…ë‹ˆë‹¤.\" (doc=ì „ì„¸í”¼í•´ë²•ë¥ ìƒë‹´ì‚¬ë¡€ì§‘_250102.pdf, chunk=case_1_29)\n",
      "\n",
      "2) [ì¡°ë¬¸ ìš”ì§€] : ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ì€ ì£¼ê±°ìš© ê±´ë¬¼ ì„ëŒ€ì°¨ì— ëŒ€í•´ ë¯¼ë²•ì˜ íŠ¹ë¡€ë¥¼ ë‘ì–´ ì„ëŒ€ì¸ê³¼ ì„ì°¨ì¸ì„ ë³´í˜¸í•˜ê³  êµ­ë¯¼ ì£¼ê±°ìƒí™œì˜ ì•ˆì •ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ì œì •ëœ ë²•ë¥ ì´ë©°, ì£¼íƒì˜ ì „ì„¸ ë˜ëŠ” ì„ëŒ€ì°¨ê´€ê³„ì—ì„œ ì„ì°¨ì¸ì˜ ê¶Œë¦¬ë¥¼ ë³´í˜¸í•˜ëŠ” ì¤‘ìš”í•œ ë²•ë¥ ì´ë‹¤.\n",
      "\n",
      "3) [í•´ì„¤] : ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ì€ ì§‘ì„ ë¹Œë ¤ì£¼ëŠ” ì‚¬ëŒê³¼ ë¹Œë¦¬ëŠ” ì‚¬ëŒ ëª¨ë‘ë¥¼ ë³´í˜¸í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì§„ ë²•ì´ì—ìš”. íŠ¹íˆ ì „ì„¸ ê°™ì€ ì£¼íƒ ì„ëŒ€ì°¨ ê´€ê³„ì—ì„œ ì„¸ì…ìë¥¼ ì§€ì¼œì£¼ê¸° ìœ„í•œ ì¤‘ìš”í•œ ë²•ì´ì—ìš”.\n",
      "\n",
      "4) [ì¶”ê°€ë¡œ í™•ì¸í•  ì‚¬ì‹¤] : \n",
      "- ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ì—ì„œ ëŒ€í•­ë ¥ê³¼ í™•ì •ì¼ìì— ê´€í•œ êµ¬ì²´ì ì¸ ê·œì •ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "- ì „ì„¸ê¶Œìì˜ ìš°ì„ ë³€ì œê¶Œì— ê´€í•œ ë²•ë¥  ì¡°í•­ì€ ì–´ë””ì— ìˆë‚˜ìš”?\n",
      "- ëŒ€í•­ë ¥ ë°œìƒ ì‹œì ê³¼ í™•ì •ì¼ìì˜ ê´€ê³„ì— ëŒ€í•´ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•  ë²•ë ¹ ë‚´ìš©ì´ ìˆë‚˜ìš”?\n",
      "- ì„ëŒ€ì°¨ ê³„ì•½ì—ì„œ í™•ì •ì¼ì ë¶€ì—¬ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# =========================\n",
    "# 0) ENV & CLIENT\n",
    "# =========================\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "if not OPENAI_API_KEY or not PINECONE_API_KEY or not PINECONE_INDEX_NAME:\n",
    "    raise ValueError(\"âŒ .envì— OPENAI_API_KEY / PINECONE_API_KEY / PINECONE_INDEX_NAME ì„¤ì • í•„ìš”\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-large\"\n",
    "CHAT_MODEL  = \"gpt-4.1-mini\"\n",
    "\n",
    "DEFAULT_NS = \"__default__\"  # âœ… ë„¤ stats ê¸°ì¤€ ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê³³\n",
    "\n",
    "print(\"âœ… ë²•ë ¹ ê·¼ê±° í•´ì„¤ ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(\"   - Index:\", PINECONE_INDEX_NAME)\n",
    "print(\"   - Namespace:\", DEFAULT_NS)\n",
    "\n",
    "# =========================\n",
    "# 1) EMBEDDING\n",
    "# =========================\n",
    "def embed(text: str) -> list[float]:\n",
    "    return client.embeddings.create(model=EMBED_MODEL, input=text).data[0].embedding\n",
    "\n",
    "# =========================\n",
    "# 2) Safe KR sentence split (no variable look-behind)\n",
    "# =========================\n",
    "def split_sentences_kr(text: str) -> list[str]:\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    # 1) .,?,! ë’¤ ê³µë°± ë¶„ë¦¬\n",
    "    parts = re.split(r'(?<=[\\.\\?\\!])\\s+', text)\n",
    "\n",
    "    # 2) 'ë‹¤.' ê¸°ì¤€ ì¶”ê°€ ë¶„ë¦¬(look-behind ì—†ì´)\n",
    "    final = []\n",
    "    for p in parts:\n",
    "        sub = re.split(r'(ë‹¤\\.)\\s*', p)\n",
    "        buf = \"\"\n",
    "        i = 0\n",
    "        while i < len(sub):\n",
    "            token = sub[i]\n",
    "            if token == \"ë‹¤.\":\n",
    "                buf += token\n",
    "                if buf.strip():\n",
    "                    final.append(buf.strip())\n",
    "                buf = \"\"\n",
    "            else:\n",
    "                buf += token\n",
    "            i += 1\n",
    "        if buf.strip():\n",
    "            final.append(buf.strip())\n",
    "\n",
    "    # ì •ë¦¬\n",
    "    final = [s.strip() for s in final if s and s.strip()]\n",
    "    return final\n",
    "\n",
    "TEXT_KEYS = [\"text\", \"page_content\", \"content\", \"body\", \"chunk\", \"excerpt\", \"paragraph\", \"raw_text\"]\n",
    "\n",
    "def extract_text(md: dict) -> str:\n",
    "    if not isinstance(md, dict):\n",
    "        return \"\"\n",
    "    for k in TEXT_KEYS:\n",
    "        v = md.get(k)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip()\n",
    "    data = md.get(\"data\")\n",
    "    if isinstance(data, dict):\n",
    "        for k in TEXT_KEYS:\n",
    "            v = data.get(k)\n",
    "            if isinstance(v, str) and v.strip():\n",
    "                return v.strip()\n",
    "    return \"\"\n",
    "\n",
    "def is_law_like(md: dict, sent: str) -> bool:\n",
    "    law_type = str(md.get(\"law_type\") or \"\").lower()\n",
    "    category = str(md.get(\"category\") or \"\").lower()\n",
    "    source   = str(md.get(\"source\") or \"\").lower()\n",
    "    meta_blob = \" \".join([law_type, category, source])\n",
    "\n",
    "    if any(x in meta_blob for x in [\"law\", \"ë²•ë ¹\", \"ì¡°ë¬¸\", \"statute\", \"regulation\", \"ë¯¼ë²•\", \"ì£¼íƒì„ëŒ€ì°¨\"]):\n",
    "        return True\n",
    "    if re.search(r\"\\bì œ\\s*\\d+\\s*ì¡°\\b\", sent):\n",
    "        return True\n",
    "    if any(k in sent for k in [\"ë¯¼ë²•\", \"ì£¼íƒì„ëŒ€ì°¨\", \"ì¡°\", \"ì‹œí–‰ë ¹\", \"ì‹œí–‰ê·œì¹™\", \"ë²•ë¥ \"]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# =========================\n",
    "# 3) Pineconeì—ì„œ ë²•ë ¹ ë¬¸ì¥ ë½‘ê¸°\n",
    "# =========================\n",
    "def fetch_law_quotes(query: str, namespace: str = DEFAULT_NS, top_k: int = 30, max_quotes: int = 8):\n",
    "    qvec = embed(query)\n",
    "    res = index.query(\n",
    "        vector=qvec,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace,\n",
    "    )\n",
    "\n",
    "    pool = []\n",
    "    for m in res.matches or []:\n",
    "        md = m.metadata or {}\n",
    "        raw = extract_text(md)\n",
    "        if not raw:\n",
    "            continue\n",
    "\n",
    "        for sent in split_sentences_kr(raw):\n",
    "            pool.append({\n",
    "                \"score\": float(getattr(m, \"score\", 0.0)),\n",
    "                \"doc_id\": md.get(\"doc_id\") or md.get(\"source\") or \"unknown\",\n",
    "                \"chunk_id\": md.get(\"chunk_id\"),\n",
    "                \"law_type\": md.get(\"law_type\") or md.get(\"category\") or \"\",\n",
    "                \"text\": sent,\n",
    "                \"law_like\": is_law_like(md, sent),\n",
    "            })\n",
    "\n",
    "    if not pool:\n",
    "        return []\n",
    "\n",
    "    # dedupe\n",
    "    seen = set()\n",
    "    cleaned = []\n",
    "    for s in pool:\n",
    "        norm = re.sub(r\"\\s+\", \"\", s[\"text\"])\n",
    "        if len(s[\"text\"]) < 10:\n",
    "            continue\n",
    "        if norm in seen:\n",
    "            continue\n",
    "        seen.add(norm)\n",
    "        cleaned.append(s)\n",
    "\n",
    "    cleaned.sort(key=lambda x: (1 if x[\"law_like\"] else 0, x[\"score\"]), reverse=True)\n",
    "    return cleaned[:max_quotes]\n",
    "\n",
    "# =========================\n",
    "# 4) LLM: ë°œì·Œ â†’ ìš”ì§€ â†’ í•´ì„¤\n",
    "# =========================\n",
    "SYSTEM = \"\"\"ë„ˆëŠ” 'ë²•ë ¹ ê·¼ê±° í•´ì„¤' ì±—ë´‡ì´ë‹¤.\n",
    "\n",
    "ì ˆëŒ€ ê·œì¹™:\n",
    "- ë°˜ë“œì‹œ ì œê³µëœ [ë²•ë ¹ ë°œì·Œ] ë¬¸ì¥ë§Œì„ ê·¼ê±°ë¡œ ë‹µí•œë‹¤.\n",
    "- ë°œì·Œì— ì—†ëŠ” ì‚¬ì‹¤/ë²•ë¦¬/ì ˆì°¨/íŒë¡€/ì¶”ì •/ì¼ë°˜ë¡ ì„ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆë¼.\n",
    "- ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ë°œì·Œë§Œìœ¼ë¡œ ë‹µì„ í™•ì •í•  ìˆ˜ ì—†ìœ¼ë©´ 'ê·¼ê±° ë¶€ì¡±' ë˜ëŠ” 'ì¶”ê°€ í™•ì¸ í•„ìš”'ë¼ê³  ë§í•˜ë¼.\n",
    "\n",
    "[ì¶œë ¥ í˜•ì‹]\n",
    "1) [ë²•ë ¹ ë°œì·Œ] : 4~8ê°œ ë¬¸ì¥ì„ ë”°ì˜´í‘œë¡œ ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ê³  (doc/chunk) í‘œê¸°\n",
    "2) [ì¡°ë¬¸ ìš”ì§€] : ë°œì·Œì˜ ì˜ë¯¸ë¥¼ ì¤‘ë³µ ì—†ì´ ì¬êµ¬ì„±(ìƒˆ ì •ë³´ ê¸ˆì§€)\n",
    "3) [í•´ì„¤] : ìš”ì§€ë¥¼ ì‰¬ìš´ ë§ë¡œ ì„¤ëª…(ìƒˆ ì •ë³´ ê¸ˆì§€)\n",
    "4) [ì¶”ê°€ë¡œ í™•ì¸í•  ì‚¬ì‹¤] : í•„ìš”í•œ ì§ˆë¬¸ 2~5ê°œ\n",
    "\"\"\"\n",
    "\n",
    "def law_chat(question: str, namespace: str = DEFAULT_NS, top_k: int = 30, max_quotes: int = 8):\n",
    "    quotes = fetch_law_quotes(question, namespace=namespace, top_k=top_k, max_quotes=max_quotes)\n",
    "    if not quotes:\n",
    "        return \"ê·¼ê±° ë¶€ì¡±\"\n",
    "\n",
    "    quote_block = \"\\n\".join(\n",
    "        [f'- \"{q[\"text\"]}\" (doc={q[\"doc_id\"]}, chunk={q[\"chunk_id\"]})' for q in quotes]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "[ì§ˆë¬¸]\n",
    "{question}\n",
    "\n",
    "[ë²•ë ¹ ë°œì·Œ]\n",
    "{quote_block}\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# =========================\n",
    "# 5) Demo\n",
    "# =========================\n",
    "print(\"\\nğŸ¤– ë°ëª¨\")\n",
    "print(law_chat(\"ì „ì„¸ ê³„ì•½ì—ì„œ ëŒ€í•­ë ¥ê³¼ í™•ì •ì¼ì, ìš°ì„ ë³€ì œì— ê´€í•œ ë²•ë ¹ ê·¼ê±°ë¥¼ ë°œì·Œí•´ì„œ í•´ì„¤í•´ì¤˜\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d73e3f-3511-4203-b11d-ddcb0f16d99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10ccb93b-fcd1-4270-b3a2-c8ef69484537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] score=0.432\n",
      "law_type: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• category: law source: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20260102).docx\n",
      "text: ì„ì°¨ì¸ì´ ëŒ€í•­ë ¥ì´ë‚˜ ìš°ì„ ë³€ì œê¶Œì„ ê°–ì¶”ê³  ã€Œë¯¼ë²•ã€\n",
      "\n",
      "[2] score=0.432\n",
      "law_type: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• category: law source: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20260102).docx\n",
      "text: ì„ì°¨ì¸ì´ ëŒ€í•­ë ¥ì´ë‚˜ ìš°ì„ ë³€ì œê¶Œì„ ê°–ì¶”ê³  ã€Œë¯¼ë²•ã€\n",
      "\n",
      "[3] score=0.403\n",
      "law_type: ê·œì¹™ category: rule source: ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™(ëŒ€ë²•ì›ê·œì¹™)(ì œ02986í˜¸)(20210610).docx\n",
      "text: ì œ1í•­ì˜ í™•ì •ì¼ìì •ë³´ëŠ” 20ë…„ê°„ ë³´ì¡´í•œë‹¤.\n",
      "\n",
      "[4] score=0.400\n",
      "law_type: ê·œì¹™ category: rule source: ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™(ëŒ€ë²•ì›ê·œì¹™)(ì œ02986í˜¸)(20210610).docx\n",
      "text: ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™ ì¼ë¶€ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê°œì •í•œë‹¤.\n",
      "\n",
      "[5] score=0.400\n",
      "law_type: ì‹œí–‰ê·œì¹™/ëŒ€ë²•ì›ê·œì¹™ category: rule source: ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™(ëŒ€ë²•ì›ê·œì¹™)(ì œ02986í˜¸)(20210610).docx\n",
      "text: ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì¦ì„œì˜ í™•ì •ì¼ì ë¶€ì—¬ ë° ì •ë³´ì œê³µì— ê´€í•œ ê·œì¹™ ì¼ë¶€ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê°œì •í•œë‹¤.\n",
      "\n",
      "[6] score=0.385\n",
      "law_type: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• category: law source: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20260102).docx\n",
      "text: ì œ1í•­ì— ë”°ë¼ ìš°ì„ ë³€ì œë¥¼ ë°›ì„ ì„ì°¨ì¸ ë° ë³´ì¦ê¸ˆ ì¤‘ ì¼ì •ì•¡ì˜ ë²”ìœ„ì™€ ê¸°ì¤€ì€\n",
      "\n",
      "[7] score=0.385\n",
      "law_type: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• category: law source: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20260102).docx\n",
      "text: ì œ1í•­ì— ë”°ë¼ ìš°ì„ ë³€ì œë¥¼ ë°›ì„ ì„ì°¨ì¸ ë° ë³´ì¦ê¸ˆ ì¤‘ ì¼ì •ì•¡ì˜ ë²”ìœ„ì™€ ê¸°ì¤€ì€\n",
      "\n",
      "[8] score=0.382\n",
      "law_type: ì‹œí–‰ë ¹ category: rule source: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35947í˜¸)(20260102).docx\n",
      "text: (ì‹œí–‰ì¼) ì´ ì˜ì€ 2026ë…„ 1ì›” 2ì¼ë¶€í„° ì‹œí–‰í•œë‹¤. ë‹¤ë§Œ, ë¶€ì¹™\n"
     ]
    }
   ],
   "source": [
    "qvec = embed(\"ëŒ€í•­ë ¥ í™•ì •ì¼ì ìš°ì„ ë³€ì œ\")\n",
    "res = index.query(\n",
    "    vector=qvec,\n",
    "    top_k=8,\n",
    "    include_metadata=True,\n",
    "    namespace=\"__default__\"\n",
    ")\n",
    "\n",
    "for i, m in enumerate(res.matches or [], 1):\n",
    "    md = m.metadata or {}\n",
    "    print(f\"\\n[{i}] score={m.score:.3f}\")\n",
    "    print(\"law_type:\", md.get(\"law_type\"), \"category:\", md.get(\"category\"), \"source:\", md.get(\"source\"))\n",
    "    print(\"text:\", (md.get(\"text\") or \"\")[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bdfbb-9759-4dfa-b057-4d3c4ff3bad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763bcf2-64ef-4887-af3f-5153d29628bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d215758-995c-44f2-8478-0957bae380c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
