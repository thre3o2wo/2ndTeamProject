{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338392a-ba8a-4849-ab0b-3166f2d0364f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fdfcf-0159-49ae-a379-6af1f94c8c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a1192-07ab-4a7f-ae82-65066a8201de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ\n",
      " - index: realestate2\n",
      " - namespace: __default2__\n",
      " - embed: text-embedding-3-large | chat: gpt-4.1-mini\n",
      "\n",
      "=== ğŸ  RealEstate RAG Chat (ê·¼ê±° TEXT í¬í•¨) ===\n",
      "ëª…ë ¹ì–´: /exit ì¢…ë£Œ | /help ë„ì›€ë§ | /ns í˜„ì¬ namespace í‘œì‹œ\n",
      "ê·¸ëƒ¥ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ê·¼ê±° TEXTë¥¼ ê°™ì´ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You>  ì§‘ì£¼ì¸ì´ ë³´ì¦ê¸ˆì„ ì•ˆ ëŒë ¤ì£¼ë©´ ë°”ë¡œ ì†Œì†¡ ê°€ëŠ¥í•œê°€ìš”?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bot>\n",
      "1) [ê·¼ê±° TEXT] :\n",
      "- (priority=1, law_type=ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•, source=ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20260102).docx, article=ì œ13ì¡°, chunk=0, score=0.547)\n",
      "  \"(ã€Œì†Œì•¡ì‚¬ê±´ì‹¬íŒë²•ã€ì˜ ì¤€ìš©) ì„ì°¨ì¸ì´ ì„ëŒ€ì¸ì— ëŒ€í•˜ì—¬ ì œê¸°í•˜ëŠ” ë³´ì¦ê¸ˆë°˜í™˜ì²­êµ¬ì†Œì†¡ì— ê´€í•˜ì—¬ëŠ” ã€Œì†Œì•¡ì‚¬ê±´ì‹¬íŒë²•ã€\"\n",
      "\n",
      "- (priority=4, law_type=ì‚¬ë¡€/íŒë¡€/í”¼í•´ìƒë‹´, source=2025ì „ì„¸í”¼í•´ì§€ì›ì‚¬ë¡€ì§‘.pdf, article=ì‚¬ë¡€ 4, chunk=0, score=0.589)\n",
      "  \"ê¹¡í†µì£¼íƒ ë§¤ìˆ˜ ë¬¸ì œ 5 ë³´ì¦ê¸ˆë°˜í™˜ì†Œì†¡ ë“± ì†Œì†¡ë¹„ìš© ë¬¸ì œ ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ëŒë ¤ì¤„ ìˆ˜ ì—†ìœ¼ë‹ˆ í”¼í•´ì£¼íƒì˜ ì†Œìœ ê¶Œì„ ëŒ€ì‹  ì´ì „í•´ ê°€ë¼ê³  ì„ëŒ€ì¸ì„ ëŒ€ìƒìœ¼ë¡œ ë³´ì¦ê¸ˆë°˜í™˜ì†Œì†¡ ë“±ì„ ì§„í–‰í•˜ê³ ì í•˜ëŠ”ë° ì†Œì†¡ë¹„ìš©ì´ ë¶€ë‹´ë©ë‹ˆë‹¤. í•©ë‹ˆë‹¤. ë³´ì¦ê¸ˆìœ¼ë¡œ ì§‘ì„ ë§¤ìˆ˜í•´ë„ ë¬¸ì œê°€ ì—†ì„ê¹Œìš”? l ì„ ëŒ€ì¸ì´ í”¼í•´ì£¼íƒ ì™¸ íšŒìˆ˜ì‹¤ìµì´ ìˆëŠ” ì¬ì‚°ê³¼ ì†Œë“ì´ ì—†ì–´ ë³´ì¦ê¸ˆë°˜í™˜ì´ ë¶ˆê°€í•œ ìƒí™©ì´ë¼ë©´ l êµ­ í† ë¶€ ì „ì„¸ì‚¬ê¸°í”¼í•´ì(ë‚˜ëª©, ë‹¤ëª© í¬í•¨) ë˜ëŠ” HUG ì „ì„¸í”¼í•´í™•ì¸ì„œë¥¼ ë°œê¸‰ë°›ì€ ì„ì°¨ì¸ì—ê²ŒëŠ” ëŒ€í•œë³€í˜‘ ë²•ë¥ êµ¬ì¡°ì¬ë‹¨ì„ í†µí•´ ì†Œì†¡ëŒ€ë¦¬ ë²•ë¥ êµ¬ì¡°ë¥¼ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ì„¸í”¼í•´ ê°€êµ¬ì˜ ì†Œë“ì— ë³´ì¦ê¸ˆìœ¼ë¡œ ì£¼íƒì„ ë§¤ìˆ˜í•˜ì—¬ ì†Œìœ ê¶Œì„ ì´ì „ë°›ëŠ” ë°©ë²•ì„ ê³ ë ¤í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° ì§€ê¸‰ëª…ë ¹ ë”°ë¼ ì¤‘ìœ„ì†Œë“ 125%ë¥¼ ì´ˆê³¼í•˜ëŠ” í”¼í•´ìëŠ” ë²•ë¥ êµ¬ì¡°ì¬ë‹¨ì˜ ìˆ˜í–‰ë³€í˜¸ì‚¬ì™€ ë§¤ì¹­í•˜ì—¬ ìˆ˜ì„ë£Œë¥¼ ë˜ëŠ” ë³´ì¦ê¸ˆë°˜í™˜ì†Œì†¡ ë° ê²½ë§¤ë¥¼ í†µí•œ í”¼í•´ì£¼íƒ ê°•ì œì²˜ë¶„ ëŒ€ë¹„ ì‹œê°„ê³¼ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆì§€ë§Œ, ìµœëŒ€ 250ë§Œì›ê¹Œì§€ ì§€ì›í•˜ê³  ìˆìœ¼ë©°, ì¤‘ìœ„ì†Œë“ 125% ì´í•˜ì¸ í”¼í•´ìëŠ” ë²•ë¥ êµ¬ì¡°ê³µë‹¨ìœ¼ë¡œë¶€í„° ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì£¼íƒì˜ ì‹œì„¸ê°€ ë‚®ì„ ê²½ìš°ì—ëŠ” ì†ì‹¤ì´ ë°œìƒí•  ìˆ˜ ìˆìŒì„ ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ë¬´ë£Œì†Œì†¡ì„ ì§€ì›ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. l ë˜ í•œ, ì••ë¥˜ ë˜ëŠ” ê°€ì••ë¥˜ ë“± ê¶Œë¦¬ì œí•œì´ ìˆëŠ” ì£¼íƒì´ë¼ë©´ ë§¤ìˆ˜ ì´í›„ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë‹ˆ, ë²•ë¥  l ì•„ ìš¸ëŸ¬, ì§ì ‘ ë³€í˜¸ì‚¬ ë˜ëŠ” ë²•ë¬´ì‚¬ë¥¼ í†µí•˜ì—¬ ì§‘í–‰ê¶Œì›ì„ í™•ë³´í•˜ì˜€ê±°ë‚˜, ë‚˜í™€ë¡œì†Œì†¡ì„ ì§„í–‰í•˜ì—¬ ì „ë¬¸ê°€ì™€ ìƒì˜í•œ ì´í›„ ëª…ì˜ ì´ì „ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì„ëŒ€ì¸ì˜ ë³´ì¦ê¸ˆ ë¯¸ë°˜í™˜ìœ¼ë¡œ ì¸í•´ ì§‘í–‰ê¶Œì›ì„ í™•ë³´í•œ ê²½ìš°, êµ­í† ë¶€ ì „ì„¸ì‚¬ê¸°í”¼í•´ì(ë‚˜ëª©, ë‹¤ëª© í¬í•¨)ì—ê²ŒëŠ” ì§‘í–‰ê¶Œì› í™•ë³´ë¹„ìš© ì§€ì›ì„ ë¶€ë“ì´í•˜ê²Œ í”¼í•´ì£¼íƒ ë§¤ìˆ˜ë¥¼ ê³ ë¯¼ ì¤‘ì¸ ìƒí™©ì´ë¼ë©´, HUG ì „ì„¸í”¼í•´ì§€ì›ì„¼í„°(ì„œìš¸ ê°•ì„œ) ë˜ëŠ” ì§€ìì²´ í†µí•´ ë³€í˜¸ì‚¬Â·ë²•ë¬´ì‚¬* ìˆ˜ì„ë£Œ ë˜ëŠ” ì¸ì§€Â·ì†¡ë‹¬ë£Œë¥¼ ìµœëŒ€ 140ë§Œì›(ì§€ê¸‰ëª…ë ¹ 40ë§Œì›, ë³´ì¦ê¸ˆâ€¦\"\n",
      "\n",
      "2) [ìš”ì§€] :\n",
      "ì„ì°¨ì¸ì´ ì„ëŒ€ì¸ì„ ìƒëŒ€ë¡œ ë³´ì¦ê¸ˆ ë°˜í™˜ ì²­êµ¬ ì†Œì†¡ì„ ì œê¸°í•  ë•ŒëŠ” ã€Œì†Œì•¡ì‚¬ê±´ì‹¬íŒë²•ã€ì´ ì ìš©ëœë‹¤. ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ëŒë ¤ì£¼ì§€ ëª»í•˜ëŠ” ê²½ìš°, ì„ì°¨ì¸ì€ ë²•ë¥ êµ¬ì¡°ì¬ë‹¨ ë“±ì˜ ì§€ì›ì„ ë°›ì„ ìˆ˜ ìˆìœ¼ë‚˜, ì†Œì†¡ë¹„ìš© ë¶€ë‹´ì´ ì¡´ì¬í•œë‹¤. í”¼í•´ì£¼íƒ ì†Œìœ ê¶Œ ì´ì „ì´ë‚˜ ì§‘í–‰ê¶Œì›ì„ í™•ë³´í•˜ëŠ” ì ˆì°¨ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•˜ë‹¤.\n",
      "\n",
      "3) [ë‹µë³€] :\n",
      "ì§‘ì£¼ì¸ì´ ë³´ì¦ê¸ˆì„ ëŒë ¤ì£¼ì§€ ì•Šìœ¼ë©´, ì„ì°¨ì¸ì€ ì†Œì•¡ì‚¬ê±´ì‹¬íŒë²•ì— ë”°ë¼ ë°”ë¡œ ë³´ì¦ê¸ˆ ë°˜í™˜ ì²­êµ¬ ì†Œì†¡ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ì†Œì†¡ë¹„ìš© ë¶€ë‹´ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë²•ë¥ êµ¬ì¡°ì¬ë‹¨ ë“±ì˜ ë„ì›€ì„ ë°›ê±°ë‚˜ ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œí•©ë‹ˆë‹¤.\n",
      "\n",
      "4) [ì¶”ê°€ë¡œ í™•ì¸í•  ì‚¬ì‹¤] :\n",
      "- í˜„ì¬ ì„ëŒ€ì°¨ ê³„ì•½ì´ ë§Œë£Œë˜ì—ˆë‚˜ìš”?\n",
      "- ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ê±°ì ˆí•˜ëŠ” êµ¬ì²´ì ì¸ ì‚¬ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "- ì„ì°¨ì¸ì´ ì†Œì†¡ë¹„ìš© ì§€ì› ìê²©ì´ ë˜ëŠ”ì§€ í™•ì¸ë˜ì—ˆë‚˜ìš”?\n",
      "- ì„ì°¨ì¸ì€ ì†Œì†¡ì„ ì§„í–‰í•˜ê¸° ì „ì— ë²•ë¥  ìƒë‹´ì„ ë°›ì•˜ë‚˜ìš”?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# =========================\n",
    "# 0) ENV & CLIENT\n",
    "# =========================\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY or not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ .envì— OPENAI_API_KEY / PINECONE_API_KEY ì„¤ì • í•„ìš”\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "INDEX_NAME = \"realestate2\"\n",
    "DEFAULT_NS = \"__default2__\"\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-large\"  # 3072\n",
    "CHAT_MODEL  = \"gpt-4.1-mini\"\n",
    "\n",
    "print(\"âœ… ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(\" - index:\", INDEX_NAME)\n",
    "print(\" - namespace:\", DEFAULT_NS)\n",
    "print(\" - embed:\", EMBED_MODEL, \"| chat:\", CHAT_MODEL)\n",
    "\n",
    "# =========================\n",
    "# 1) PRIORITY MAP\n",
    "# =========================\n",
    "PRIORITY_MAP = {\n",
    "    \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•\": 1,\n",
    "    \"ì‹œí–‰ë ¹\": 2,\n",
    "    \"ì‹œí–‰ê·œì¹™/ëŒ€ë²•ì›ê·œì¹™\": 3,\n",
    "    \"ë¯¼ë²•\": 4,\n",
    "    \"ì‚¬ë¡€/íŒë¡€/í”¼í•´ìƒë‹´\": 50,\n",
    "}\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \"\", (s or \"\").strip())\n",
    "\n",
    "def get_priority_from_md(md: dict) -> int:\n",
    "    if not isinstance(md, dict):\n",
    "        return 50\n",
    "    p = md.get(\"priority\")\n",
    "    if p is not None:\n",
    "        try:\n",
    "            return int(p)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    lt = md.get(\"law_type\") or md.get(\"category\") or \"\"\n",
    "    lt_n = normalize(str(lt))\n",
    "\n",
    "    for k, v in PRIORITY_MAP.items():\n",
    "        if normalize(k) == lt_n:\n",
    "            return v\n",
    "\n",
    "    # ëŠìŠ¨í•œ ë§¤ì¹­\n",
    "    if \"ì£¼íƒì„ëŒ€ì°¨\" in lt_n:\n",
    "        return 1\n",
    "    if \"ì‹œí–‰ë ¹\" in lt_n:\n",
    "        return 2\n",
    "    if \"ì‹œí–‰ê·œì¹™\" in lt_n or \"ëŒ€ë²•ì›ê·œì¹™\" in lt_n:\n",
    "        return 3\n",
    "    if \"ë¯¼ë²•\" in lt_n:\n",
    "        return 4\n",
    "    if \"íŒë¡€\" in lt_n or \"ì‚¬ë¡€\" in lt_n or \"í”¼í•´ìƒë‹´\" in lt_n:\n",
    "        return 50\n",
    "    return 50\n",
    "\n",
    "# =========================\n",
    "# 2) Embedding\n",
    "# =========================\n",
    "def embed(text: str) -> list[float]:\n",
    "    return client.embeddings.create(model=EMBED_MODEL, input=text).data[0].embedding\n",
    "\n",
    "# =========================\n",
    "# 3) Query intent -> quota\n",
    "# =========================\n",
    "def detect_intent(question: str) -> str:\n",
    "    q = question.strip()\n",
    "\n",
    "    # ì›ë¬¸/ì¡°ë¬¸ ê·¸ëŒ€ë¡œ ì¶œë ¥ ì˜ë„\n",
    "    if re.search(r\"(ì›ë¬¸|ê·¸ëŒ€ë¡œ|ì „ë¶€|ì „ì²´|ì¡°ë¬¸|ì œ\\s*\\d+\\s*ì¡°|ì œ\\s*\\d+\\s*í•­|ì œ\\s*\\d+\\s*í˜¸)\", q):\n",
    "        return \"verbatim\"\n",
    "\n",
    "    # ì‚¬ë¡€/íŒë¡€ ìœ„ì£¼\n",
    "    if re.search(r\"(ì‚¬ë¡€|íŒë¡€|íŒê²°|ê²°ì •|ìœ ì‚¬|ë¹„ìŠ·í•œ|ë¹„êµ)\", q):\n",
    "        return \"case\"\n",
    "\n",
    "    # ì ˆì°¨/ë°©ë²• ìœ„ì£¼ (ì‹œí–‰ë ¹/ê·œì¹™ì´ ë„ì›€ ë˜ëŠ” ê²½ìš° ë§ìŒ)\n",
    "    if re.search(r\"(ì–´ë–»ê²Œ|ì ˆì°¨|ë°©ë²•|ì‹ ì²­|ìš”ê±´|ì„œë¥˜|ê°€ëŠ¥|í• \\s*ìˆ˜|í•´ì•¼\\s*í•´)\", q):\n",
    "        return \"procedure\"\n",
    "\n",
    "    return \"general\"\n",
    "\n",
    "def quota_for_intent(intent: str) -> dict:\n",
    "    # priority: 1(ë²•) 2(ì‹œí–‰ë ¹) 3(ê·œì¹™) 4(ë¯¼ë²•) 50(ì‚¬ë¡€/íŒë¡€)\n",
    "    if intent == \"verbatim\":\n",
    "        return {1: 7, 2: 2, 3: 1, 4: 0, 50: 0}\n",
    "    if intent == \"case\":\n",
    "        return {1: 2, 2: 1, 3: 1, 4: 0, 50: 6}\n",
    "    if intent == \"procedure\":\n",
    "        return {1: 3, 2: 3, 3: 3, 4: 1, 50: 0}\n",
    "    return {1: 4, 2: 2, 3: 2, 4: 1, 50: 1}\n",
    "\n",
    "# =========================\n",
    "# 4) Keyword boost rerank\n",
    "# =========================\n",
    "STOPWORDS = {\n",
    "    \"ê·¸ë¦¬ê³ \", \"ë˜ëŠ”\", \"ê·¸ë˜ì„œ\", \"ê·¸ëŸ¬ë©´\", \"í•˜ì§€ë§Œ\", \"ë•Œë¬¸ì—\", \"ëŒ€í•œ\", \"ê´€ë ¨\", \"ê²½ìš°\", \"ì‚¬ì‹¤\",\n",
    "    \"ìˆëŠ”\", \"ì—†ëŠ”\", \"í•©ë‹ˆë‹¤\", \"í•´ìš”\", \"ë˜ë‚˜ìš”\", \"ì¸ê°€ìš”\", \"ì–´ë–»ê²Œ\", \"ë¬´ì—‡\", \"ì™œ\", \"ì–¸ì œ\",\n",
    "    \"ìˆë‹¤\", \"ì—†ë‹¤\", \"ì´ë‹¤\", \"ìˆ˜\", \"ê²ƒ\", \"ì¢€\", \"ì œê°€\", \"ì €ëŠ”\", \"ì„ì°¨ì¸\", \"ì„ëŒ€ì¸\"\n",
    "}\n",
    "\n",
    "def extract_keywords_ko(text: str, max_kw: int = 8) -> list[str]:\n",
    "    # ì•„ì£¼ ë‹¨ìˆœí•œ í† í°í™”: í•œê¸€/ìˆ«ì ì—°ì† 2ê¸€ì ì´ìƒ\n",
    "    toks = re.findall(r\"[ê°€-í£0-9]{2,}\", text)\n",
    "    uniq = []\n",
    "    for t in toks:\n",
    "        if t in STOPWORDS:\n",
    "            continue\n",
    "        if t not in uniq:\n",
    "            uniq.append(t)\n",
    "    return uniq[:max_kw]\n",
    "\n",
    "def keyword_boost_score(question: str, evidence_text: str) -> float:\n",
    "    # ì§ˆë¬¸ì˜ í‚¤ì›Œë“œê°€ evidenceì— í¬í•¨ë˜ë©´ ê°€ì¤‘ì¹˜\n",
    "    kws = extract_keywords_ko(question, max_kw=8)\n",
    "    if not kws:\n",
    "        return 0.0\n",
    "    hit = 0\n",
    "    et = evidence_text\n",
    "    for k in kws:\n",
    "        if k in et:\n",
    "            hit += 1\n",
    "    # ë„ˆë¬´ ê³¼í•˜ê²Œ ì•ˆ ì˜¬ë¦¬ë„ë¡ 0~0.12 ì‚¬ì´\n",
    "    return min(0.12, hit * 0.03)\n",
    "\n",
    "# =========================\n",
    "# 5) Retrieve + Priority + Keyword rerank + Quota\n",
    "# =========================\n",
    "def fetch_context_blocks(\n",
    "    query: str,\n",
    "    namespace: str = DEFAULT_NS,\n",
    "    top_k: int = 60,\n",
    "    max_blocks: int = 10,\n",
    "    max_chars_per_block: int = 900,\n",
    "):\n",
    "    intent = detect_intent(query)\n",
    "    per_priority_quota = quota_for_intent(intent)\n",
    "\n",
    "    qvec = embed(query)\n",
    "    res = index.query(\n",
    "        vector=qvec,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace,\n",
    "    )\n",
    "\n",
    "    items = []\n",
    "    for m in (res.matches or []):\n",
    "        md = m.metadata or {}\n",
    "        text = md.get(\"text\") or \"\"\n",
    "        text = re.sub(r\"\\s+\", \" \", str(text)).strip()\n",
    "        if len(text) < 30:\n",
    "            continue\n",
    "\n",
    "        p = get_priority_from_md(md)\n",
    "        score = float(getattr(m, \"score\", 0.0))\n",
    "\n",
    "        # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°(ì»¨í…ìŠ¤íŠ¸ í­ë°œ ë°©ì§€)\n",
    "        if max_chars_per_block and len(text) > max_chars_per_block:\n",
    "            text = text[:max_chars_per_block].rstrip() + \"â€¦\"\n",
    "\n",
    "        # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì¶”ê°€\n",
    "        boost = keyword_boost_score(query, text)\n",
    "        adj_score = score + boost\n",
    "\n",
    "        items.append({\n",
    "            \"id\": getattr(m, \"id\", None),\n",
    "            \"score\": score,\n",
    "            \"adj_score\": adj_score,\n",
    "            \"boost\": boost,\n",
    "            \"priority\": p,\n",
    "            \"law_type\": md.get(\"law_type\") or md.get(\"category\") or \"\",\n",
    "            \"article\": md.get(\"article\"),\n",
    "            \"chunk_id\": md.get(\"chunk_id\"),\n",
    "            \"page\": md.get(\"page\") or md.get(\"pageno\") or md.get(\"page_no\"),\n",
    "            \"source\": md.get(\"source\") or \"unknown\",\n",
    "            \"text\": text,\n",
    "        })\n",
    "\n",
    "    if not items:\n",
    "        return [], intent, per_priority_quota\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±°(í…ìŠ¤íŠ¸ ê¸°ì¤€)\n",
    "    seen = set()\n",
    "    dedup = []\n",
    "    for it in items:\n",
    "        key = re.sub(r\"\\s+\", \"\", it[\"text\"])\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        dedup.append(it)\n",
    "\n",
    "    # ì •ë ¬: priority ìš°ì„  -> (ê°€ì¤‘ì¹˜ ì ìš© ì ìˆ˜) ë‚´ë¦¼ì°¨ìˆœ\n",
    "    dedup.sort(key=lambda x: (x[\"priority\"], -x[\"adj_score\"]))\n",
    "\n",
    "    # (source, article) ì¤‘ë³µ ì–µì œ\n",
    "    sa_seen = set()\n",
    "    sa_filtered = []\n",
    "    for it in dedup:\n",
    "        sa = (it[\"source\"], it.get(\"article\"))\n",
    "        if it.get(\"article\"):\n",
    "            if sa in sa_seen:\n",
    "                continue\n",
    "            sa_seen.add(sa)\n",
    "        sa_filtered.append(it)\n",
    "\n",
    "    # quotaë¡œ ì„ íƒ\n",
    "    selected = []\n",
    "    counts = {k: 0 for k in per_priority_quota.keys()}\n",
    "    for it in sa_filtered:\n",
    "        p = it[\"priority\"]\n",
    "        if p not in per_priority_quota:\n",
    "            continue\n",
    "        if per_priority_quota[p] <= 0:\n",
    "            continue\n",
    "        if counts[p] >= per_priority_quota[p]:\n",
    "            continue\n",
    "        selected.append(it)\n",
    "        counts[p] += 1\n",
    "        if len(selected) >= max_blocks:\n",
    "            break\n",
    "\n",
    "    # ë¶€ì¡±í•˜ë©´ ë‚¨ì€ ê±¸ ì±„ì›€\n",
    "    if len(selected) < max_blocks:\n",
    "        sel_keys = set(re.sub(r\"\\s+\", \"\", x[\"text\"]) for x in selected)\n",
    "        for it in sa_filtered:\n",
    "            if len(selected) >= max_blocks:\n",
    "                break\n",
    "            k = re.sub(r\"\\s+\", \"\", it[\"text\"])\n",
    "            if k in sel_keys:\n",
    "                continue\n",
    "            selected.append(it)\n",
    "            sel_keys.add(k)\n",
    "\n",
    "    return selected[:max_blocks], intent, per_priority_quota\n",
    "\n",
    "# =========================\n",
    "# 6) LLM Prompt (LLMì€ ìš”ì§€/ë‹µë³€ë§Œ ì‘ì„±)\n",
    "# =========================\n",
    "SYSTEM = \"\"\"ë„ˆëŠ” 'ë¶€ë™ì‚°/ì„ëŒ€ì°¨ ë²•ë ¹ ê·¼ê±° ì±—ë´‡'ì´ë‹¤.\n",
    "\n",
    "ì ˆëŒ€ ê·œì¹™:\n",
    "- ë„ˆì—ê²Œ ì£¼ì–´ì§€ëŠ” [ê·¼ê±° ìš”ì•½ìš© TEXT]ì— í¬í•¨ëœ ë‚´ìš©ë§Œ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œë‹¤.\n",
    "- ê·¼ê±°ì— ì—†ëŠ” ë²•ë¦¬/ì ˆì°¨/íŒë¡€/ì¶”ì •/ì¼ë°˜ë¡ ì„ ì¶”ê°€í•˜ì§€ ë§ˆë¼.\n",
    "- ê·¼ê±°ë§Œìœ¼ë¡œ ë‹¨ì •ì´ ì–´ë µë‹¤ë©´ ë°˜ë“œì‹œ 'ê·¼ê±° ë¶€ì¡±' ë˜ëŠ” 'ì¶”ê°€ í™•ì¸ í•„ìš”'ë¼ê³  ë§í•˜ë¼.\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì§€ì¼œë¼):\n",
    "1) [ìš”ì§€] : ê·¼ê±° ë‚´ìš©ì˜ ì˜ë¯¸ë¥¼ ì¤‘ë³µ ì—†ì´ ì •ë¦¬(ìƒˆ ì •ë³´ ê¸ˆì§€)\n",
    "2) [ë‹µë³€] : ì§ˆë¬¸ì— ëŒ€í•´ ìš”ì§€ë¥¼ ì‰¬ìš´ ë§ë¡œ ì„¤ëª…(ìƒˆ ì •ë³´ ê¸ˆì§€)\n",
    "3) [ì¶”ê°€ë¡œ í™•ì¸í•  ì‚¬ì‹¤] : í•„ìš”í•œ ì§ˆë¬¸ 2~5ê°œ\n",
    "\"\"\"\n",
    "\n",
    "def format_evidence_block(blocks: list[dict]) -> str:\n",
    "    # âœ… [ê·¼ê±° TEXT]ëŠ” ì½”ë“œê°€ ê·¸ëŒ€ë¡œ ì¶œë ¥ (LLMì´ ì†ëŒ€ì§€ ì•ŠìŒ)\n",
    "    lines = []\n",
    "    for b in blocks:\n",
    "        page = b.get(\"page\")\n",
    "        page_str = f\", page={page}\" if page is not None else \"\"\n",
    "        lines.append(\n",
    "            f'- (priority={b[\"priority\"]}, law_type={b[\"law_type\"]}, source={b[\"source\"]}'\n",
    "            f'{page_str}, article={b.get(\"article\")}, chunk={b.get(\"chunk_id\")}, '\n",
    "            f'score={b[\"score\"]:.3f}, boost={b[\"boost\"]:.2f})\\n'\n",
    "            f'  \"{b[\"text\"]}\"'\n",
    "        )\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def law_chat(question: str, namespace: str = DEFAULT_NS):\n",
    "    blocks, intent, quota = fetch_context_blocks(\n",
    "        question,\n",
    "        namespace=namespace,\n",
    "        top_k=60,\n",
    "        max_blocks=10,\n",
    "        max_chars_per_block=900,\n",
    "    )\n",
    "    if not blocks:\n",
    "        return \"ê·¼ê±° ë¶€ì¡±\"\n",
    "\n",
    "    evidence = format_evidence_block(blocks)\n",
    "\n",
    "    # âœ… LLMì—ëŠ” evidenceë¥¼ \"ì¬ì¸ìš©\"ì‹œí‚¤ì§€ ì•Šê³ , ìš”ì§€/ë‹µë³€ë§Œ ì“°ê²Œ í•œë‹¤.\n",
    "    # (ê·¸ë˜ë„ ê·¼ê±° ë°– ë§ ê¸ˆì§€ ë£° ìœ ì§€)\n",
    "    prompt = f\"\"\"[ì§ˆë¬¸]\n",
    "{question}\n",
    "\n",
    "[ê·¼ê±° ìš”ì•½ìš© TEXT]\n",
    "{evidence}\n",
    "\n",
    "(ì£¼ì˜) ìœ„ TEXTë¥¼ ê·¸ëŒ€ë¡œ ì¬ì¸ìš©í•˜ê±°ë‚˜ ìƒˆë¡œ ë§Œë“¤ì–´ ì“°ì§€ ë§ê³ , ì˜¤ì§ ìš”ì§€/ë‹µë³€/ì¶”ê°€í™•ì¸ë§Œ ì‘ì„±í•´ë¼.\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    body = resp.choices[0].message.content.strip()\n",
    "\n",
    "    # ìµœì¢… ì¶œë ¥: âœ… ê·¼ê±° TEXTëŠ” ì½”ë“œê°€ ê·¸ëŒ€ë¡œ ë¶™ì„\n",
    "    header = f\"[ì˜ë„ë¶„ë¥˜] {intent} | [quota] {quota}\\n\"\n",
    "    out = (\n",
    "        header\n",
    "        + \"1) [ê·¼ê±° TEXT]\\n\"\n",
    "        + evidence\n",
    "        + \"\\n\\n\"\n",
    "        + body\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# 7) Interactive loop\n",
    "# =========================\n",
    "def run_chat(namespace: str = DEFAULT_NS):\n",
    "    print(\"\\n=== ğŸ  RealEstate RAG Chat (ê·¼ê±° TEXTëŠ” ì½”ë“œê°€ ì§ì ‘ ì¶œë ¥) ===\")\n",
    "    print(\"ëª…ë ¹ì–´: /exit ì¢…ë£Œ | /help ë„ì›€ë§ | /ns í˜„ì¬ namespace í‘œì‹œ\")\n",
    "    print(\"ê·¸ëƒ¥ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ê·¼ê±° TEXT + (ìš”ì§€/ë‹µë³€/ì¶”ê°€í™•ì¸)ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            q = input(\"You> \").strip()\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            print(\"\\nì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        if not q:\n",
    "            continue\n",
    "\n",
    "        if q.lower() in [\"/exit\", \"exit\", \"quit\", \"/q\"]:\n",
    "            print(\"ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        if q.lower() == \"/help\":\n",
    "            print(\" - ì§ˆë¬¸ì„ ê·¸ëƒ¥ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "            print(\" - /exit : ì¢…ë£Œ\")\n",
    "            print(\" - /ns   : í˜„ì¬ namespace í™•ì¸\")\n",
    "            continue\n",
    "\n",
    "        if q.lower() == \"/ns\":\n",
    "            print(f\"(namespace = {namespace})\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ans = law_chat(q, namespace=namespace)\n",
    "            print(\"\\nBot>\\n\" + ans + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[ì—ëŸ¬] {type(e).__name__}: {e}\\n\")\n",
    "\n",
    "# âœ… ì‹¤í–‰\n",
    "run_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8309ff-7d7e-40c0-95f6-39fb2c40c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6283629-7b58-4e1d-8bdf-6e5c47d7edca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
