{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abcf1220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79cb06",
   "metadata": {},
   "source": [
    "# 1. í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73ad000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13116\\865369951.py:41: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import answer_relevancy as AnswerRelevancy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… patched AnswerRelevancy similarity (pure python)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13116\\865369951.py:75: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  ragas_llm_upstage = LangchainLLMWrapper(ChatUpstage(model=\"solar-pro2\", temperature=0))\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, gc, math\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "# -----------------------------\n",
    "# 0) RAG pipeline\n",
    "# -----------------------------\n",
    "import sys\n",
    "MODULES_PATH = os.path.join(os.getcwd(), \"chatbot_app\", \"modules\")\n",
    "sys.path.append(MODULES_PATH)\n",
    "sys.path.append(os.getcwd())\n",
    "from chatbot_app.modules.rag_module import create_pipeline\n",
    "try:\n",
    "    from chatbot_app.modules.rag_module import RAGConfig\n",
    "except Exception:\n",
    "    RAGConfig = None\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Metrics (ragas ë²„ì „ ì°¨ì´ ëŒ€ì‘)\n",
    "# -----------------------------\n",
    "try:\n",
    "    from ragas.metrics._context_precision import ContextPrecision\n",
    "except Exception:\n",
    "    from ragas.metrics import context_precision as ContextPrecision\n",
    "\n",
    "try:\n",
    "    from ragas.metrics._context_recall import ContextRecall\n",
    "except Exception:\n",
    "    from ragas.metrics import context_recall as ContextRecall\n",
    "\n",
    "try:\n",
    "    from ragas.metrics._answer_relevancy import AnswerRelevancy\n",
    "except Exception:\n",
    "    from ragas.metrics import answer_relevancy as AnswerRelevancy\n",
    "\n",
    "try:\n",
    "    from ragas.metrics._faithfulness import Faithfulness\n",
    "except Exception:\n",
    "    from ragas.metrics import faithfulness as Faithfulness\n",
    "\n",
    "def _metric_instance(m):\n",
    "    return m() if callable(m) else m\n",
    "\n",
    "CP_METRIC = _metric_instance(ContextPrecision)\n",
    "CR_METRIC = _metric_instance(ContextRecall)\n",
    "AR_METRIC = _metric_instance(AnswerRelevancy)\n",
    "F_METRIC  = _metric_instance(Faithfulness)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) LLM/Embeddings\n",
    "#    - CP/CR: OpenAI (llm_factory)\n",
    "#    - AR/F : Upstage (solar-pro2)\n",
    "#    - Embeddings: UpstageEmbeddings(solar-embedding-1-large)\n",
    "# -----------------------------\n",
    "from openai import OpenAI\n",
    "from ragas.llms import llm_factory\n",
    "from langchain_upstage import ChatUpstage, UpstageEmbeddings\n",
    "\n",
    "openai_client = OpenAI()\n",
    "ragas_llm_openai = llm_factory(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    provider=\"openai\",\n",
    "    client=openai_client,\n",
    ")\n",
    "\n",
    "try:\n",
    "    from ragas.llms import LangchainLLMWrapper\n",
    "    ragas_llm_upstage = LangchainLLMWrapper(ChatUpstage(model=\"solar-pro2\", temperature=0))\n",
    "except Exception:\n",
    "    ragas_llm_upstage = ChatUpstage(model=\"solar-pro2\", temperature=0)\n",
    "\n",
    "ragas_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# Upstage provider ì œì•½: strictness=1 ê°•ì œ(ARì—ì„œ n=1 ìš”êµ¬)\n",
    "if hasattr(AR_METRIC, \"strictness\"):\n",
    "    AR_METRIC.strictness = 1\n",
    "\n",
    "# ì‹¤í–‰ ì•ˆì • ì„¤ì •\n",
    "rc = RunConfig(max_workers=1, timeout=180)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) AnswerRelevancy ì„¸ê·¸í´íŠ¸ íšŒí”¼ íŒ¨ì¹˜\n",
    "# -----------------------------\n",
    "try:\n",
    "    import ragas.metrics._answer_relevance as ar_mod\n",
    "\n",
    "    def _cos_sim(u, v, eps=1e-8):\n",
    "        su = 0.0\n",
    "        sv = 0.0\n",
    "        s  = 0.0\n",
    "        for a, b in zip(u, v):\n",
    "            af = float(a); bf = float(b)\n",
    "            s  += af * bf\n",
    "            su += af * af\n",
    "            sv += bf * bf\n",
    "        return s / (math.sqrt(su) * math.sqrt(sv) + eps)\n",
    "\n",
    "    def safe_calculate_similarity(self, question: str, generated_questions: list[str]):\n",
    "        emb = None\n",
    "        for name in [\"embeddings\", \"_embeddings\", \"embedding\", \"_embedding\"]:\n",
    "            if hasattr(self, name):\n",
    "                emb = getattr(self, name)\n",
    "                if emb is not None:\n",
    "                    break\n",
    "        if emb is None:\n",
    "            raise RuntimeError(\"AnswerRelevancy metricì— embeddingsê°€ ì„¸íŒ…ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        def embed_one(text: str):\n",
    "            if hasattr(emb, \"embed_query\"):\n",
    "                return emb.embed_query(text)\n",
    "            if hasattr(emb, \"embed_documents\"):\n",
    "                return emb.embed_documents([text])[0]\n",
    "            raise RuntimeError(\"embeddings ê°ì²´ì— embed_query/embed_documentsê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        def embed_many(texts: list[str]):\n",
    "            if len(texts) == 0:\n",
    "                return []\n",
    "            if hasattr(emb, \"embed_documents\"):\n",
    "                return emb.embed_documents(texts)\n",
    "            if hasattr(emb, \"embed_query\"):\n",
    "                return [emb.embed_query(t) for t in texts]\n",
    "            raise RuntimeError(\"embeddings ê°ì²´ì— embed_query/embed_documentsê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        qv  = embed_one(question)\n",
    "        gvs = embed_many(generated_questions)\n",
    "        if not gvs:\n",
    "            return np.array([0.0], dtype=\"float32\")\n",
    "        sims = [_cos_sim(qv, gv) for gv in gvs]\n",
    "        return np.array(sims, dtype=\"float32\")\n",
    "\n",
    "    # í´ë˜ìŠ¤ ë©”ì„œë“œ ë®ì–´ì“°ê¸°\n",
    "    if hasattr(ar_mod, \"ResponseRelevancy\"):\n",
    "        ar_mod.ResponseRelevancy.calculate_similarity = safe_calculate_similarity\n",
    "    if hasattr(ar_mod, \"AnswerRelevancy\"):\n",
    "        ar_mod.AnswerRelevancy.calculate_similarity = safe_calculate_similarity\n",
    "\n",
    "    if hasattr(ar_mod, \"calculate_similarity\"):\n",
    "        ar_mod.calculate_similarity.__code__ = _cos_sim.__code__\n",
    "        ar_mod.calculate_similarity.__defaults__ = _cos_sim.__defaults__\n",
    "\n",
    "    if hasattr(AR_METRIC, \"strictness\"):\n",
    "        AR_METRIC.strictness = 1\n",
    "\n",
    "    print(\"âœ… patched AnswerRelevancy similarity (pure python)\")\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ AnswerRelevancy patch skipped:\", repr(e))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Utils\n",
    "# -----------------------------\n",
    "OUT_DIR = \"./data/RAGAS\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def cleanup_memory():\n",
    "    gc.collect()\n",
    "\n",
    "def validate_data(rows, required_fields):\n",
    "    issues = []\n",
    "    for i, r in enumerate(rows):\n",
    "        for field in required_fields:\n",
    "            if field not in r:\n",
    "                issues.append(f\"Row {i}: missing field '{field}'\")\n",
    "            elif r[field] is None:\n",
    "                issues.append(f\"Row {i}: field '{field}' is None\")\n",
    "            elif field in [\"question\", \"answer\"] and not str(r[field]).strip():\n",
    "                issues.append(f\"Row {i}: field '{field}' is empty\")\n",
    "    if issues:\n",
    "        print(\"âš ï¸ Data validation issues:\")\n",
    "        for x in issues[:10]:\n",
    "            print(\" -\", x)\n",
    "    else:\n",
    "        print(\"âœ… Data validation passed\")\n",
    "    return len(issues) == 0\n",
    "\n",
    "def clip_rows_cp(rows, *, max_ctx=3, max_chars=600):\n",
    "    clipped = []\n",
    "    for r in rows:\n",
    "        rr = dict(r)\n",
    "        ctx = rr.get(\"contexts\", []) or []\n",
    "        ctx = [c for c in ctx if c is not None]\n",
    "        rr[\"contexts\"] = [str(c)[:max_chars] for c in ctx[:max_ctx]]\n",
    "        clipped.append(rr)\n",
    "    return clipped\n",
    "\n",
    "def clip_rows_cr(rows, *, max_ctx=2, max_chars=400, clip_reference_chars=600, clip_answer_chars=600):  # 200/300/300\n",
    "    clipped = []\n",
    "    for r in rows:\n",
    "        rr = dict(r)\n",
    "        ctx = rr.get(\"contexts\", []) or []\n",
    "        ctx = [c for c in ctx if c is not None]\n",
    "        rr[\"contexts\"] = [str(c)[:max_chars] for c in ctx[:max_ctx]]\n",
    "        if clip_reference_chars is not None and rr.get(\"reference\"):\n",
    "            rr[\"reference\"] = str(rr[\"reference\"])[:clip_reference_chars]\n",
    "        if clip_answer_chars is not None and rr.get(\"answer\"):\n",
    "            rr[\"answer\"] = str(rr[\"answer\"])[:clip_answer_chars]\n",
    "        clipped.append(rr)\n",
    "    return clipped\n",
    "\n",
    "def clip_rows_af(rows, *, max_ctx=4, max_chars=1200, clip_answer_chars=700):\n",
    "    clipped = []\n",
    "    for r in rows:\n",
    "        rr = dict(r)\n",
    "        ctx = rr.get(\"contexts\", []) or []\n",
    "        ctx = [c for c in ctx if c is not None]\n",
    "        rr[\"contexts\"] = [str(c)[:max_chars] for c in ctx[:max_ctx]]\n",
    "        if rr.get(\"answer\"):\n",
    "            rr[\"answer\"] = str(rr[\"answer\"])[:clip_answer_chars]\n",
    "        clipped.append(rr)\n",
    "    return clipped\n",
    "\n",
    "# -----------------------------\n",
    "# 5) DOCX -> items\n",
    "# -----------------------------\n",
    "from docx import Document as DocxDocument\n",
    "DOCX_PATH = \"./data/RAGAS/RAGAS_ì§ˆë¬¸_10ê°œ_ì •ë¦¬ë³¸.docx\"\n",
    "\n",
    "def parse_ragas_docx(doc_path: str) -> List[Dict[str, Any]]:\n",
    "    doc = DocxDocument(doc_path)\n",
    "    paras = [p.text.strip() for p in doc.paragraphs if p.text and p.text.strip()]\n",
    "    text = \"\\n\".join(paras)\n",
    "    blocks = re.split(r\"\\n(?=\\d+\\.\\s)\", text)\n",
    "\n",
    "    items = []\n",
    "    for b in blocks:\n",
    "        b = b.strip()\n",
    "        if not re.match(r\"^\\d+\\.\\s\", b):\n",
    "            continue\n",
    "        parts = b.split(\"âœ”ï¸ ëª¨ë²”ë‹µì•ˆ\", 1)\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        q_part = re.sub(r\"^\\d+\\.\\s*\", \"\", parts[0].strip())\n",
    "        a_part = parts[1].strip()\n",
    "        items.append({\"question\": q_part.strip(), \"ground_truth\": a_part.strip()})\n",
    "\n",
    "    if len(items) == 0:\n",
    "        raise ValueError(\"docxì—ì„œ ë¬¸í•­ì„ 1ê°œë„ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return items\n",
    "\n",
    "# -----------------------------\n",
    "# 6) RAG ì‹¤í–‰ -> rows (1íšŒ)\n",
    "# -----------------------------\n",
    "def run_rag_and_build_rows(items: List[Dict[str, Any]], pipeline) -> List[Dict[str, Any]]:\n",
    "    rows = []\n",
    "    for i, ex in enumerate(items, start=1):\n",
    "        q = ex[\"question\"]\n",
    "        gt = ex.get(\"ground_truth\", \"\")\n",
    "\n",
    "        MAX_QUERY_CHARS = 2000\n",
    "        q_for_retrieval = q if len(q) <= MAX_QUERY_CHARS else q[:MAX_QUERY_CHARS]\n",
    "\n",
    "        try:\n",
    "            trace = pipeline.answer_with_trace(q_for_retrieval, skip_normalization=False)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Q{i} retrieval failed:\", repr(e))\n",
    "            trace = {\"answer\": \"\", \"docs\": [], \"normalized_query\": \"\"}\n",
    "\n",
    "        answer = trace.get(\"answer\", \"\") or \"\"\n",
    "        docs = trace.get(\"docs\", []) or []\n",
    "\n",
    "        contexts = []\n",
    "        for d in docs:\n",
    "            try:\n",
    "                contexts.append(d.page_content)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        rows.append({\n",
    "            \"id\": i,\n",
    "            \"question\": q,\n",
    "            \"answer\": answer if answer else \"ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\",\n",
    "            \"contexts\": contexts,\n",
    "            \"reference\": gt,\n",
    "            \"ground_truths\": [gt],\n",
    "            \"normalized_query\": trace.get(\"normalized_query\", \"\"),\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def to_dataset(rows: List[Dict[str, Any]]) -> Dataset:\n",
    "    return Dataset.from_list([{\n",
    "        \"question\": r[\"question\"],\n",
    "        \"answer\": r[\"answer\"],\n",
    "        \"contexts\": r.get(\"contexts\", []),\n",
    "        \"reference\": r.get(\"reference\", \"\"),\n",
    "    } for r in rows])\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Main: 1 run -> total table\n",
    "# -----------------------------\n",
    "def run_once_total_table(\n",
    "    cfg=None,\n",
    "    out_csv: str = os.path.join(OUT_DIR, \"ragas_total_score_table.csv\"),\n",
    "):\n",
    "    items = parse_ragas_docx(DOCX_PATH)\n",
    "    print(\"âœ… items loaded:\", len(items))\n",
    "\n",
    "    # pipeline ìƒì„±\n",
    "    if cfg is not None:\n",
    "        pipeline = create_pipeline(config=cfg)\n",
    "    else:\n",
    "        pipeline = create_pipeline()\n",
    "\n",
    "    rows_local = run_rag_and_build_rows(items, pipeline)\n",
    "    validate_data(rows_local, required_fields=[\"question\", \"answer\", \"contexts\"])\n",
    "\n",
    "    # ì§€í‘œë³„ í´ë¦½\n",
    "    rows_cp = clip_rows_cp(rows_local, max_ctx=3, max_chars=600)\n",
    "    rows_cr = clip_rows_cr(rows_local, max_ctx=2, max_chars=200, clip_reference_chars=300, clip_answer_chars=300)\n",
    "    rows_af = clip_rows_af(rows_local, max_ctx=4, max_chars=1200, clip_answer_chars=700)\n",
    "\n",
    "    ds_cp = to_dataset(rows_cp)\n",
    "    ds_cr = to_dataset(rows_cr)\n",
    "    ds_af = to_dataset(rows_af)\n",
    "\n",
    "    # CP (OpenAI)\n",
    "    res_cp = evaluate(\n",
    "        dataset=ds_cp,\n",
    "        metrics=[CP_METRIC],\n",
    "        llm=ragas_llm_openai,\n",
    "        embeddings=ragas_embeddings,\n",
    "        run_config=rc,\n",
    "        show_progress=True,\n",
    "        raise_exceptions=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "    df_cp = res_cp.to_pandas()\n",
    "    if \"id\" not in df_cp.columns:\n",
    "        df_cp[\"id\"] = range(1, len(df_cp) + 1)\n",
    "\n",
    "    # CR (OpenAI)\n",
    "    res_cr = evaluate(\n",
    "        dataset=ds_cr,\n",
    "        metrics=[CR_METRIC],\n",
    "        llm=ragas_llm_openai,\n",
    "        embeddings=ragas_embeddings,\n",
    "        run_config=rc,\n",
    "        show_progress=True,\n",
    "        raise_exceptions=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "    df_cr = res_cr.to_pandas()\n",
    "    if \"id\" not in df_cr.columns:\n",
    "        df_cr[\"id\"] = range(1, len(df_cr) + 1)\n",
    "\n",
    "    # AR/F (Upstage)\n",
    "    if hasattr(AR_METRIC, \"strictness\"):\n",
    "        AR_METRIC.strictness = 1\n",
    "\n",
    "    res_af = evaluate(\n",
    "        dataset=ds_af,\n",
    "        metrics=[AR_METRIC, F_METRIC],\n",
    "        llm=ragas_llm_upstage,\n",
    "        embeddings=ragas_embeddings,\n",
    "        run_config=rc,\n",
    "        show_progress=True,\n",
    "        raise_exceptions=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "    df_af = res_af.to_pandas()\n",
    "    if \"id\" not in df_af.columns:\n",
    "        df_af[\"id\"] = range(1, len(df_af) + 1)\n",
    "\n",
    "    # í†µí•© í…Œì´ë¸”\n",
    "    merged = (\n",
    "        df_cp[[\"id\", \"context_precision\"]]\n",
    "        .merge(df_cr[[\"id\", \"context_recall\"]], on=\"id\", how=\"inner\")\n",
    "        .merge(df_af[[\"id\", \"answer_relevancy\", \"faithfulness\"]], on=\"id\", how=\"inner\")\n",
    "        .sort_values(\"id\")\n",
    "    )\n",
    "\n",
    "    merged = merged.rename(columns={\n",
    "        \"context_precision\": \"context-precision\",\n",
    "        \"context_recall\": \"context-recall\",\n",
    "        \"answer_relevancy\": \"answer-relevancy\",\n",
    "        \"faithfulness\": \"faithfulness\",\n",
    "    })\n",
    "\n",
    "    score_cols = [\"context-precision\", \"context-recall\", \"answer-relevancy\", \"faithfulness\"]\n",
    "    for c in score_cols:\n",
    "        merged[c] = pd.to_numeric(merged[c], errors=\"coerce\")\n",
    "\n",
    "    # Ri = 0.4*CP + 0.6*CR (retrieval integrated score)\n",
    "    merged[\"Ri\"] = 0.4 * merged[\"context-precision\"] + 0.6 * merged[\"context-recall\"]\n",
    "\n",
    "    # ì†Œìˆ˜ì  2ìë¦¬ ê³ ì • (í–‰ë“¤ë„ 2ìë¦¬)\n",
    "    merged[score_cols + [\"Ri\"]] = merged[score_cols + [\"Ri\"]].round(2)\n",
    "\n",
    "    # mean í–‰(2ìë¦¬)\n",
    "    mean_row = {\"id\": \"mean\"}\n",
    "    for c in score_cols + [\"Ri\"]:\n",
    "        mean_row[c] = round(float(merged[c].mean(skipna=True)), 2)\n",
    "\n",
    "    out_df = pd.concat([merged, pd.DataFrame([mean_row])], ignore_index=True).set_index(\"id\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    out_df.to_csv(out_csv, encoding=\"utf-8\")\n",
    "    print(\"âœ… saved:\", out_csv)\n",
    "\n",
    "    cleanup_memory()\n",
    "    return out_df, out_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2210c3d",
   "metadata": {},
   "source": [
    "# ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ed63fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:42:02,627 - chatbot_app.modules.rag_module - INFO - ğŸ”— Pinecone 3ì¤‘ ì¸ë±ìŠ¤ ì—°ê²° ì¤‘...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… items loaded: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:42:05,340 - chatbot_app.modules.rag_module - INFO - âœ… [Law / Rule / Case] 3ê°œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "2026-02-06 14:42:05,385 - chatbot_app.modules.rag_module - INFO - â„¹ï¸ SimpleTokenizer ì‚¬ìš© (BM25)\n",
      "2026-02-06 14:42:06,587 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:06,602 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©(í™•ì •ì¼ìë¶€ ë‚´ìš©)ì´ ì¤‘ìš”í•œê°€ìš”?  \n",
      "\n",
      "[ë³€ê²½ëœ ì§ˆë¬¸]  \n",
      "ì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡)Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©(í™•ì •ì¼ìë¶€ ë‚´ìš©)ì´ ì¤‘ìš”í•œê°€ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'í™•ì •ì¼ìë¶€ ë‚´ìš©'ì€ ìš©ì–´ ì‚¬ì „ì— ì—†ëŠ” í‘œí˜„ì´ë¯€ë¡œ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¶”ê°€ ë§¤í•‘ ìš”ì²­ ë°”ëë‹ˆë‹¤.\n",
      "2026-02-06 14:42:06,603 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©(í™•ì •ì¼ìë¶€ ë‚´ìš©)ì´ ì¤‘ìš”í•œê°€ìš”?  \n",
      "\n",
      "[ë³€ê²½ëœ ì§ˆë¬¸]  \n",
      "ì£¼ë¯¼ë“±ë¡(ì£¼ë¯¼ë“±ë¡)Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©(í™•ì •ì¼ìë¶€ ë‚´ìš©)ì´ ì¤‘ìš”í•œê°€ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'í™•ì •ì¼ìë¶€ ë‚´ìš©'ì€ ìš©ì–´ ì‚¬ì „ì— ì—†ëŠ” í‘œí˜„ì´ë¯€ë¡œ ì›ë¬¸ì„ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì¶”ê°€ ë§¤í•‘ ìš”ì²­ ë°”ëë‹ˆë‹¤.'\n",
      "2026-02-06 14:42:07,046 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:09,418 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:11,638 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:13,776 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:42:13,776 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': '4ddef547784d5fe6c474de2978c04f11', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '39', 'date': 'Fri, 06 Feb 2026 05:42:13 GMT', 'x-envoy-upstream-service-time': '4', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': '7d616d33-9006-4b5c-924b-0a8c3b24106f', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:42:13,791 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:42:13,793 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:42:18,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:19,273 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:19,288 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê³„ì•½ì¦ì„œ(ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ)ì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„(í‡´ê±°)í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "2026-02-06 14:42:19,288 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê³„ì•½ì¦ì„œ(ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ)ì— 1ë…„ì´ë¼ê³  ì¨ ìˆìœ¼ë©´, 1ë…„ ì§€ë‚˜ë©´ ë¬´ì¡°ê±´ ì£¼íƒì˜ì¸ë„(í‡´ê±°)í•´ì•¼ í•˜ë‚˜ìš”?'\n",
      "2026-02-06 14:42:19,779 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:20,327 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:20,843 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:21,330 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:42:21,346 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': '5ec2e4ec6cf25cb41a5ca04aa62d380b', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '38', 'date': 'Fri, 06 Feb 2026 05:42:21 GMT', 'x-envoy-upstream-service-time': '6', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': '2ebcfb1e-ffc3-4597-847f-2a79cf741d11', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:42:21,349 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:42:21,351 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:42:24,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:25,654 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:25,654 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì„ëŒ€ì¸(ì§‘ì£¼ì¸)ê°€ ì•„ë¬´ ë§ ì•ˆ í–ˆëŠ”ë°, ê³„ì•½ì´ ë¬µì‹œì ê°±ì‹ (ìë™ì—°ì¥)ëœ ê±´ê°€ìš”?\n",
      "2026-02-06 14:42:25,664 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì„ëŒ€ì¸(ì§‘ì£¼ì¸)ê°€ ì•„ë¬´ ë§ ì•ˆ í–ˆëŠ”ë°, ê³„ì•½ì´ ë¬µì‹œì ê°±ì‹ (ìë™ì—°ì¥)ëœ ê±´ê°€ìš”?'\n",
      "2026-02-06 14:42:26,071 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:26,920 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:28,143 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:28,607 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:42:28,607 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': 'c1bafbc130239ed35fa3fa52fceb3121', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '37', 'date': 'Fri, 06 Feb 2026 05:42:28 GMT', 'x-envoy-upstream-service-time': '6', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': 'ea0ddfcd-e13b-41b0-a190-f1f3c7fd59ed', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:42:28,622 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:42:28,624 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:42:33,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:34,558 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:34,560 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì´ì‚¬'ì˜ ê²½ìš° ë¬¸ë§¥ìƒ 'ì£¼íƒì˜ì¸ë„'ë¡œ ë³€í™˜ë˜ì—ˆìœ¼ë‚˜, ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì ìš©ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: \"ì´ì‚¬ ê°€ë ¤ë©´\" â†’ \"ì„ì°¨ì£¼íƒì„ ëª…ë„í•˜ë ¤ë©´\")\n",
      "2026-02-06 14:42:34,563 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ë¬µì‹œì ê°±ì‹ (ë¬µì‹œì ê°±ì‹ )ìœ¼ë¡œ ì—°ì¥ëœ ì¤„ ëª¨ë¥´ê³  ì‚´ì•˜ëŠ”ë°, ì£¼íƒì˜ì¸ë„(ì£¼íƒì˜ì¸ë„) ê°€ë ¤ë©´ ì–¸ì œê¹Œì§€ ì‚´ì•„ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì´ì‚¬'ì˜ ê²½ìš° ë¬¸ë§¥ìƒ 'ì£¼íƒì˜ì¸ë„'ë¡œ ë³€í™˜ë˜ì—ˆìœ¼ë‚˜, ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì ìš©ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: \"ì´ì‚¬ ê°€ë ¤ë©´\" â†’ \"ì„ì°¨ì£¼íƒì„ ëª…ë„í•˜ë ¤ë©´\")'\n",
      "2026-02-06 14:42:35,250 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:42:36,144 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:36,956 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:37,447 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:42:37,447 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': 'b95a5ad6957104b28717a3346469a418', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '36', 'date': 'Fri, 06 Feb 2026 05:42:37 GMT', 'x-envoy-upstream-service-time': '5', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': 'bb36cfad-92e0-44b4-be9b-d77b157e5c5c', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:42:37,455 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:42:37,456 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:42:42,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:43,365 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:43,365 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì°¨ì„(ì¦ì•¡)ì„ 6ê°œì›” ì „ì— í–ˆëŠ”ë° ë˜ ì°¨ì„ì¦ì•¡(ì¦ì•¡)ì„ ìš”êµ¬í•´ìš”. ë”°ë¼ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸: ì°¨ì„(ì¦ì•¡)ì„ 6ê°œì›” ì „ì— í–ˆëŠ”ë° ë˜ ì°¨ì„ì¦ì•¡(ì¦ì•¡)ì„ ìš”êµ¬í•´ìš”. ë”°ë¼ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‹¤ì œ ë²•ë¥  ì ìš© ì‹œ ì°¨ì„ì¦ì•¡ ìš”ê±´(ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡° ë“±) ë° ì¦ì•¡ ìƒí•œë¥ (5% ì´ë‚´) ë“±ì„ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë§Œ, ë³¸ ì‘ì—…ì€ ìš©ì–´ ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "2026-02-06 14:42:43,377 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì°¨ì„(ì¦ì•¡)ì„ 6ê°œì›” ì „ì— í–ˆëŠ”ë° ë˜ ì°¨ì„ì¦ì•¡(ì¦ì•¡)ì„ ìš”êµ¬í•´ìš”. ë”°ë¼ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸: ì°¨ì„(ì¦ì•¡)ì„ 6ê°œì›” ì „ì— í–ˆëŠ”ë° ë˜ ì°¨ì„ì¦ì•¡(ì¦ì•¡)ì„ ìš”êµ¬í•´ìš”. ë”°ë¼ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : ì‹¤ì œ ë²•ë¥  ì ìš© ì‹œ ì°¨ì„ì¦ì•¡ ìš”ê±´(ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡° ë“±) ë° ì¦ì•¡ ìƒí•œë¥ (5% ì´ë‚´) ë“±ì„ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë§Œ, ë³¸ ì‘ì—…ì€ ìš©ì–´ ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 14:42:43,861 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:44,714 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:45,568 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:46,153 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:42:46,156 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': 'ddc4041b5f6170fee882476a48c0dc0e', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '35', 'date': 'Fri, 06 Feb 2026 05:42:45 GMT', 'x-envoy-upstream-service-time': '9', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': 'dfb4462a-a2c8-4c00-848f-631cc735e8be', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:42:46,158 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:42:46,160 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:42:52,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:52,628 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:52,628 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "2026-02-06 14:42:52,638 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê²½ê¸°ë„ì— ì‚¬ëŠ”ë° ì„ì°¨ì£¼íƒì´ ê²½ë§¤ì ˆì°¨ë¡œ ë„˜ì–´ê°€ë©´, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ì¼ë¶€ë¼ë„ ìš°ì„ ë³€ì œê¶Œìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?'\n",
      "2026-02-06 14:42:53,326 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:54,464 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:55,302 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:42:55,794 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:42:55,794 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': '4959734079982f9360f9894e2a012b42', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '34', 'date': 'Fri, 06 Feb 2026 05:42:55 GMT', 'x-envoy-upstream-service-time': '5', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': '92d5d918-8d33-47ba-bb22-d09b41cc4a26', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:42:55,807 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:42:55,810 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:43:00,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:02,230 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:02,230 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì¡°ì • ì‹ ì²­ì€ ì–´ë””ì— í•˜ë‚˜ìš”? ë§ë¡œ í•´ë„ ë˜ë‚˜ìš”? ëˆì€ ê¼­ ë‚´ì•¼ í•˜ë‚˜ìš”?  \n",
      "â†’ ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ(ì¡°ì •ìœ„) ì‹ ì²­ì€ ì–´ë””ì— í•˜ë‚˜ìš”? ë§ë¡œ í•´ë„ ë˜ë‚˜ìš”? ëˆ(ì¤‘ê°œë³´ìˆ˜)ì€ ê¼­ ë‚´ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "[ìˆ˜ì • í›„ ìµœì¢… ì¶œë ¥]  \n",
      "ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ(ì¡°ì •ìœ„) ì‹ ì²­ì€ ì–´ë””ì— í•˜ë‚˜ìš”? ë§ë¡œ í•´ë„ ë˜ë‚˜ìš”? ëˆ(ì¤‘ê°œë³´ìˆ˜)ì€ ê¼­ ë‚´ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ëˆ'ì€ ìš©ì–´ ì‚¬ì „ì— ëª…ì‹œëœ ë§¤í•‘ ëŒ€ìƒì´ ì•„ë‹ˆë¯€ë¡œ ë³€ê²½í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë§Œ 'ì¤‘ê°œë³´ìˆ˜'ê°€ í¬í•¨ëœ ê²½ìš° ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ì§€ì¹¨ 3í•­ì— ë”°ë¼ ì¶”ê°€ ì„¤ëª…ì„ ìƒëµí–ˆìŠµë‹ˆë‹¤.\n",
      "2026-02-06 14:43:02,244 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì¡°ì • ì‹ ì²­ì€ ì–´ë””ì— í•˜ë‚˜ìš”? ë§ë¡œ í•´ë„ ë˜ë‚˜ìš”? ëˆì€ ê¼­ ë‚´ì•¼ í•˜ë‚˜ìš”?  \n",
      "â†’ ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ(ì¡°ì •ìœ„) ì‹ ì²­ì€ ì–´ë””ì— í•˜ë‚˜ìš”? ë§ë¡œ í•´ë„ ë˜ë‚˜ìš”? ëˆ(ì¤‘ê°œë³´ìˆ˜)ì€ ê¼­ ë‚´ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "[ìˆ˜ì • í›„ ìµœì¢… ì¶œë ¥]  \n",
      "ì£¼íƒì„ëŒ€ì°¨ë¶„ìŸì¡°ì •ìœ„ì›íšŒ(ì¡°ì •ìœ„) ì‹ ì²­ì€ ì–´ë””ì— í•˜ë‚˜ìš”? ë§ë¡œ í•´ë„ ë˜ë‚˜ìš”? ëˆ(ì¤‘ê°œë³´ìˆ˜)ì€ ê¼­ ë‚´ì•¼ í•˜ë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ëˆ'ì€ ìš©ì–´ ì‚¬ì „ì— ëª…ì‹œëœ ë§¤í•‘ ëŒ€ìƒì´ ì•„ë‹ˆë¯€ë¡œ ë³€ê²½í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë§Œ 'ì¤‘ê°œë³´ìˆ˜'ê°€ í¬í•¨ëœ ê²½ìš° ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ì§€ì¹¨ 3í•­ì— ë”°ë¼ ì¶”ê°€ ì„¤ëª…ì„ ìƒëµí–ˆìŠµë‹ˆë‹¤.'\n",
      "2026-02-06 14:43:03,131 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:03,981 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:04,685 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:05,218 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:43:05,218 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': '0dcafcd2ffda10961acb20e4d20149d2', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '33', 'date': 'Fri, 06 Feb 2026 05:43:04 GMT', 'x-envoy-upstream-service-time': '7', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': '029f7962-e513-4611-a2b9-a108df13a408', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:43:05,222 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:43:05,225 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:43:09,360 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:10,162 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:10,162 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¡œ ë„˜ì–´ê°”ëŠ”ë°, êµ­ì„¸ ì²´ë‚©ìœ¼ë¡œ ê°€ì••ë¥˜(ê°€ì••ë¥˜)ê°€ ë¨¼ì € ê±¸ë ¤ ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. ì„¸ê¸ˆê³¼ ì œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ) ì¤‘ ë­ê°€ ìš°ì„ ë³€ì œê¶Œ(ìš°ì„ ë³€ì œ)ìœ¼ë¡œ ë¨¼ì € ê°€ì ¸ê°€ë‚˜ìš”?\n",
      "2026-02-06 14:43:10,174 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¡œ ë„˜ì–´ê°”ëŠ”ë°, êµ­ì„¸ ì²´ë‚©ìœ¼ë¡œ ê°€ì••ë¥˜(ê°€ì••ë¥˜)ê°€ ë¨¼ì € ê±¸ë ¤ ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. ì„¸ê¸ˆê³¼ ì œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ë³´ì¦ê¸ˆ) ì¤‘ ë­ê°€ ìš°ì„ ë³€ì œê¶Œ(ìš°ì„ ë³€ì œ)ìœ¼ë¡œ ë¨¼ì € ê°€ì ¸ê°€ë‚˜ìš”?'\n",
      "2026-02-06 14:43:11,877 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:12,764 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:13,607 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:14,091 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:43:14,107 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': '04a977149259d4de38b8bf0f184077e9', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '33', 'date': 'Fri, 06 Feb 2026 05:43:13 GMT', 'x-envoy-upstream-service-time': '8', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': '9a78552a-9670-4e36-a759-7a02205e4b64', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:43:14,109 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:43:14,111 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:43:20,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:22,606 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:22,622 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì„¸(ì „ì„¸) ê³„ì•½í•˜ë ¤ëŠ” ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)ì— ì„ ìˆœìœ„ ê·¼ì €ë‹¹ê¶Œ(ê·¼ì €ë‹¹ê¶Œ)ì€ ì—†ëŠ”ë°, ë‚˜ì¤‘ì— ë³´ë‹ˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ êµ­ì„¸ë¥¼ ì²´ë‚©(êµ­ì„¸ì²´ë‚©)í•œ ìƒíƒœì˜€ìŠµë‹ˆë‹¤. ì•„ì§ ì••ë¥˜ë“±ê¸°(ì••ë¥˜ë“±ê¸°)ëŠ” ì—†ì—ˆëŠ”ë°, ì´ ê²½ìš°ì—ë„ ì œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì´ ìœ„í—˜í•œê°€ìš”?  \n",
      "\n",
      "(ë³€ê²½ ì‚¬í•­:  \n",
      "- 'ì „ì„¸' â†’ 'ì „ì„¸(ì „ì„¸)' (ìš©ì–´ ì‚¬ì „ ë¯¸ë“±ì¬ ë‹¨ì–´ë¡œ ìœ ì§€)  \n",
      "- 'ì§‘' â†’ 'ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)'  \n",
      "- 'ì„ ìˆœìœ„ ê·¼ì €ë‹¹' â†’ 'ì„ ìˆœìœ„ ê·¼ì €ë‹¹ê¶Œ(ê·¼ì €ë‹¹ê¶Œ)'  \n",
      "- 'ì§‘ì£¼ì¸' â†’ 'ì„ëŒ€ì¸(ì„ëŒ€ì¸)'  \n",
      "- 'ì „ì„¸ê¸ˆ' â†’ 'ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)'  \n",
      "- 'ë³´ì¦ê¸ˆ' â†’ 'ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)'  \n",
      "â€» 'êµ­ì„¸ì²´ë‚©', 'ì••ë¥˜ë“±ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ ë¯¸ë“±ì¬ ë‹¨ì–´ë¡œ ìœ ì§€)\n",
      "2026-02-06 14:43:22,622 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì„¸(ì „ì„¸) ê³„ì•½í•˜ë ¤ëŠ” ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)ì— ì„ ìˆœìœ„ ê·¼ì €ë‹¹ê¶Œ(ê·¼ì €ë‹¹ê¶Œ)ì€ ì—†ëŠ”ë°, ë‚˜ì¤‘ì— ë³´ë‹ˆ ì„ëŒ€ì¸(ì„ëŒ€ì¸)ì´ êµ­ì„¸ë¥¼ ì²´ë‚©(êµ­ì„¸ì²´ë‚©)í•œ ìƒíƒœì˜€ìŠµë‹ˆë‹¤. ì•„ì§ ì••ë¥˜ë“±ê¸°(ì••ë¥˜ë“±ê¸°)ëŠ” ì—†ì—ˆëŠ”ë°, ì´ ê²½ìš°ì—ë„ ì œ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)ì´ ìœ„í—˜í•œê°€ìš”?  \n",
      "\n",
      "(ë³€ê²½ ì‚¬í•­:  \n",
      "- 'ì „ì„¸' â†’ 'ì „ì„¸(ì „ì„¸)' (ìš©ì–´ ì‚¬ì „ ë¯¸ë“±ì¬ ë‹¨ì–´ë¡œ ìœ ì§€)  \n",
      "- 'ì§‘' â†’ 'ì„ì°¨ì£¼íƒ(ì„ì°¨ì£¼íƒ)'  \n",
      "- 'ì„ ìˆœìœ„ ê·¼ì €ë‹¹' â†’ 'ì„ ìˆœìœ„ ê·¼ì €ë‹¹ê¶Œ(ê·¼ì €ë‹¹ê¶Œ)'  \n",
      "- 'ì§‘ì£¼ì¸' â†’ 'ì„ëŒ€ì¸(ì„ëŒ€ì¸)'  \n",
      "- 'ì „ì„¸ê¸ˆ' â†’ 'ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)'  \n",
      "- 'ë³´ì¦ê¸ˆ' â†’ 'ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ(ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ)'  \n",
      "â€» 'êµ­ì„¸ì²´ë‚©', 'ì••ë¥˜ë“±ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ ë¯¸ë“±ì¬ ë‹¨ì–´ë¡œ ìœ ì§€)'\n",
      "2026-02-06 14:43:23,247 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:24,013 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:24,893 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:25,444 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:43:25,447 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': 'cc2e10d64e7175271b97bc33ca5470e9', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '33', 'date': 'Fri, 06 Feb 2026 05:43:25 GMT', 'x-envoy-upstream-service-time': '7', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': '01aef518-352e-43f1-b0cf-4f5499bfdb31', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:43:25,449 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:43:25,451 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:43:32,079 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:34,100 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:34,101 - chatbot_app.modules.rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì „ì„¸ì‚¬ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ì— 'ì „ì„¸í”¼í•´'ë¡œ ì§ì ‘ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ë¬¸ë§¥ìƒ 'ê¶Œë¦¬ë¦¬ìŠ¤í¬'ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì ìš©ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "(ìµœì¢… ì¶œë ¥ ì‹œ ìœ„ ì°¸ê³  ë¬¸êµ¬ ì œì™¸)  \n",
      "\n",
      "**ìµœì¢… ì¶œë ¥:**  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?\n",
      "2026-02-06 14:43:34,105 - chatbot_app.modules.rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "ë³€ê²½ëœ ì§ˆë¬¸:  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?  \n",
      "\n",
      "â€» ì°¸ê³ : 'ì „ì„¸ì‚¬ê¸°'ëŠ” ìš©ì–´ ì‚¬ì „ì— 'ì „ì„¸í”¼í•´'ë¡œ ì§ì ‘ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ë¬¸ë§¥ìƒ 'ê¶Œë¦¬ë¦¬ìŠ¤í¬'ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì ìš©ì„ ìœ„í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "(ìµœì¢… ì¶œë ¥ ì‹œ ìœ„ ì°¸ê³  ë¬¸êµ¬ ì œì™¸)  \n",
      "\n",
      "**ìµœì¢… ì¶œë ¥:**  \n",
      "ì „ì„¸í”¼í•´(ê¶Œë¦¬ë¦¬ìŠ¤í¬)ë¡œ ì•„ì§ ê³µì‹ ê²°ì • ì „ì¸ë° ê²½ë§¤ì ˆì°¨(ê²½ë§¤) ë§¤ê°ê¸°ì¼ì´ ì¡í˜”ìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ë„ ê²½ë§¤ì ˆì°¨(ê²½ë§¤)ë¥¼ ë©ˆì¶œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?'\n",
      "2026-02-06 14:43:34,764 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:35,884 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:43:36,770 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:37,311 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-02-06 14:43:37,311 - chatbot_app.modules.rag_module - WARNING - âš ï¸ Rerank ì‹¤íŒ¨ (skip): headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-encoding': 'gzip', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin,Accept-Encoding', 'x-accel-expires': '0', 'x-debug-trace-id': 'd6a993d16a848214d4a4cccc1762a137', 'x-trial-endpoint-call-limit': '40', 'x-trial-endpoint-call-remaining': '33', 'date': 'Fri, 06 Feb 2026 05:43:36 GMT', 'x-envoy-upstream-service-time': '4', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'transfer-encoding': 'chunked'}, status_code: 429, body: {'id': 'eb62f3d7-5098-40b8-866f-3eda14d7c5ad', 'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
      "2026-02-06 14:43:37,319 - chatbot_app.modules.rag_module - INFO - ğŸ“ Using prompt mode: GENERAL\n",
      "2026-02-06 14:43:37,321 - chatbot_app.modules.rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-02-06 14:43:41,257 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data validation passed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96916366313478489bc45192935f530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e407b4a187b4785ad3c5ce5efe243f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch 1/10:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:43:43,379 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:45,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:48,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:50,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:52,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:54,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:57,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:43:59,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:01,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:04,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:07,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:09,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:11,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:13,984 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:16,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:18,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:22,773 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:25,227 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:27,404 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:29,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:31,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:34,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:36,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:39,075 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:41,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:43,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:46,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:48,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:51,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:44:53,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f636a0420920421785df0b06102bcfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638645a83e4a4c5790df481668731b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch 1/10:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:45:05,404 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:45:15,091 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:45:26,165 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:45:34,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:45:43,920 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:45:53,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:02,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:11,168 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:18,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:24,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dd1e3349924ba1a57bd4dc7139d30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbf350d7d8541dbb1db986e139b31c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch 1/20:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 14:46:26,680 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:27,763 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:29,103 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:30,793 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:37,036 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:38,295 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:39,402 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:40,213 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:42,088 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:47,650 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:48,934 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:50,426 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:51,473 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:53,494 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:46:59,755 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:01,090 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:02,583 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:03,606 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:05,747 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:13,319 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:14,733 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:16,081 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:16,880 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:19,150 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:27,811 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:29,612 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:30,986 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:31,832 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:33,685 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:40,029 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:41,443 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:42,627 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:43,890 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:45,796 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:51,273 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:52,523 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:54,303 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:55,100 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:47:57,109 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:03,658 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:04,932 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:06,291 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:07,328 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:10,236 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:17,153 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:18,503 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:19,887 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:20,659 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:22,527 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-02-06 14:48:27,472 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… saved: ./data/RAGAS\\ragas_total_score_table.csv\n",
      "CPU times: total: 8.02 s\n",
      "Wall time: 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = RAGConfig(\n",
    "        k_law=7, \n",
    "        k_rule=7, \n",
    "        k_case=3, \n",
    "        search_multiplier=4, \n",
    "        \n",
    "        enable_rerank=True,\n",
    "        \n",
    "        bm25_algorithm=\"okapi\", # \"okapi\" | \"plus\"\n",
    "        bm25_k1=1.5, \n",
    "        bm25_max_doc_chars=2200,\n",
    "        \n",
    "        hybrid_sparse_title_ratio=0.35,\n",
    "        hybrid_dense_weight=0.5, \n",
    "        hybrid_sparse_weight=0.5, \n",
    "        \n",
    "        rerank_threshold=0.2,\n",
    "        rerank_max_documents=22,\n",
    "        rerank_doc_max_chars=2600, \n",
    "        )\n",
    "    table, path = run_once_total_table(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2213128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context-precision</th>\n",
       "      <th>context-recall</th>\n",
       "      <th>answer-relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.413251</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.521555</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.509518</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.438959</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252470</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364895</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.445392</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.508144</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.317246</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.403050</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648056</td>\n",
       "      <td>0.417448</td>\n",
       "      <td>0.266522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  context-precision  context-recall  answer-relevancy  faithfulness\n",
       "0      1                1.0        0.857143          0.413251      0.400000\n",
       "1      2                1.0        0.142857          0.521555      0.142857\n",
       "2      3                1.0        0.875000          0.509518      0.222222\n",
       "3      4                1.0        0.555556          0.438959      0.363636\n",
       "4      5                1.0        1.000000          0.252470      0.000000\n",
       "5      6                1.0        1.000000          0.364895      0.428571\n",
       "6      7                1.0        0.400000          0.445392      0.100000\n",
       "7      8                1.0        0.400000          0.508144      0.500000\n",
       "8      9                1.0        0.500000          0.317246      0.222222\n",
       "9     10                1.0        0.750000          0.403050      0.285714\n",
       "10  mean                1.0        0.648056          0.417448      0.266522"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_csv('data/RAGAS/ragas_total_score_table.csv')\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm (ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
