{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ” RAG ì—”ì§„ í…ŒìŠ¤íŠ¸ (3ê°œ ì¸ë±ìŠ¤ + Priority Rerank)\n",
    "\n",
    "**ëª©í‘œ**: 3ê°œ Pinecone ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰ â†’ Priority Rerank â†’ GPT-4o ë‹µë³€ ìƒì„±\n",
    "\n",
    "**ì¸ë±ìŠ¤ êµ¬ì¡°:**\n",
    "- `housing-law-index`: ë²•ë¥  (ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•, ë¯¼ë²•)\n",
    "- `housing-rule-index`: ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™  \n",
    "- `housing-case-index`: íŒë¡€, ìƒë‹´ì‚¬ë¡€\n",
    "\n",
    "**ì´ì „ ë‹¨ê³„**: `embed_to_pinecone_test.ipynb` ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° API í‚¤ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import textwrap\n",
    "\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pinecone import Pinecone\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ API í‚¤ í™•ì¸:\n",
      "  PINECONE: âœ…\n",
      "  UPSTAGE: âœ…\n",
      "  OPENAI: âœ…\n",
      "\n",
      "ğŸ“Œ ì¸ë±ìŠ¤:\n",
      "  - Law: housing-law-index\n",
      "  - Rule: housing-rule-index\n",
      "  - Case: housing-case-index\n"
     ]
    }
   ],
   "source": [
    "# API í‚¤ ë¡œë“œ\n",
    "BASE_DIR = Path.cwd().parents[1]  # í”„ë¡œì íŠ¸ ë£¨íŠ¸\n",
    "env_path = BASE_DIR / \".env\"\n",
    "load_dotenv(env_path)\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 3ê°œ ì¸ë±ìŠ¤ëª…\n",
    "LAW_INDEX_NAME = \"housing-law-index\"\n",
    "RULE_INDEX_NAME = \"housing-rule-index\"\n",
    "CASE_INDEX_NAME = \"housing-case-index\"\n",
    "\n",
    "# API í‚¤ í™•ì¸\n",
    "print(\"ğŸ”‘ API í‚¤ í™•ì¸:\")\n",
    "print(f\"  PINECONE: {'âœ…' if PINECONE_API_KEY else 'âŒ'}\")\n",
    "print(f\"  UPSTAGE: {'âœ…' if UPSTAGE_API_KEY else 'âŒ'}\")\n",
    "print(f\"  OPENAI: {'âœ…' if OPENAI_API_KEY else 'âŒ'}\")\n",
    "print(f\"\\nğŸ“Œ ì¸ë±ìŠ¤:\")\n",
    "print(f\"  - Law: {LAW_INDEX_NAME}\")\n",
    "print(f\"  - Rule: {RULE_INDEX_NAME}\")\n",
    "print(f\"  - Case: {CASE_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Upstage ì„ë² ë”© & Pinecone ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Upstage ì„ë² ë”© ë¡œë“œ ì¤‘...\n",
      "âœ… ì„ë² ë”© ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“¦ Upstage ì„ë² ë”© ë¡œë“œ ì¤‘...\")\n",
    "embedding = UpstageEmbeddings(\n",
    "    model=\"solar-embedding-1-large-passage\",\n",
    "    api_key=UPSTAGE_API_KEY\n",
    ")\n",
    "print(\"âœ… ì„ë² ë”© ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Pinecone ì—°ê²° ì¤‘...\n",
      "âœ… 3ê°œ Pinecone ì¸ë±ìŠ¤ ì—°ê²° ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”— Pinecone ì—°ê²° ì¤‘...\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# 3ê°œ VectorStore ì´ˆê¸°í™”\n",
    "law_vectorstore = PineconeVectorStore(\n",
    "    index_name=LAW_INDEX_NAME,\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "rule_vectorstore = PineconeVectorStore(\n",
    "    index_name=RULE_INDEX_NAME,\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "case_vectorstore = PineconeVectorStore(\n",
    "    index_name=CASE_INDEX_NAME,\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "print(\"âœ… 3ê°œ Pinecone ì¸ë±ìŠ¤ ì—°ê²° ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ OpenAI LLM ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– OpenAI LLM ì´ˆê¸°í™” ì¤‘...\n",
      "âœ… LLM ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¤– OpenAI LLM ì´ˆê¸°í™” ì¤‘...\")\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "print(\"âœ… LLM ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì‚¬ì „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¹´í…Œê³ ë¦¬ ì‚¬ì „ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def get_law_category():\n",
    "    \"\"\"ì£¼íƒì„ëŒ€ì°¨ RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì¹´í…Œê³ ë¦¬-í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì‚¬ì „\"\"\"\n",
    "    return {\n",
    "        'ë³´ì¦ê¸ˆ_ëŒ€í•­ë ¥': {\n",
    "            'ë³´ì¦ê¸ˆ': 3, 'ëŒ€í•­ë ¥': 3, 'ìš°ì„ ë³€ì œê¶Œ': 3, 'ìµœìš°ì„ ë³€ì œ': 3,\n",
    "            'ë³´ì¦ê¸ˆë°˜í™˜': 3, 'ì „ì„¸ê¸ˆ': 2, 'ì†Œì•¡ì„ì°¨ì¸': 2, 'í™•ì •ì¼ì': 2,\n",
    "            'ì „ì…ì‹ ê³ ': 2, 'ì ìœ ': 2, 'ì„ì°¨ê¶Œë“±ê¸°': 3, 'ë°°ë‹¹': 2\n",
    "        },\n",
    "        'ê³„ì•½ê°±ì‹ ': {\n",
    "            'ê³„ì•½ê°±ì‹ ': 3, 'ê°±ì‹ ìš”êµ¬': 3, 'ê°±ì‹ ê±°ì ˆ': 3, 'ë¬µì‹œì ê°±ì‹ ': 3,\n",
    "            'ê³„ì•½ì—°ì¥': 2, 'ì‹¤ê±°ì£¼': 3, 'ì¡´ì†ê¸°ê°„': 2, 'ì¬ê³„ì•½': 2\n",
    "        },\n",
    "        'ê³„ì•½í•´ì§€': {\n",
    "            'ê³„ì•½í•´ì§€': 3, 'í•´ì§€í†µê³ ': 3, 'ì¤‘ë„í•´ì§€': 3, 'ê¸°ê°„ë§Œë£Œ': 2,\n",
    "            'ê³„ì•½ì¢…ë£Œ': 2, 'í‡´ê±°': 2, 'ëª…ë„': 2, 'í•©ì˜í•´ì§€': 2\n",
    "        },\n",
    "        'ì„ëŒ€ë£Œ_ì¦ê°': {\n",
    "            'ì°¨ì„': 3, 'ì›”ì„¸': 2, 'ì¦ì•¡': 3, 'ê°ì•¡': 2, 'ì¸ìƒ': 2,\n",
    "            '5í¼ì„¼íŠ¸': 3, '5%': 3, '20ë¶„ì˜ 1': 2, 'ì „í™˜ìœ¨': 2\n",
    "        },\n",
    "        'ìˆ˜ì„ _ì›ìƒíšŒë³µ': {\n",
    "            'ìˆ˜ì„ ': 3, 'ìˆ˜ë¦¬': 3, 'ì›ìƒíšŒë³µ': 3, 'íŒŒì†': 2, 'ëˆ„ìˆ˜': 2,\n",
    "            'í•„ìš”ë¹„': 3, 'ìœ ìµë¹„': 3, 'ë¹„ìš©ìƒí™˜': 2\n",
    "        },\n",
    "        'ê¶Œë¦¬_ë¦¬ìŠ¤í¬': {\n",
    "            'ì „ì„¸ì‚¬ê¸°': 3, 'ê¹¡í†µì „ì„¸': 3, 'ì‹ íƒ': 3, 'ê·¼ì €ë‹¹': 3, 'ì €ë‹¹ê¶Œ': 3,\n",
    "            'ì„ ìˆœìœ„': 3, 'ê°€ì••ë¥˜': 3, 'ì••ë¥˜': 3, 'ì²´ë‚©': 3, 'ë…ì†Œì¡°í•­': 2\n",
    "        },\n",
    "        'í–‰ì •ì ˆì°¨': {\n",
    "            'í™•ì •ì¼ìë¶€ì—¬': 3, 'ë™ì£¼ë¯¼ì„¼í„°': 2, 'ë“±ê¸°ì†Œ': 2, 'ì„ëŒ€ì°¨ê³„ì•½ì¦ì„œ': 2\n",
    "        },\n",
    "        'ë¶„ìŸí•´ê²°': {\n",
    "            'ë¶„ìŸì¡°ì •': 3, 'ì§€ê¸‰ëª…ë ¹': 3, 'ì†Œì†¡': 3, 'ê²½ë§¤': 3, 'ì†í•´ë°°ìƒ': 3\n",
    "        },\n",
    "        'ì„ì°¨ê¶Œ_ìŠ¹ê³„': {\n",
    "            'ì„ì°¨ê¶ŒìŠ¹ê³„': 3, 'ìŠ¹ê³„': 3, 'ì‚¬ë§': 3, 'ìƒì†': 3, 'ì‚¬ì‹¤í˜¼': 3\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"âœ… ì¹´í…Œê³ ë¦¬ ì‚¬ì „ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"ë‹¹ì‹ ì€ ì„ì°¨ì¸ì˜ ê¶Œìµì„ ë³´í˜¸í•˜ëŠ” ì „ë¬¸ ë²•ë¥  ìƒë‹´ AIì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì¤‘ìš” ê·œì¹™:\n",
    "1. **ë°˜ë“œì‹œ ê·¼ê±° ë²•ë ¹ì„ ëª…ì‹œ**í•˜ì„¸ìš” (ì˜ˆ: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡°)\n",
    "2. ì„ì°¨ì¸ì—ê²Œ **ë¶ˆë¦¬í•œ ì¡°í•­ì€ ëª…í™•íˆ ê²½ê³ **í•˜ì„¸ìš”\n",
    "3. **êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ**ì„ ì œì‹œí•˜ì„¸ìš”\n",
    "4. ë²•ë¥  ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”\n",
    "\n",
    "### ê²€ìƒ‰ëœ ë²•ë ¹ ë° ì‚¬ë¡€:\n",
    "{context}\n",
    "\n",
    "### ì‚¬ìš©ì ì§ˆë¬¸:\n",
    "{question}\n",
    "\n",
    "### AI ë‹µë³€:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Priority Rerank í•¨ìˆ˜\n",
    "# pip install -U cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rerank í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n",
      "âœ… Cohere Rerank í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def rerank_by_priority(documents):\n",
    "    \"\"\"\n",
    "    ìš°ì„ ìˆœìœ„ ê¸°ë°˜ rerank\n",
    "    \n",
    "    Priority ìˆœì„œ:\n",
    "    1. ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• (priority=1)\n",
    "    2. ì‹œí–‰ë ¹ (priority=2)\n",
    "    3. ì‹œí–‰ê·œì¹™ (priority=3)\n",
    "    4. ë¯¼ë²• (priority=4)\n",
    "    5. ëŒ€ë²•ì› íŒë¡€ (priority=5)\n",
    "    6. í•˜ê¸‰ì‹¬ íŒë¡€ (priority=6)\n",
    "    7. ìƒë‹´ ì‚¬ë¡€ (priority=7)\n",
    "    \"\"\"\n",
    "    reranked = sorted(\n",
    "        documents,\n",
    "        key=lambda doc: int(doc.metadata.get('priority', 99))\n",
    "    )\n",
    "    return reranked\n",
    "\n",
    "print(\"âœ… Rerank í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "import cohere\n",
    "\n",
    "def rerank_by_cohere(query, documents, top_k=10):\n",
    "    \"\"\"\n",
    "    Cohere Rerank APIë¡œ ì§ˆë¬¸ ê´€ë ¨ì„± ê¸°ë°˜ ì¬ì •ë ¬\n",
    "    \n",
    "    Args:\n",
    "        query: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        documents: ì¬ì •ë ¬í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "        top_k: ìƒìœ„ ëª‡ ê°œ ì„ íƒí• ì§€\n",
    "    \n",
    "    Returns:\n",
    "        ì¬ì •ë ¬ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "    \n",
    "    # ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì œëª© + ë‚´ìš©)\n",
    "    docs_text = [\n",
    "        doc.metadata.get('law_name', '') + \" \" + \n",
    "        doc.metadata.get('article', '') + \" \" + \n",
    "        doc.page_content \n",
    "        for doc in documents\n",
    "    ]\n",
    "    \n",
    "    # Cohere Rerank API í˜¸ì¶œ\n",
    "    results = co.rerank(\n",
    "        model=\"rerank-multilingual-v3.0\",  # í•œêµ­ì–´ ì§€ì› ëª¨ë¸\n",
    "        query=query,\n",
    "        documents=docs_text,\n",
    "        top_n=top_k\n",
    "    )\n",
    "    \n",
    "    # ì¬ì •ë ¬ëœ ìˆœì„œëŒ€ë¡œ ë¬¸ì„œ ë°˜í™˜\n",
    "    reranked = [documents[r.index] for r in results.results]\n",
    "    return reranked\n",
    "\n",
    "print(\"âœ… Cohere Rerank í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "#```\n",
    "\n",
    "#**.env íŒŒì¼ì— ì¶”ê°€**:\n",
    "#```\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ í†µí•© RAG ì§ˆì˜ í•¨ìˆ˜ (3ê°œ ì¸ë±ìŠ¤ ê²€ìƒ‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (5.20.1)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from cohere) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from cohere) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from cohere) (2.12.5)\n",
      "Requirement already satisfied: pydantic-core>=2.18.2 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from cohere) (2.41.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from cohere) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from cohere) (0.20.3)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from cohere) (2.32.4.20260107)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from cohere) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2025.11.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from tokenizers<1,>=0.15->cohere) (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.20.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from httpx>=0.21.2->cohere) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\llm\\lib\\site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í†µí•© RAG ì§ˆì˜ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def query_rag(question, k_per_index=5, top_n=10):\n",
    "    \"\"\"\n",
    "    3ê°œ ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰ í›„ í†µí•© Rerank\n",
    "    \n",
    "    Args:\n",
    "        question: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        k_per_index: ê° ì¸ë±ìŠ¤ì—ì„œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜\n",
    "        top_n: ìµœì¢… ì„ íƒí•  ë¬¸ì„œ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        str: AI ë‹µë³€\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. 3ê°œ ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰\n",
    "        print(f\"ğŸ” 3ê°œ ì¸ë±ìŠ¤ ê²€ìƒ‰ ì¤‘... (ê° {k_per_index}ê°œ)\")\n",
    "        \n",
    "        law_docs = law_vectorstore.similarity_search(question, k=k_per_index)\n",
    "        print(f\"   âœ… Law: {len(law_docs)}ê°œ\")\n",
    "        \n",
    "        rule_docs = rule_vectorstore.similarity_search(question, k=k_per_index)\n",
    "        print(f\"   âœ… Rule: {len(rule_docs)}ê°œ\")\n",
    "        \n",
    "        case_docs = case_vectorstore.similarity_search(question, k=k_per_index)\n",
    "        print(f\"   âœ… Case: {len(case_docs)}ê°œ\")\n",
    "        \n",
    "        # 2. ëª¨ë“  ë¬¸ì„œ í†µí•©\n",
    "        all_docs = law_docs + rule_docs + case_docs\n",
    "        print(f\"\\nğŸ“Š ì´ ê²€ìƒ‰ ê²°ê³¼: {len(all_docs)}ê°œ\")\n",
    "        \n",
    "        # 3. Priority Rerank\n",
    "        print(f\"ğŸ”„ Priority Rerank ì¤‘...\")\n",
    "        priority_ranked = rerank_by_priority(all_docs)\n",
    "        \n",
    "        # ğŸ†• 3.5. Cohere Rerank (ì—¬ê¸° ì¶”ê°€!)\n",
    "        print(f\"ğŸ¯ Cohere Rerank ì¤‘...\")\n",
    "        cohere_ranked = rerank_by_cohere(question, priority_ranked[:20], top_n)\n",
    "        \n",
    "        # 4. ìµœì¢… ë¬¸ì„œ ì„ íƒ\n",
    "        top_docs =priority_ranked[:top_n]   # í‰ê°€ ìœ„í•´ ë²ˆê°ˆì•„ ì£¼ì„ì²˜ë¦¬\n",
    "        #top_docs = cohere_ranked   \n",
    "        print(f\"   âœ… ìƒìœ„ {len(top_docs)}ê°œ ì„ íƒ ì™„ë£Œ\")\n",
    "        \n",
    "        # 5. Context ìƒì„±\n",
    "        context_parts = []\n",
    "        for i, doc in enumerate(top_docs, 1):\n",
    "            meta = doc.metadata\n",
    "            priority = int(meta.get('priority', 99))   # â¬…ï¸ ì—¬ê¸°ë§Œ í•µì‹¬ ìˆ˜ì •\n",
    "            law_name = meta.get('law_name', meta.get('src_title', 'Unknown'))\n",
    "            article = meta.get('article', '')\n",
    "            \n",
    "            content = textwrap.fill(doc.page_content[:300], width=80)\n",
    "            \n",
    "            context_parts.append(\n",
    "                f\"[ë¬¸ì„œ {i}] (ìš°ì„ ìˆœìœ„: {priority})\\n\"\n",
    "                f\"ì¶œì²˜: {law_name} {article}\\n\"\n",
    "                f\"ë‚´ìš©: {content}...\\n\"\n",
    "            )\n",
    "\n",
    "        context = \"\\n\".join(context_parts)\n",
    "\n",
    "        \n",
    "        # 6. LLM ë‹µë³€ ìƒì„±\n",
    "        print(f\"ğŸ¤– GPT-4o ë‹µë³€ ìƒì„± ì¤‘...\")\n",
    "        prompt = prompt_template.format(\n",
    "            context=context,\n",
    "            question=question\n",
    "        )\n",
    "        \n",
    "        answer = llm.invoke(prompt).content\n",
    "        \n",
    "        #ì¤„ë°”ê¿ˆ ì²˜ë¦¬: 80ì ì´ìƒ ë¬¸ì¥ì„ ìë™ ì¤„ë°”ê¿ˆ\n",
    "        lines = answer.split('\\n')\n",
    "        wrapped_lines = []\n",
    "        for line in lines:\n",
    "            if len(line) > 80 and not line.strip().startswith('#'):\n",
    "                # textwrapìœ¼ë¡œ 80ìë§ˆë‹¤ ì¤„ë°”ê¿ˆ\n",
    "                wrapped = textwrap.fill(line, width=80, break_long_words=False, break_on_hyphens=False)\n",
    "                wrapped_lines.append(wrapped)\n",
    "            else:\n",
    "                wrapped_lines.append(line)\n",
    "\n",
    "        answer = '\\n'.join(wrapped_lines)\n",
    "\n",
    "        # 7. ì°¸ê³  ë²•ë ¹ ì¶”ê°€\n",
    "        answer += \"\\n\\n---\\n**ğŸ“š ì°¸ê³  ë²•ë ¹ ë° ì‚¬ë¡€:**\\n\"\n",
    "        for i, doc in enumerate(top_docs, 1):\n",
    "            meta = doc.metadata\n",
    "            law_name = meta.get('law_name', meta.get('src_title', '?'))\n",
    "            article = meta.get('article', '')\n",
    "            priority = meta.get('priority', '?')\n",
    "            \n",
    "            answer += f\"{i}. {law_name} {article} (ìš°ì„ ìˆœìœ„: {priority})\\n\"\n",
    "        \n",
    "        answer += \"\\nâš ï¸ ë³¸ ë‹µë³€ì€ AI ë¶„ì„ ê²°ê³¼ë¡œ, ìµœì¢… ê²°ì • ì „ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\"\n",
    "        \n",
    "        return answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "print(\"âœ… í†µí•© RAG ì§ˆì˜ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 í†µê³„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Pinecone ì¸ë±ìŠ¤ í†µê³„:\n",
      "\n",
      "ğŸ“Œ housing-law-index:\n",
      "   - ì´ ë²¡í„°: 19\n",
      "   - ì°¨ì›: 4096\n",
      "\n",
      "ğŸ“Œ housing-rule-index:\n",
      "   - ì´ ë²¡í„°: 4\n",
      "   - ì°¨ì›: 4096\n",
      "\n",
      "ğŸ“Œ housing-case-index:\n",
      "   - ì´ ë²¡í„°: 160\n",
      "   - ì°¨ì›: 4096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ê° ì¸ë±ìŠ¤ í†µê³„ í™•ì¸\n",
    "print(\"ğŸ“Š Pinecone ì¸ë±ìŠ¤ í†µê³„:\\n\")\n",
    "\n",
    "for idx_name in [LAW_INDEX_NAME, RULE_INDEX_NAME, CASE_INDEX_NAME]:\n",
    "    try:\n",
    "        idx = pc.Index(idx_name)\n",
    "        stats = idx.describe_index_stats()\n",
    "        print(f\"ğŸ“Œ {idx_name}:\")\n",
    "        print(f\"   - ì´ ë²¡í„°: {stats['total_vector_count']}\")\n",
    "        print(f\"   - ì°¨ì›: {stats['dimension']}\")\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {idx_name}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì™„ë£Œ\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„:**\n",
    "1. Django ì›¹ ì•± í†µí•©\n",
    "2. í‚¤ì›Œë“œ ê¸°ë°˜ ì¸ë±ìŠ¤ ë¼ìš°íŒ… ì¶”ê°€\n",
    "3. Cohere Rerank ë„ì… (ì˜µì…˜)\n",
    "4. RAGAS í‰ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
