{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3410cd46-8bde-4451-81ee-4c8494246cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI & Pinecone 연결 완료\n",
      "   - Index: realestate\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# === 환경변수 읽기 ===\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "# === 환경변수 검증 (중요!) ===\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"❌ OPENAI_API_KEY가 설정되지 않았습니다.\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"❌ PINECONE_API_KEY가 설정되지 않았습니다.\")\n",
    "if not PINECONE_INDEX_NAME:\n",
    "    raise ValueError(\"❌ PINECONE_INDEX_NAME가 설정되지 않았습니다 (.env 확인).\")\n",
    "\n",
    "# === 클라이언트 생성 ===\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "# === 모델 설정 ===\n",
    "EMBED_MODEL = \"text-embedding-3-large\"   # 3072-dim\n",
    "CHAT_MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "print(\"✅ OpenAI & Pinecone 연결 완료\")\n",
    "print(\"   - Index:\", PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16989a7d-03ea-4417-878c-eb6e0a16258d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c448ae32-567a-477b-97ee-9dc294fe5bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7c515-f014-42f0-b577-b1032fa038e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4386e86a-905f-48f9-a56e-7addd1a6ee46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ca7a3-ebc7-4d58-9a43-69012351fe5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d04b75-981a-4dcc-b72e-f04d8893f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_query(text: str):\n",
    "    res = client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=text\n",
    "    )\n",
    "    return res.data[0].embedding\n",
    "\n",
    "\n",
    "def search_docs(query: str, top_k=8, min_score=0.45):\n",
    "    v = embed_query(query)\n",
    "    res = index.query(\n",
    "        vector=v,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return [m for m in res[\"matches\"] if m[\"score\"] >= min_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a40c31-0d7c-4f87-9f0d-4e0929ffb4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5afa59f-c0be-4448-a1b5-503d28ccca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_RULES = \"\"\"\n",
    "너는 오직 제공된 [근거]만으로 답한다.\n",
    "- 근거에 없는 사실/법리/절차/판례/조문을 절대 추가하지 마라.\n",
    "- 결론은 근거 문장을 최대한 그대로 재구성해라(새 표현 최소화).\n",
    "- 반드시 근거 문장을 따옴표로 2~3개 인용해라.\n",
    "- 불확실하면 '근거 부족'이라고 말해라.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def answer_with_rag(query: str, return_matches=False):\n",
    "    matches = search_docs(query)\n",
    "    if not matches:\n",
    "        return (\"근거 부족: 관련 문서를 찾지 못했습니다.\", matches) if return_matches else \"근거 부족: 관련 문서를 찾지 못했습니다.\"\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"[근거 {i+1} | score={m['score']:.3f}] {m['metadata'].get('text','')}\"\n",
    "        for i, m in enumerate(matches)\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"{RAG_RULES}\n",
    "\n",
    "\n",
    "\n",
    "[근거]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{query}\n",
    "\n",
    "[출력 형식]\n",
    "1) 결론\n",
    "2) 근거 인용(따옴표 2~3개)\n",
    "3) 요약(3줄 이내)\n",
    "4) 근거 부족한 부분(있으면)\n",
    "\"\"\"\n",
    "\n",
    "    res = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53f9cc-8c29-4a37-9d01-7c698949c56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef818a0e-0abe-4fea-a6f9-e3ffd730e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 결론  \n",
      "임대인이 전세사기 재판 중이거나 주택에 압류·가압류가 있거나 경매 진행 중인 경우, 임대차계약 해지는 일반적으로 어렵고, 해지권이 발생한다고 볼 수 없으나, 임차인이 전세사기 피해자로 결정되면 신뢰관계 파괴로 계약 해지가 가능할 수 있으며, 경매 진행 시 임차인이 권리신고와 배당요구를 하면 임대차계약 해지와 같은 효력이 발생합니다.\n",
      "\n",
      "2) 근거 인용  \n",
      "\"임대인의 파산이나 회생신청 등, 가압류, 압류, 근저당권설정 등과 같은 사유를 사정변경에 의한 해지사유로 보기는 어려우므로 임대차계약이 종료되려면 기간만료를 기다려야 하는 것이 일반적입니다.\"  \n",
      "\"임차인 A의 경우와 같이 ①임대인이 전세사기 가해자가 되어 형사소추를 받고 있는 경우, 아직 이에 관한 사례는 없으나 임차인이 전세사기 피해자로 결정이 된다면 신뢰관계 파괴로 보아 임대차계약을 해지할 수 있을 가능성이 있으며,\"  \n",
      "\"다만 본 건물이 경·공매진행시 임차인이 권리신고와 배당요구를 하면 임대차계약을 해지한 것과 같은 효력이 있습니다(대법원 94다37646 판결).\"\n",
      "\n",
      "3) 요약  \n",
      "- 임대인의 압류·가압류 등은 해지사유로 보기 어렵다.  \n",
      "- 임대인이 전세사기 가해자로 형사재판 중이라도 해지 가능성은 피해자 결정 시에 한정된다.  \n",
      "- 경매 진행 시 권리신고와 배당요구를 하면 해지와 같은 효력이 발생한다.\n",
      "\n",
      "4) 근거 부족한 부분  \n",
      "임대인이 전세사기 재판 중인 경우 해지 가능성에 대한 구체적 판례나 명확한 법리 근거는 부족하다.\n"
     ]
    }
   ],
   "source": [
    "print(answer_with_rag(\n",
    "    \"임대인이 전세사기 재판 중이거나 주택에 압류·가압류가 있거나 경매 진행 중이면 계약 해지가 가능한가?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d473b9f-1d18-401f-896f-62d6bed6b96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c66182-2949-45e4-ba2b-5ee3ce28b353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81acf31c-c0e1-4ee7-a0fc-eb231fc1e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.594979346\n",
      "2000다69026 판결) 양도인과 양수인 모두가 보증금반환의무가 있고, 임\n",
      "62\n",
      "차인의 대항력과 우선변제권도 그대로 유지된다할 것입니다.\n",
      "그리하여 임차인 A나 B는 소유권이 이전된 사실을 알게 된 날로부터 상당한 기간내에 이\n",
      "의를 제기하면 임대인 전소유자는 보증금반환 채무가 있고, 현소유자(C)법인은 임차보증금\n",
      "을 변제할 채무를 전소유자와 병존적으로 부담하는 것이므로, 전소유자와 C법인을 상대로\n",
      "보증금반환소송을 제기하면 될 것입니다.\n",
      "(참고로 임대인의 승계사실에 이의를 제기하면 현소유자는 보증금반환 책임이 없고 전소유자만 책\n",
      "임을\n",
      "------------------------------------------------------------\n",
      "score: 0.576351225\n",
      "(참고로 임대인의 승계사실에 이의를 제기하면 현소유자는 보증금반환 책임이 없고 전소유자만 책 임을 부담한다는 하급심 판결이 있으나, 변론주의 원칙상 주택매매시 보증금 공제사실과 병존적 채 무인수를 주장·입증하면 전소유자와 현소유자가 공동책임을 부담할 것입니다.) * 채무인수 의 종류는 면책적채무인수와 병존적 채무인수가 있습니다. 1. 면책적 채무인수란채무를 인수함에 있어서 종전 채무자는 채무를 면하고 인수인만이 채무를 부담하는 채무인수 방법인데, 이때에는 반드시 채권자의 승낙이 있어야만 면책적 채무인수가 될 수 있습니다. 2. **\n",
      "------------------------------------------------------------\n",
      "score: 0.575548232\n",
      "임대인이 제1항제8호의 사유로 갱신을 거절하였음에도 불구하고 갱신요구가 거절되지 아니하였더라면 갱신되었을 기간이 만료되기 전에 정당한 사유 없이 제3자에게 목적 주택을 임대한 경우 임대인은 갱신거절로 인하여 임차인이 입은 손해를 배상하여야 한다.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "matches = search_docs(\"임대차계약 해지 사유\")\n",
    "for m in matches[:3]:\n",
    "    print(\"score:\", m[\"score\"])\n",
    "    print(m[\"metadata\"][\"text\"][:300])\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d855c92-550b-4530-80f3-ffbd04c7bf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96ed5e3b-78fe-4265-a9e9-2ad0c90736c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U python-dotenv openai pinecone langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "744404ea-8cd9-4e63-a8d7-9d969b474778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 업서트 중...\n",
      "{'doc_id': 'contract_v1', 'chunks': 1}\n",
      "\n",
      "2) RAG 답변:\n",
      "\n",
      "- 리스크 요약: 손해배상 한도가 연간 계약 금액의 100%로 제한되어 있어, 특정 상황에서 무제한 책임을 질 수 있다.\n",
      "\n",
      "- 주요 리스크\n",
      "  - 근거: \"본 계약의 손해배상 한도는 연간 계약 금액의 100%로 한다.\"\n",
      "  - 영향: 계약 금액을 초과하는 손해가 발생할 경우, 추가적인 손해에 대한 배상이 불가능해 재정적 부담이 커질 수 있다.\n",
      "  - 권고 조치: 손해배상 한도를 명확히 하고, 고의 또는 중과실, 비밀유지 위반, 지식재산권 침해와 같은 상황에 대한 책임 범위를 구체적으로 정의하는 조항을 추가하는 것이 필요하다.\n",
      "\n",
      "- 추가로 확인할 질문: 고의 또는 중과실의 정의와 판단 기준은 무엇인가?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 0) 환경 로드\n",
    "# ---------------------------\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "if not OPENAI_API_KEY or not PINECONE_API_KEY or not PINECONE_INDEX_NAME:\n",
    "    raise ValueError(\"OPENAI_API_KEY / PINECONE_API_KEY / PINECONE_INDEX_NAME 를 .env에 설정해줘.\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 1) 임베딩 유틸\n",
    "# ---------------------------\n",
    "def embed_text(text: str) -> list[float]:\n",
    "    resp = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",  # ✅ 3072 dim\n",
    "        input=text\n",
    "    )\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2) 문서 -> 청크 -> 업서트\n",
    "# ---------------------------\n",
    "def upsert_document(\n",
    "    doc_id: str,\n",
    "    text: str,\n",
    "    namespace: str = \"default\",\n",
    "    chunk_size: int = 800,\n",
    "    chunk_overlap: int = 120,\n",
    "):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    vectors = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        vec = embed_text(chunk)\n",
    "        vectors.append({\n",
    "            \"id\": f\"{doc_id}::chunk{i}\",\n",
    "            \"values\": vec,\n",
    "            \"metadata\": {\n",
    "                \"doc_id\": doc_id,\n",
    "                \"chunk_id\": i,\n",
    "                \"text\": chunk,\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # 배치 업서트\n",
    "    index.upsert(vectors=vectors, namespace=namespace)\n",
    "    return {\"doc_id\": doc_id, \"chunks\": len(chunks)}\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3) 검색\n",
    "# ---------------------------\n",
    "def retrieve(\n",
    "    query: str,\n",
    "    namespace: str = \"default\",\n",
    "    top_k: int = 5,\n",
    "):\n",
    "    qvec = embed_text(query)\n",
    "    res = index.query(\n",
    "        vector=qvec,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace,\n",
    "    )\n",
    "\n",
    "    contexts = []\n",
    "    for m in res.matches or []:\n",
    "        md = m.metadata or {}\n",
    "        contexts.append({\n",
    "            \"score\": m.score,\n",
    "            \"doc_id\": md.get(\"doc_id\"),\n",
    "            \"chunk_id\": md.get(\"chunk_id\"),\n",
    "            \"text\": md.get(\"text\", \"\"),\n",
    "        })\n",
    "    return contexts\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4) LLM 응답 (RAG)\n",
    "# ---------------------------\n",
    "SYSTEM = \"\"\"너는 계약서/정책 문서를 검토하는 실무형 어시스턴트다.\n",
    "주어진 근거(context) 안에서만 답하고, 근거가 부족하면 '근거 부족'이라고 말한다.\n",
    "출력은 한국어로, 핵심 리스크/근거/권고조치 형태로 정리한다.\n",
    "\"\"\"\n",
    "\n",
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    namespace: str = \"default\",\n",
    "    top_k: int = 5,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "):\n",
    "    ctxs = retrieve(question, namespace=namespace, top_k=top_k)\n",
    "\n",
    "    context_block = \"\\n\\n\".join(\n",
    "        [f\"[doc={c['doc_id']} chunk={c['chunk_id']} score={c['score']:.3f}]\\n{c['text']}\"\n",
    "         for c in ctxs]\n",
    "    ) or \"(검색 결과 없음)\"\n",
    "\n",
    "    prompt = f\"\"\"아래 context를 근거로 질문에 답해줘.\n",
    "\n",
    "[context]\n",
    "{context_block}\n",
    "\n",
    "[question]\n",
    "{question}\n",
    "\n",
    "[output format]\n",
    "- 리스크 요약(한 줄)\n",
    "- 주요 리스크(불릿 3~7개)\n",
    "  - 근거: (doc/chunk 인용)\n",
    "  - 영향\n",
    "  - 권고 조치\n",
    "- 추가로 확인할 질문(있다면)\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": resp.choices[0].message.content\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5) 데모 실행\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sample_doc = \"\"\"\n",
    "    본 계약의 손해배상 한도는 연간 계약 금액의 100%로 한다.\n",
    "    단, 고의 또는 중과실, 비밀유지 위반, 지식재산권 침해의 경우 손해배상 한도를 적용하지 않는다.\n",
    "    계약 해지는 30일 전 서면 통지로 가능하다.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"1) 업서트 중...\")\n",
    "    print(upsert_document(doc_id=\"contract_v1\", text=sample_doc, namespace=\"contracts\"))\n",
    "\n",
    "    q = \"손해배상 한도 조항에서 우리에게 불리한 리스크가 뭐야?\"\n",
    "    print(\"\\n2) RAG 답변:\\n\")\n",
    "    out = answer_with_rag(q, namespace=\"contracts\", top_k=5)\n",
    "    print(out[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346f918-ed6f-4aac-94e1-94b8c8435ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7e5cb-9d04-4a86-9b9e-2db7e31f1ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0c9c3-f5d9-4bd9-be9d-ca0d0332a27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd72b51-b93e-4b44-885e-c42b6fdf2221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
