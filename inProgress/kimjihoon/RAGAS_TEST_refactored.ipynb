{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4decb793",
   "metadata": {},
   "source": [
    "# RAGAS Evaluation Notebook (Clean)\n",
    "\n",
    "This notebook evaluates **baseline vs experiment** RAG pipelines using RAGAS and saves **summary/detail** outputs per run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf76203-b1ff-4ee3-b17e-06004982adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdaa3541-ee50-497b-81cd-91c2274ba4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ragas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e3c80",
   "metadata": {},
   "source": [
    "## 0) Environment & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3772574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded .env from: C:\\ai\\source\\chatbot_app\\.env\n",
      "âœ… sys.path[0] = C:\\ai\\source\\chatbot_app\\modules\n",
      "âœ… rag_module.py exists: True\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# === Project paths (edit if needed) ===\n",
    "PROJECT_ROOT = Path(r\"C:\\ai\\source\\chatbot_app\")\n",
    "MODULES_DIR  = PROJECT_ROOT / \"modules\"\n",
    "ENV_PATH     = PROJECT_ROOT / \".env\"\n",
    "\n",
    "# Add modules dir so we can import rag_module.py\n",
    "sys.path.insert(0, str(MODULES_DIR))\n",
    "\n",
    "# Load .env (optional but recommended)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(ENV_PATH)\n",
    "    print(f\"âœ… Loaded .env from: {ENV_PATH}\")\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ dotenv load failed (can continue):\", e)\n",
    "\n",
    "print(\"âœ… sys.path[0] =\", sys.path[0])\n",
    "print(\"âœ… rag_module.py exists:\", (MODULES_DIR / \"rag_module.py\").exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0093e",
   "metadata": {},
   "source": [
    "## 1) Load testset (JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8108580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… rows: 1\n",
      "âœ… keys example: dict_keys(['question', 'ground_truth'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì „ì…ì‹ ê³ Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?</td>\n",
       "      <td>ë„¤, ì¤‘ìš”í•©ë‹ˆë‹¤. í™•ì •ì¼ìë¥¼ ë°›ì•˜ë‹¤ëŠ” ì‚¬ì‹¤ë§Œìœ¼ë¡œ ëë‚˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í™•ì •ì¼ìë¶€ì— ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           question  \\\n",
       "0  ì „ì…ì‹ ê³ Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  ë„¤, ì¤‘ìš”í•©ë‹ˆë‹¤. í™•ì •ì¼ìë¥¼ ë°›ì•˜ë‹¤ëŠ” ì‚¬ì‹¤ë§Œìœ¼ë¡œ ëë‚˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í™•ì •ì¼ìë¶€ì— ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TESTSET_JSONL = PROJECT_ROOT / \"ragas_testset_one.jsonl\"  # change if needed\n",
    "assert TESTSET_JSONL.exists(), f\"âŒ JSONL not found: {TESTSET_JSONL}\"\n",
    "\n",
    "rows = []\n",
    "with open(TESTSET_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        rows.append(json.loads(line))\n",
    "\n",
    "print(\"âœ… rows:\", len(rows))\n",
    "print(\"âœ… keys example:\", rows[0].keys())\n",
    "pd.DataFrame(rows[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1529b4",
   "metadata": {},
   "source": [
    "## 2) Define baseline & experiment configs\n",
    "\n",
    "- Keep **base_cfg** stable.\n",
    "- Only put **changed knobs** in `exp_cfg = replace(base_cfg, ...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c6ca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RAGConfig(normalize_model='solar-pro2', generation_model='gpt-4o-mini', temperature=0.1, normalize_temperature=0.0, embedding_backend='upstage', embedding_model='solar-embedding-1-large-passage', k_law=5, k_rule=5, k_case=3, search_multiplier=2, enable_bm25=True, sparse_mode='auto', sparse_k_law=None, sparse_k_rule=None, sparse_k_case=None, bm25_algorithm='okapi', bm25_k1=1.5, bm25_b=0.75, bm25_use_kiwi=True, bm25_max_doc_chars=2400, enable_bm25_title=True, bm25_title_field='title', bm25_title_max_chars=512, hybrid_sparse_title_ratio=0.35, hybrid_fusion='rrf', hybrid_dense_weight=0.6, hybrid_sparse_weight=0.4, rrf_k=60, enable_rerank=True, rerank_threshold=0.2, rerank_model='rerank-multilingual-v3.0', rerank_max_documents=20, rerank_doc_max_chars=2400, case_candidate_k=40, case_expand_top_n=None, case_context_top_k=50, dedupe_key_fields=('chunk_id', 'id')),\n",
       " RAGConfig(normalize_model='solar-pro2', generation_model='gpt-4o-mini', temperature=0.1, normalize_temperature=0.0, embedding_backend='upstage', embedding_model='solar-embedding-1-large-passage', k_law=5, k_rule=5, k_case=3, search_multiplier=2, enable_bm25=True, sparse_mode='auto', sparse_k_law=None, sparse_k_rule=None, sparse_k_case=None, bm25_algorithm='okapi', bm25_k1=1.5, bm25_b=0.75, bm25_use_kiwi=True, bm25_max_doc_chars=2400, enable_bm25_title=True, bm25_title_field='title', bm25_title_max_chars=512, hybrid_sparse_title_ratio=0.45, hybrid_fusion='rrf', hybrid_dense_weight=0.5, hybrid_sparse_weight=0.5, rrf_k=60, enable_rerank=True, rerank_threshold=0.2, rerank_model='rerank-multilingual-v3.0', rerank_max_documents=20, rerank_doc_max_chars=2400, case_candidate_k=40, case_expand_top_n=None, case_context_top_k=50, dedupe_key_fields=('chunk_id', 'id')))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import replace\n",
    "from rag_module import RAGConfig\n",
    "\n",
    "# =========================\n",
    "# Base config (edit as needed)\n",
    "# =========================\n",
    "base_cfg = RAGConfig(\n",
    "    # ---- LLM ----\n",
    "    normalize_model=\"solar-pro2\",\n",
    "    generation_model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    normalize_temperature=0.0,\n",
    "\n",
    "    # ---- Embedding ----\n",
    "    embedding_backend=\"upstage\",\n",
    "    embedding_model=\"solar-embedding-1-large-passage\",\n",
    "\n",
    "    # ---- Dense Retrieval ----\n",
    "    k_law=5,\n",
    "    k_rule=5,\n",
    "    k_case=3,\n",
    "    search_multiplier=2,\n",
    "\n",
    "    # ---- BM25 / Sparse ----\n",
    "    enable_bm25=True,\n",
    "\n",
    "    # ---- Rerank ----\n",
    "    enable_rerank=True,\n",
    "    rerank_threshold=0.2,\n",
    "    rerank_max_documents=20,\n",
    "\n",
    "    # ---- Output trimming ----\n",
    "    bm25_max_doc_chars=2400,\n",
    "    rerank_doc_max_chars=2400,\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Experiment config (only diffs here)\n",
    "# =========================\n",
    "exp_cfg = replace(\n",
    "    base_cfg,\n",
    "    hybrid_dense_weight=0.5,\n",
    "    hybrid_sparse_weight=0.5,\n",
    "    hybrid_sparse_title_ratio=0.45,\n",
    ")\n",
    "\n",
    "base_cfg, exp_cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fbbb5",
   "metadata": {},
   "source": [
    "## 3) Build pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0f69f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 17:34:22,659 - rag_module - INFO - ğŸ”— Pinecone 3ì¤‘ ì¸ë±ìŠ¤ ì—°ê²° ì¤‘...\n",
      "2026-01-30 17:34:22,661 - rag_module - INFO - âœ… [Law / Rule / Case] 3ê°œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "2026-01-30 17:34:23,047 - rag_module - INFO - âœ… Kiwi í† í¬ë‚˜ì´ì € ì‚¬ìš© (BM25)\n",
      "2026-01-30 17:34:24,334 - rag_module - INFO - ğŸ”— Pinecone 3ì¤‘ ì¸ë±ìŠ¤ ì—°ê²° ì¤‘...\n",
      "2026-01-30 17:34:24,334 - rag_module - INFO - âœ… [Law / Rule / Case] 3ê°œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "2026-01-30 17:34:24,740 - rag_module - INFO - âœ… Kiwi í† í¬ë‚˜ì´ì € ì‚¬ìš© (BM25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… pipelines ready\n"
     ]
    }
   ],
   "source": [
    "from rag_module import create_pipeline\n",
    "\n",
    "base_pipe = create_pipeline(config=base_cfg)\n",
    "exp_pipe  = create_pipeline(config=exp_cfg)\n",
    "\n",
    "print(\"âœ… pipelines ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6dfb91",
   "metadata": {},
   "source": [
    "## 4) (Optional) Quick trace sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85371f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ Skip or customize depending on your pipeline API.\n"
     ]
    }
   ],
   "source": [
    "# If your rag_module exposes a trace / debug method, call it here.\n",
    "# Otherwise you can skip this cell.\n",
    "\n",
    "# Example (adjust to your actual API):\n",
    "# ans, trace = base_pipe.answer_with_trace(\"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ...\")\n",
    "# display(trace)\n",
    "\n",
    "print(\"â„¹ï¸ Skip or customize depending on your pipeline API.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16739f05",
   "metadata": {},
   "source": [
    "## 5) Build RAGAS samples from your pipeline outputs\n",
    "\n",
    "This converts each testset row into the RAGAS format:\n",
    "- `question`\n",
    "- `answer`\n",
    "- `contexts` (list[str])\n",
    "- `ground_truth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a8d6173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 17:36:21,369 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:21,383 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€(í™•ì •ì¼ìë¶€) ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?\n",
      "2026-01-30 17:36:21,384 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì£¼ë¯¼ë“±ë¡Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€(í™•ì •ì¼ìë¶€) ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?'\n",
      "2026-01-30 17:36:21,898 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:24,071 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:26,341 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:31,165 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:31,187 - rag_module - INFO - ğŸ“Œ Rerank selected=2 (threshold=0.2)\n",
      "2026-01-30 17:36:31,188 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-01-30 17:36:38,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:39,081 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:39,085 - rag_module - INFO - ğŸ”„ í‘œì¤€í™”ëœ ì§ˆë¬¸: ì „ì…ì‹ ê³ (ì£¼ë¯¼ë“±ë¡)Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€(í™•ì •ì¼ì) ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?\n",
      "2026-01-30 17:36:39,086 - rag_module - INFO - ğŸ” [Hybrid Retrieval] query='ì „ì…ì‹ ê³ (ì£¼ë¯¼ë“±ë¡)Â·í™•ì •ì¼ì(í™•ì •ì¼ì) í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€(í™•ì •ì¼ì) ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?'\n",
      "2026-01-30 17:36:39,716 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:42,056 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:44,220 - httpx - INFO - HTTP Request: POST https://api.upstage.ai/v1/solar/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:48,983 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:36:48,991 - rag_module - INFO - ğŸ“Œ Rerank selected=3 (threshold=0.2)\n",
      "2026-01-30 17:36:48,993 - rag_module - INFO - ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
      "2026-01-30 17:36:56,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BASE_SAMPLES: 1\n",
      "âœ… EXP_SAMPLES : 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì „ì…ì‹ ê³ Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?</td>\n",
       "      <td>A. í™•ì •ì¼ìë¶€ì˜ ë‚´ìš©ì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.\\n\\nB. ì§€ê¸ˆ ë‹¹ì¥ í•  ì¼\\n   - ...</td>\n",
       "      <td>[page_content='â‘  ì œ3ì¡°ì˜2ì œ2í•­ì˜ í™•ì •ì¼ìëŠ” ì£¼íƒ ì†Œì¬ì§€ì˜ ìã†ë©´ì‚¬ë¬´...</td>\n",
       "      <td>ë„¤, ì¤‘ìš”í•©ë‹ˆë‹¤. í™•ì •ì¼ìë¥¼ ë°›ì•˜ë‹¤ëŠ” ì‚¬ì‹¤ë§Œìœ¼ë¡œ ëë‚˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í™•ì •ì¼ìë¶€ì— ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           question  \\\n",
       "0  ì „ì…ì‹ ê³ Â·í™•ì •ì¼ì í–ˆëŠ”ë°, í™•ì •ì¼ìë¶€ ë‚´ìš©ê¹Œì§€ ì¤‘ìš”í•œê°€ìš”?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  A. í™•ì •ì¼ìë¶€ì˜ ë‚´ìš©ì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.\\n\\nB. ì§€ê¸ˆ ë‹¹ì¥ í•  ì¼\\n   - ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [page_content='â‘  ì œ3ì¡°ì˜2ì œ2í•­ì˜ í™•ì •ì¼ìëŠ” ì£¼íƒ ì†Œì¬ì§€ì˜ ìã†ë©´ì‚¬ë¬´...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  ë„¤, ì¤‘ìš”í•©ë‹ˆë‹¤. í™•ì •ì¼ìë¥¼ ë°›ì•˜ë‹¤ëŠ” ì‚¬ì‹¤ë§Œìœ¼ë¡œ ëë‚˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í™•ì •ì¼ìë¶€ì— ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shrink_contexts(ctxs, max_chars=2400, max_contexts=30):\n",
    "    out = []\n",
    "    for c in (ctxs or []):\n",
    "        if c is None:\n",
    "            continue\n",
    "        s = str(c).strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        out.append(s[:max_chars])\n",
    "        if len(out) >= max_contexts:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def row_get_ground_truth(r: dict):\n",
    "    return r.get(\"ground_truth\") or r.get(\"reference\") or r.get(\"gt\") or r.get(\"answer\")\n",
    "\n",
    "def run_pipe_to_samples(pipe, rows, max_chars=2400, max_contexts=30, limit=None):\n",
    "    samples = []\n",
    "    n = len(rows) if limit is None else min(limit, len(rows))\n",
    "\n",
    "    for i in range(n):\n",
    "        r = rows[i]\n",
    "        q = r.get(\"question\") or r.get(\"query\")\n",
    "        if not q:\n",
    "            continue\n",
    "\n",
    "        # âœ… ë„¤ íŒŒì´í”„ë¼ì¸ì€ ì´ê±¸ë¡œ í˜¸ì¶œí•´ì•¼ í•¨\n",
    "        out = pipe.answer_with_trace(q)\n",
    "\n",
    "        # outì´ dictì¼ ìˆ˜ë„ ìˆê³ , (answer, ctxs, trace) íŠœí”Œì¼ ìˆ˜ë„ ìˆì–´ì„œ ì•ˆì „ ì²˜ë¦¬\n",
    "        ans, ctxs, trace = \"\", [], None\n",
    "\n",
    "        if isinstance(out, dict):\n",
    "            ans = out.get(\"answer\") or out.get(\"result\") or out.get(\"output\") or out.get(\"text\") or \"\"\n",
    "            ctxs = out.get(\"contexts\") or out.get(\"context\") or out.get(\"docs\") or []\n",
    "            trace = out.get(\"trace\") or out.get(\"debug\") or out.get(\"meta\")\n",
    "        elif isinstance(out, tuple):\n",
    "            # í”í•œ íŒ¨í„´ë“¤ ëŒ€ì‘\n",
    "            if len(out) == 3:\n",
    "                ans, ctxs, trace = out\n",
    "            elif len(out) == 2:\n",
    "                ans, ctxs = out\n",
    "            elif len(out) == 1:\n",
    "                ans = out[0]\n",
    "        else:\n",
    "            ans = str(out)\n",
    "\n",
    "        samples.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": ans or \"\",\n",
    "            \"contexts\": shrink_contexts(ctxs, max_chars=max_chars, max_contexts=max_contexts),\n",
    "            \"ground_truth\": row_get_ground_truth(r) or \"\",\n",
    "            \"_trace\": trace,  # âœ… traceë„ ê°™ì´ ë³´ê´€(ì›í•˜ë©´ ì €ì¥ ê°€ëŠ¥)\n",
    "        })\n",
    "\n",
    "    return samples\n",
    "\n",
    "# âœ… ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸: 1ë¬¸ì œë§Œ\n",
    "BASE_SAMPLES = run_pipe_to_samples(base_pipe, rows, max_chars=2400, max_contexts=30, limit=1)\n",
    "EXP_SAMPLES  = run_pipe_to_samples(exp_pipe,  rows, max_chars=2400, max_contexts=30, limit=1)\n",
    "\n",
    "print(\"âœ… BASE_SAMPLES:\", len(BASE_SAMPLES))\n",
    "print(\"âœ… EXP_SAMPLES :\", len(EXP_SAMPLES))\n",
    "pd.DataFrame([{k:v for k,v in BASE_SAMPLES[0].items() if k != \"_trace\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a3c26",
   "metadata": {},
   "source": [
    "## 6) RAGAS evaluation (prepared cell)\n",
    "\n",
    "- Creates per-sample detail dataframe (when supported by your RAGAS version)\n",
    "- Creates summary dataframe (mean over samples)\n",
    "- Keeps timing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10a15582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RAGAS compare + clean saving (no deprecated imports/wrappers)\n",
    "# - metrics: ragas.metrics.collections\n",
    "# - LLM: ragas.llms.llm_factory (no LangchainLLMWrapper)\n",
    "# - saves: summary/detail/meta + config.json + samples_base/exp.jsonl + trace.jsonl\n",
    "# - run dir: auto-increment + timestamp\n",
    "# ============================================================\n",
    "\n",
    "import time, json, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from openai import OpenAI\n",
    "from ragas import evaluate\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.metrics.collections import ContextPrecision, ContextRecall, Faithfulness, AnswerRelevancy\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# LLM + METRICS (non-deprecated)\n",
    "# ----------------------------\n",
    "client = OpenAI()  # uses OPENAI_API_KEY env var\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "\n",
    "METRICS = [\n",
    "    ContextPrecision(llm=llm),\n",
    "    ContextRecall(llm=llm),\n",
    "    Faithfulness(llm=llm),\n",
    "]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# utils\n",
    "# ----------------------------\n",
    "def _json_safe(obj):\n",
    "    \"\"\"Make config/meta safe to dump to json.\"\"\"\n",
    "    try:\n",
    "        json.dumps(obj, ensure_ascii=False)\n",
    "        return obj\n",
    "    except TypeError:\n",
    "        if hasattr(obj, \"model_dump\"):\n",
    "            return obj.model_dump()\n",
    "        if hasattr(obj, \"dict\"):\n",
    "            return obj.dict()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "\n",
    "def _write_json(path: Path, data):\n",
    "    path.write_text(json.dumps(_json_safe(data), ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def _write_jsonl(path: Path, rows):\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(_json_safe(r), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _next_run_dir(project_root: Path, prefix: str):\n",
    "    runs_root = Path(project_root) / \"results\" / \"ragas_runs\"\n",
    "    runs_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Find existing {prefix}_0001_* directories\n",
    "    pat = re.compile(rf\"^{re.escape(prefix)}_(\\d{{4}})_\")\n",
    "    nums = []\n",
    "    for p in runs_root.iterdir():\n",
    "        if p.is_dir():\n",
    "            m = pat.match(p.name)\n",
    "            if m:\n",
    "                nums.append(int(m.group(1)))\n",
    "    next_idx = (max(nums) + 1) if nums else 1\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = runs_root / f\"{prefix}_{next_idx:04d}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=False)\n",
    "    return run_dir, next_idx, ts\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# core eval\n",
    "# ----------------------------\n",
    "def eval_ragas_with_details(samples, run_tag: str):\n",
    "    ds = Dataset.from_list(samples)\n",
    "\n",
    "    t0 = time.time()\n",
    "    res = evaluate(dataset=ds, metrics=METRICS)\n",
    "    eval_sec = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    detail_df = res.to_pandas() if hasattr(res, \"to_pandas\") else pd.DataFrame()\n",
    "    to_pandas_sec = time.time() - t1\n",
    "\n",
    "    samples_df = pd.DataFrame(samples)\n",
    "\n",
    "    # merge per-sample metrics back onto samples\n",
    "    if len(detail_df) == len(samples_df) and len(detail_df) > 0:\n",
    "        out_detail = pd.concat(\n",
    "            [samples_df.reset_index(drop=True), detail_df.reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        out_detail = samples_df.copy()\n",
    "\n",
    "    out_detail[\"run_tag\"] = run_tag\n",
    "    out_detail[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    out_detail[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    # summary (mean of numeric metric columns if available)\n",
    "    summary = {}\n",
    "    if len(detail_df) > 0:\n",
    "        summary = detail_df.mean(numeric_only=True).to_dict()\n",
    "    elif isinstance(res, dict):\n",
    "        summary = {k: float(v) for k, v in res.items() if isinstance(v, (int, float))}\n",
    "\n",
    "    summary[\"run_tag\"] = run_tag\n",
    "    summary[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    summary[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    return res, out_detail, pd.DataFrame([summary])\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# compare + save (clean)\n",
    "# ----------------------------\n",
    "def run_compare_and_save(\n",
    "    base_samples,\n",
    "    exp_samples,\n",
    "    project_root: Path,\n",
    "    prefix=\"ragas_compare\",\n",
    "    base_cfg=None,\n",
    "    exp_cfg=None,\n",
    "):\n",
    "    base_res, base_detail_df, base_summary_df = eval_ragas_with_details(base_samples, \"baseline\")\n",
    "    exp_res,  exp_detail_df,  exp_summary_df  = eval_ragas_with_details(exp_samples,  \"experiment\")\n",
    "\n",
    "    summary_df = pd.concat([base_summary_df, exp_summary_df], ignore_index=True)\n",
    "    detail_df  = pd.concat([base_detail_df,  exp_detail_df],  ignore_index=True)\n",
    "\n",
    "    run_dir, run_id, ts = _next_run_dir(project_root, prefix)\n",
    "\n",
    "    # fixed filenames inside run dir (clean)\n",
    "    out_summary = run_dir / \"summary.csv\"\n",
    "    out_detail  = run_dir / \"detail.csv\"\n",
    "    out_meta    = run_dir / \"meta.json\"\n",
    "    out_config  = run_dir / \"config.json\"\n",
    "    out_base_in = run_dir / \"samples_base.jsonl\"\n",
    "    out_exp_in  = run_dir / \"samples_exp.jsonl\"\n",
    "    out_trace   = run_dir / \"trace.jsonl\"  # best-effort trace\n",
    "\n",
    "    summary_df.to_csv(out_summary, index=False, encoding=\"utf-8-sig\")\n",
    "    detail_df.to_csv(out_detail, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # config snapshot (best-effort)\n",
    "    cfg_payload = {\n",
    "        \"base_cfg\": _json_safe(base_cfg) if base_cfg is not None else None,\n",
    "        \"exp_cfg\":  _json_safe(exp_cfg)  if exp_cfg  is not None else None,\n",
    "        \"llm\": {\"model\": \"gpt-4o-mini\"},\n",
    "        \"metrics\": [\"ContextPrecision\", \"ContextRecall\", \"Faithfulness\", \"AnswerRelevancy\"],\n",
    "    }\n",
    "    _write_json(out_config, cfg_payload)\n",
    "\n",
    "    # input snapshots\n",
    "    _write_jsonl(out_base_in, base_samples)\n",
    "    _write_jsonl(out_exp_in,  exp_samples)\n",
    "\n",
    "    # trace snapshot (best-effort)\n",
    "    # - if your samples include _trace, keep it\n",
    "    trace_rows = []\n",
    "    for s in list(base_samples) + list(exp_samples):\n",
    "        if isinstance(s, dict) and (\"_trace\" in s):\n",
    "            trace_rows.append({\"question\": s.get(\"question\"), \"run_tag\": s.get(\"run_tag\"), \"_trace\": s.get(\"_trace\")})\n",
    "    if not trace_rows:\n",
    "        # fallback: store minimal fields from detail\n",
    "        cols = [c for c in [\"run_tag\", \"question\", \"eval_seconds\"] if c in detail_df.columns]\n",
    "        trace_rows = detail_df[cols].to_dict(orient=\"records\") if cols else []\n",
    "    _write_jsonl(out_trace, trace_rows)\n",
    "\n",
    "    meta = {\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"run_id\": run_id,\n",
    "        \"timestamp\": ts,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"prefix\": prefix,\n",
    "        \"n_base_samples\": len(base_samples),\n",
    "        \"n_exp_samples\": len(exp_samples),\n",
    "        \"saved\": {\n",
    "            \"summary\": str(out_summary),\n",
    "            \"detail\": str(out_detail),\n",
    "            \"meta\": str(out_meta),\n",
    "            \"config\": str(out_config),\n",
    "            \"samples_base\": str(out_base_in),\n",
    "            \"samples_exp\": str(out_exp_in),\n",
    "            \"trace\": str(out_trace),\n",
    "        },\n",
    "    }\n",
    "    _write_json(out_meta, meta)\n",
    "\n",
    "    return {\n",
    "        \"base_res\": base_res,\n",
    "        \"exp_res\": exp_res,\n",
    "        \"summary_df\": summary_df,\n",
    "        \"detail_df\": detail_df,\n",
    "        \"run_dir\": run_dir,\n",
    "        \"out_summary\": out_summary,\n",
    "        \"out_detail\": out_detail,\n",
    "        \"out_meta\": out_meta,\n",
    "        \"out_config\": out_config,\n",
    "        \"out_samples_base\": out_base_in,\n",
    "        \"out_samples_exp\": out_exp_in,\n",
    "        \"out_trace\": out_trace,\n",
    "        \"run_id\": run_id,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee50b62",
   "metadata": {},
   "source": [
    "## 7) Run + compare + save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29525fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13696\\818566082.py:26: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13696\\818566082.py:26: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13696\\818566082.py:26: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import context_precision, context_recall, faithfulness\n",
      "Evaluating:   0%|                                                                                | 0/3 [00:00<?, ?it/s]2026-01-30 17:42:52,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:42:55,806 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:43:05,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:43:14,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:43:31,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:41<00:00, 13.89s/it]\n",
      "Evaluating:   0%|                                                                                | 0/3 [00:00<?, ?it/s]2026-01-30 17:43:37,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:43:40,134 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:43:43,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-30 17:43:53,458 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import time, re, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from openai import OpenAI\n",
    "from ragas import evaluate\n",
    "from ragas.llms import llm_factory\n",
    "\n",
    "# ----------------------------\n",
    "# LLM (non-deprecated)\n",
    "# ----------------------------\n",
    "client = OpenAI()\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "\n",
    "# ----------------------------\n",
    "# METRICS (version-tolerant)\n",
    "# - 1ìˆœìœ„: êµ¬ë²„ì „/í˜¸í™˜ ë†’ì€ \"metric objects\" (context_precision ë“±)\n",
    "# - 2ìˆœìœ„: ì‹ ë²„ì „ \"classes\" (ContextPrecision ë“±)\n",
    "# ----------------------------\n",
    "def build_metrics():\n",
    "    # try older/object style first (most compatible)\n",
    "    try:\n",
    "        from ragas.metrics import context_precision, context_recall, faithfulness\n",
    "        return [context_precision, context_recall, faithfulness]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fallback to class style\n",
    "    from ragas.metrics.collections import ContextPrecision, ContextRecall, Faithfulness\n",
    "    return [ContextPrecision(), ContextRecall(), Faithfulness()]\n",
    "\n",
    "METRICS = build_metrics()\n",
    "\n",
    "def eval_ragas_with_details(samples, run_tag: str):\n",
    "    ds = Dataset.from_list(samples)\n",
    "\n",
    "    t0 = time.time()\n",
    "    res = evaluate(dataset=ds, metrics=METRICS, llm=llm)  # âœ… llmì€ ì—¬ê¸°ë¡œ\n",
    "    eval_sec = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    detail_df = res.to_pandas() if hasattr(res, \"to_pandas\") else pd.DataFrame()\n",
    "    to_pandas_sec = time.time() - t1\n",
    "\n",
    "    samples_df = pd.DataFrame(samples)\n",
    "\n",
    "    # merge\n",
    "    if len(detail_df) == len(samples_df) and len(detail_df) > 0:\n",
    "        out_detail = pd.concat(\n",
    "            [samples_df.reset_index(drop=True), detail_df.reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        out_detail = samples_df.copy()\n",
    "\n",
    "    out_detail[\"run_tag\"] = run_tag\n",
    "    out_detail[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    out_detail[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    # summary\n",
    "    summary = {}\n",
    "    if len(detail_df) > 0:\n",
    "        summary = detail_df.mean(numeric_only=True).to_dict()\n",
    "    elif isinstance(res, dict):\n",
    "        summary = {k: float(v) for k, v in res.items() if isinstance(v, (int, float))}\n",
    "\n",
    "    summary[\"run_tag\"] = run_tag\n",
    "    summary[\"eval_seconds\"] = round(eval_sec, 3)\n",
    "    summary[\"to_pandas_seconds\"] = round(to_pandas_sec, 3)\n",
    "\n",
    "    return res, out_detail, pd.DataFrame([summary])\n",
    "\n",
    "def _next_run_dir(project_root: Path, prefix: str):\n",
    "    runs_root = Path(project_root) / \"results\" / \"ragas_runs\"\n",
    "    runs_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pat = re.compile(rf\"^{re.escape(prefix)}_(\\d{{4}})_\")\n",
    "    nums = []\n",
    "    for p in runs_root.iterdir():\n",
    "        if p.is_dir():\n",
    "            m = pat.match(p.name)\n",
    "            if m:\n",
    "                nums.append(int(m.group(1)))\n",
    "    next_id = (max(nums) + 1) if nums else 1\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = runs_root / f\"{prefix}_{next_id:04d}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=False)\n",
    "    return run_dir\n",
    "\n",
    "def run_compare_and_save(base_samples, exp_samples, project_root: Path, prefix=\"ragas_compare\"):\n",
    "    base_res, base_detail_df, base_summary_df = eval_ragas_with_details(base_samples, \"baseline\")\n",
    "    exp_res,  exp_detail_df,  exp_summary_df  = eval_ragas_with_details(exp_samples,  \"experiment\")\n",
    "\n",
    "    summary_df = pd.concat([base_summary_df, exp_summary_df], ignore_index=True)\n",
    "    detail_df  = pd.concat([base_detail_df,  exp_detail_df],  ignore_index=True)\n",
    "\n",
    "    run_dir = _next_run_dir(project_root, prefix)\n",
    "\n",
    "    # ê¸°ë³¸ ì‚°ì¶œë¬¼ (í•­ìƒ ê°™ì€ íŒŒì¼ëª…)\n",
    "    out_summary = run_dir / \"summary.csv\"\n",
    "    out_detail  = run_dir / \"detail.csv\"\n",
    "    out_meta    = run_dir / \"meta.json\"\n",
    "\n",
    "    summary_df.to_csv(out_summary, index=False, encoding=\"utf-8-sig\")\n",
    "    detail_df.to_csv(out_detail, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    meta = {\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"prefix\": prefix,\n",
    "        \"n_base_samples\": len(base_samples),\n",
    "        \"n_exp_samples\": len(exp_samples),\n",
    "        \"metrics\": [getattr(m, \"__name__\", m.__class__.__name__) for m in METRICS],\n",
    "    }\n",
    "    out_meta.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    return {\n",
    "        \"base_res\": base_res,\n",
    "        \"exp_res\": exp_res,\n",
    "        \"summary_df\": summary_df,\n",
    "        \"detail_df\": detail_df,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        \"out_summary\": str(out_summary),\n",
    "        \"out_detail\": str(out_detail),\n",
    "        \"out_meta\": str(out_meta),\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# RUN (ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ë©´ limit=1 ìƒ˜í”Œë¡œ ë¨¼ì €)\n",
    "# ----------------------------\n",
    "result = run_compare_and_save(\n",
    "    base_samples=BASE_SAMPLES,\n",
    "    exp_samples=EXP_SAMPLES,\n",
    "    project_root=PROJECT_ROOT,\n",
    "    prefix=\"ragas_compare\",\n",
    ")\n",
    "\n",
    "print(\"âœ… run_dir:\", result[\"run_dir\"])\n",
    "print(\"âœ… saved:\", result[\"out_summary\"], result[\"out_detail\"], result[\"out_meta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6845ece-5d8b-47af-8aaf-0a1dc5ef87c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7f586-c190-4912-a1c7-b08b1f1703db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0e570-c6a8-44d7-8628-8f2fb44c5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# ----------------------------\n",
    "# helpers\n",
    "# ----------------------------\n",
    "def _json_safe(obj):\n",
    "    try:\n",
    "        json.dumps(obj, ensure_ascii=False)\n",
    "        return obj\n",
    "    except TypeError:\n",
    "        if hasattr(obj, \"model_dump\"):\n",
    "            return obj.model_dump()\n",
    "        if hasattr(obj, \"dict\"):\n",
    "            return obj.dict()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "\n",
    "def _write_json(path: Path, data):\n",
    "    path.write_text(json.dumps(_json_safe(data), ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def _write_jsonl(path: Path, rows):\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(_json_safe(r), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _df_to_jsonl_rows(df, prefer_cols):\n",
    "    cols = [c for c in prefer_cols if c in df.columns]\n",
    "    if cols:\n",
    "        df = df[cols].copy()\n",
    "    return df.to_dict(orient=\"records\"), cols\n",
    "\n",
    "# ----------------------------\n",
    "# run_dir from result (ì…€1 ì‹¤í–‰ í›„)\n",
    "# ----------------------------\n",
    "run_dir = Path(result[\"run_dir\"])\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) config snapshot\n",
    "# ----------------------------\n",
    "cfg_payload = {}\n",
    "\n",
    "# base_cfg/exp_cfgê°€ ë…¸íŠ¸ë¶ ì „ì—­ì— ìˆìœ¼ë©´ ì €ì¥ (ì—†ìœ¼ë©´ None)\n",
    "cfg_payload[\"base_cfg\"] = _json_safe(globals().get(\"base_cfg\")) if \"base_cfg\" in globals() else None\n",
    "cfg_payload[\"exp_cfg\"]  = _json_safe(globals().get(\"exp_cfg\"))  if \"exp_cfg\"  in globals() else None\n",
    "\n",
    "# llm/metrics ì •ë³´ë„ ê°™ì´ ë‚¨ê¹€(ì¬í˜„ì„±)\n",
    "cfg_payload[\"llm\"] = {\"model\": \"gpt-4o-mini\"}\n",
    "cfg_payload[\"created_at\"] = datetime.now().isoformat()\n",
    "\n",
    "_write_json(run_dir / \"config.json\", cfg_payload)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) input samples snapshot\n",
    "# ----------------------------\n",
    "_write_jsonl(run_dir / \"samples_base.jsonl\", BASE_SAMPLES)\n",
    "_write_jsonl(run_dir / \"samples_exp.jsonl\",  EXP_SAMPLES)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) trace snapshot (from detail_df)\n",
    "# ----------------------------\n",
    "detail_df = result[\"detail_df\"]\n",
    "if not hasattr(detail_df, \"columns\"):\n",
    "    # í˜¹ì‹œ detail_dfê°€ dfê°€ ì•„ë‹ˆë¼ë©´ ì•ˆì „ ì²˜ë¦¬\n",
    "    import pandas as pd\n",
    "    detail_df = pd.DataFrame(detail_df)\n",
    "\n",
    "trace_cols_priority = [\n",
    "    \"id\", \"sample_id\",\n",
    "    \"question\", \"normalized_question\", \"normalized_query\",\n",
    "    \"answer\", \"ground_truth\", \"reference\",\n",
    "    \"contexts\",\n",
    "    \"_trace\",  # âœ… ë„ˆê°€ answer_with_traceì—ì„œ ë„£ì–´ë‘” ê²½ìš°\n",
    "    \"retrieved_doc_ids\", \"retrieved_docs\", \"retrieval_scores\",\n",
    "    \"rerank_selected_ids\", \"rerank_scores\",\n",
    "    \"final_context_ids\", \"final_contexts\",\n",
    "    \"latency_ms\", \"latency_sec\",\n",
    "    \"run_tag\",\n",
    "]\n",
    "\n",
    "trace_rows, used_cols = _df_to_jsonl_rows(detail_df, trace_cols_priority)\n",
    "_write_jsonl(run_dir / \"trace.jsonl\", trace_rows)\n",
    "\n",
    "print(\"âœ… extra saved config :\", run_dir / \"config.json\")\n",
    "print(\"âœ… extra saved samples:\", run_dir / \"samples_base.jsonl\", \"and\", run_dir / \"samples_exp.jsonl\")\n",
    "print(\"âœ… extra saved trace  :\", run_dir / \"trace.jsonl\")\n",
    "print(\"âœ… trace columns used :\", used_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
