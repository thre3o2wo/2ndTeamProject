{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2150eb4c-6284-443d-80ca-4d4079941f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd4353f-cdad-471c-9208-89d019a23722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\llm\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24d8cc6-82cb-4e09-9baf-4283b4ae7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca6ca8a-cddf-4304-af2d-13a1d6c44e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.9\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "print(pdfplumber.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938db90b-17b8-4f1d-8366-33e7cd955510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7608f-d177-4bc0-913f-fed1fbc4aaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db06f65b-73a4-479f-8a3e-b8f5e5ce6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] law.csv 생성 완료 → data\\processed\\law\\law.csv\n",
      "[OK] rule.csv 생성 완료 → data\\processed\\rule\\rule.csv\n",
      "[SKIP] case/pdf 처리는 다음 단계에서 진행\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import uuid\n",
    "from typing import List, Dict\n",
    "from docx import Document\n",
    "\n",
    "# =========================\n",
    "# (1) 설정값\n",
    "# =========================\n",
    "MAX_LEN = 1500  # ✅ 1500자 기준 청킹 상한선\n",
    "\n",
    "# 타입별 우선순위(너가 정한 룰)\n",
    "PRIORITY_MAP = {\n",
    "    \"law\": 1,   # 주택임대차보호법/법률 쪽\n",
    "    \"rule\": 2,  # 시행령/시행규칙/대법원규칙\n",
    "    \"case\": 4,  # 판례(지금은 안 함)\n",
    "}\n",
    "\n",
    "\n",
    "# 내지, 삭제 등 실질 내용이 없는 조문 제거\n",
    "def is_meaningful_text(text: str) -> bool:\n",
    "    \n",
    "    t = text.strip()\n",
    "\n",
    "    # 너무 짧으면 의미 없음\n",
    "    if len(t) < 20:\n",
    "        return False\n",
    "\n",
    "    # 생략/삭제 표식\n",
    "    if t in [\"내지\", \"삭제\"]:\n",
    "        return False\n",
    "\n",
    "    # 전문개정 표시 제거\n",
    "    if t.startswith(\"전문개정\"):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (2) DOCX 읽기\n",
    "# =========================\n",
    "def load_docx_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    docx 문서의 모든 문단을 읽어서 한 덩어리 문자열로 합침.\n",
    "    - 빈 줄/공백만 있는 문단은 제거\n",
    "    \"\"\"\n",
    "    doc = Document(file_path)\n",
    "    paras = []\n",
    "    for p in doc.paragraphs:\n",
    "        t = p.text.strip()\n",
    "        if t:\n",
    "            paras.append(t)\n",
    "    return \"\\n\".join(paras)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (3) '제n조' 단위로 조문 분리\n",
    "# =========================\n",
    "def split_by_article(full_text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    전체 텍스트를 조문 키(예: 제3조, 제3조의2) 기준으로 나눔.\n",
    "    반환: { \"제3조\": \"본문...\", \"제3조의2\": \"본문...\" }\n",
    "    \"\"\"\n",
    "    # '제숫자조' 또는 '제숫자조의숫자' 패턴\n",
    "    pattern = re.compile(r\"(제\\d+조(?:의\\d+)?)\")\n",
    "\n",
    "    parts = pattern.split(full_text)\n",
    "    # parts 구조 예:\n",
    "    # [조문이전텍스트, \"제1조\", 본문, \"제2조\", 본문, ...]\n",
    "    articles = {}\n",
    "\n",
    "    # (1,3,5...)가 조문명, 그 다음이 본문\n",
    "    for i in range(1, len(parts), 2):\n",
    "        article = parts[i].strip()\n",
    "        body = parts[i + 1].strip() if i + 1 < len(parts) else \"\"\n",
    "        if body:\n",
    "            articles[article] = body\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (4) 항(①②③...) 단위 분리\n",
    "# =========================\n",
    "def split_by_clause(article_body: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    조문 본문을 '①②③...' 항 단위로 나눔.\n",
    "    - 항이 없으면 chunk_id='본문'으로 하나만 반환\n",
    "    반환: [{\"chunk_id\": \"항①\", \"text\": \"...\"}, ...] 또는 [{\"chunk_id\":\"본문\",\"text\":\"...\"}]\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"(①|②|③|④|⑤|⑥|⑦|⑧|⑨|⑩)\")\n",
    "    parts = pattern.split(article_body)\n",
    "\n",
    "    # 항 표시가 없으면 통으로 반환\n",
    "    if len(parts) == 1:\n",
    "        return [{\"chunk_id\": \"본문\", \"text\": article_body.strip()}]\n",
    "\n",
    "    clauses = []\n",
    "    for i in range(1, len(parts), 2):\n",
    "        mark = parts[i]              # 예: \"①\"\n",
    "        text = parts[i + 1].strip()  # 해당 항의 내용\n",
    "\n",
    "        if text:  # 빈 항 방지\n",
    "            clauses.append({\n",
    "                \"chunk_id\": f\"항{mark}\",  # 예: \"항①\"\n",
    "                \"text\": text\n",
    "            })\n",
    "    return clauses\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (5) 1500자 기준으로 추가 분할\n",
    "# =========================\n",
    "def split_by_length(text: str, base_chunk_id: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    text가 MAX_LEN 초과면 잘라서 여러 청크로 분할.\n",
    "    chunk_id 규칙:\n",
    "    - 1500자 이하: base_chunk_id 그대로\n",
    "    - 초과: base_chunk_id_1, base_chunk_id_2, ...\n",
    "    \"\"\"\n",
    "    if len(text) <= MAX_LEN:\n",
    "        return [{\"chunk_id\": base_chunk_id, \"text\": text}]\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    idx = 1\n",
    "\n",
    "    while start < len(text):\n",
    "        end = start + MAX_LEN\n",
    "        piece = text[start:end]\n",
    "\n",
    "        chunks.append({\n",
    "            \"chunk_id\": f\"{base_chunk_id}_{idx}\",\n",
    "            \"text\": piece\n",
    "        })\n",
    "\n",
    "        start = end\n",
    "        idx += 1\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (6) docx 1개 → 청킹 결과 리스트\n",
    "# =========================\n",
    "def chunk_docx(file_path: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    docx 한 개를 읽어서:\n",
    "    - 제n조로 분리\n",
    "    - 항(①②③)으로 분리\n",
    "    - 1500자 초과하면 추가 분할\n",
    "    결과: [{\"article\":..., \"chunk_id\":..., \"text\":...}, ...]\n",
    "    \"\"\"\n",
    "    full_text = load_docx_text(file_path)\n",
    "    articles = split_by_article(full_text)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for article, body in articles.items():\n",
    "        clauses = split_by_clause(body)\n",
    "\n",
    "        for clause in clauses:\n",
    "            # 항/본문 단위 텍스트를 1500자 기준으로 재분할\n",
    "            pieces = split_by_length(clause[\"text\"], clause[\"chunk_id\"])\n",
    "\n",
    "            for piece in pieces:\n",
    "                if not is_meaningful_text(piece[\"text\"]):\n",
    "                    continue\n",
    "                results.append({\n",
    "                    \"article\": article,\n",
    "                    \"chunk_id\": piece[\"chunk_id\"],\n",
    "                    \"text\": piece[\"text\"]\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (7) CSV 저장\n",
    "# =========================\n",
    "def write_csv(output_path: str, rows: List[Dict]):\n",
    "    \"\"\"\n",
    "    rows(list of dict)를 지정 스키마로 CSV 저장.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    fieldnames = [\"id\", \"category\", \"priority\", \"article\", \"chunk_id\", \"source\", \"text\"]\n",
    "\n",
    "    with open(output_path, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (8) 폴더 처리: law/rule → csv\n",
    "# =========================\n",
    "def process_docx_folder(input_dir: str, output_csv: str, source_type: str):\n",
    "    \"\"\"\n",
    "    input_dir 안의 docx 전부 처리해서 output_csv로 저장.\n",
    "    source_type: \"law\" 또는 \"rule\"\n",
    "    \"\"\"\n",
    "    priority = PRIORITY_MAP[source_type]\n",
    "    all_rows = []\n",
    "\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if not file_name.lower().endswith(\".docx\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "\n",
    "        # docx 한 파일 청킹 수행\n",
    "        chunks = chunk_docx(file_path)\n",
    "\n",
    "        # 청크마다 메타데이터 붙여서 rows 생성\n",
    "        for c in chunks:\n",
    "            all_rows.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"category\": source_type,     # ✅ 여기만 바꾼다\n",
    "                \"priority\": priority,\n",
    "                \"article\": c[\"article\"],\n",
    "                \"chunk_id\": c[\"chunk_id\"],\n",
    "                \"source\": file_name,\n",
    "                \"text\": c[\"text\"],\n",
    "            })\n",
    "\n",
    "    # CSV로 저장\n",
    "    write_csv(output_csv, all_rows)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (9) 실행 엔트리\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # ✅ 너 프로젝트 구조에 맞게 여기만 경로 조정하면 됨\n",
    "    LAW_DIR = \"data/raw/law\"\n",
    "    RULE_DIR = \"data/raw/rule\"\n",
    "    OUT_LAW  = r\"data\\processed\\law\\law.csv\"\n",
    "    OUT_RULE = r\"data\\processed\\rule\\rule.csv\"\n",
    "\n",
    "    # law.csv 생성\n",
    "    process_docx_folder(LAW_DIR, OUT_LAW, source_type=\"law\")\n",
    "    print(f\"[OK] law.csv 생성 완료 → {OUT_LAW}\")\n",
    "\n",
    "    # rule.csv 생성\n",
    "    process_docx_folder(RULE_DIR, OUT_RULE, source_type=\"rule\")\n",
    "    print(f\"[OK] rule.csv 생성 완료 → {OUT_RULE}\")\n",
    "\n",
    "    # case는 PDF라서 다음 단계에서 처리할 거라 지금은 스킵\n",
    "    print(\"[SKIP] case/pdf 처리는 다음 단계에서 진행\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd5afc0-86ff-4979-9d59-1103595cc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(r\"C:\\ai\\source\\프로젝트 2\\data\\processed\\law\\law.csv\")\n",
    "\n",
    "# df[df[\"text\"].str.contains(\"내지\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ceb75-7f58-483d-896c-31788cd540c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e16806a-66b9-4712-a7f5-538e0da11a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import pdfplumber\n",
    "from typing import List, Dict\n",
    "\n",
    "MAX_LEN = 1500\n",
    "\n",
    "# =========================\n",
    "# (CASE-1) PDF 전체 텍스트 로드\n",
    "# =========================\n",
    "def load_pdf_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    PDF를 페이지 순서대로 읽어 전체 텍스트로 합침\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            t = page.extract_text()\n",
    "            if t:\n",
    "                texts.append(t.strip())\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (CASE-2) 사례 단위 분리\n",
    "# =========================\n",
    "def split_by_case(text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    '사례 1', '사례 2' 기준으로 텍스트 분리\n",
    "    반환: { '사례 1': '내용...', '사례 2': '내용...' }\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"(사례\\s*\\n?\\s*\\d+)\")\n",
    "    parts = pattern.split(text)\n",
    "\n",
    "    cases = {}\n",
    "    for i in range(1, len(parts), 2):\n",
    "        case_title = parts[i].strip()\n",
    "        body = parts[i + 1].strip() if i + 1 < len(parts) else \"\"\n",
    "        if body:\n",
    "            cases[case_title] = body\n",
    "\n",
    "    return cases\n",
    "\n",
    "# ============================\n",
    "\n",
    "def normalize_case_title(case_title: str) -> str:\n",
    "    \"\"\"\n",
    "    '사례\\\\n1', '사례  2' → '사례 1'\n",
    "    \"\"\"\n",
    "    num = re.findall(r\"\\d+\", case_title)\n",
    "    if not num:\n",
    "        return case_title.strip()\n",
    "    return f\"사례 {num[0]}\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (CASE-3) 1500자 기준 분할\n",
    "# =========================\n",
    "def split_by_length(text: str, case_no: int) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    사례 본문을 1500자 기준으로 분할\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "\n",
    "    if len(text) <= MAX_LEN:\n",
    "        return [{\n",
    "            \"chunk_id\": f\"case_{case_no}_1\",\n",
    "            \"text\": text\n",
    "        }]\n",
    "\n",
    "    start = 0\n",
    "    idx = 1\n",
    "    while start < len(text):\n",
    "        chunks.append({\n",
    "            \"chunk_id\": f\"case_{case_no}_{idx}\",\n",
    "            \"text\": text[start:start + MAX_LEN]\n",
    "        })\n",
    "        start += MAX_LEN\n",
    "        idx += 1\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (CASE-4) case 폴더 → case.csv\n",
    "# =========================\n",
    "def process_case_folder(input_dir: str, output_csv: str):\n",
    "    rows = []\n",
    "\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if not file_name.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        full_text = load_pdf_text(file_path)\n",
    "        cases = split_by_case(full_text)\n",
    "\n",
    "        for case_title, body in cases.items():\n",
    "            norm_title = normalize_case_title(case_title)\n",
    "            case_no = int(re.findall(r\"\\d+\", norm_title)[0])\n",
    "        \n",
    "            pieces = split_by_length(body, case_no)\n",
    "\n",
    "            for piece in pieces:\n",
    "                # 너무 짧은 조각 제거\n",
    "                if len(piece[\"text\"].strip()) < 50:\n",
    "                    continue\n",
    "\n",
    "                rows.append({\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"category\": \"case\",\n",
    "                    \"priority\": 4,\n",
    "                    \"article\": norm_title,          # ← 사례 1, 사례 2\n",
    "                    \"chunk_id\": piece[\"chunk_id\"],  # ← case_1_1 이런 식으로 일치\n",
    "                    \"source\": file_name,\n",
    "                    \"text\": piece[\"text\"]\n",
    "                })\n",
    "\n",
    "    # CSV 저장\n",
    "    import csv\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "        writer = csv.DictWriter(\n",
    "            f,\n",
    "            fieldnames=[\"id\", \"category\", \"priority\", \"article\", \"chunk_id\", \"source\", \"text\"]\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314dead-1551-4b20-9a15-54e366c0056b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85b24bb9-ccd3-4a6d-80e7-005a3448aa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] case.csv 생성 완료 → C:\\ai\\source\\프로젝트 2\\data\\processed\\case\\case.csv\n"
     ]
    }
   ],
   "source": [
    "CASE_DIR = r\"C:\\ai\\source\\프로젝트 2\\data\\raw\\case\"\n",
    "OUT_CASE = r\"C:\\ai\\source\\프로젝트 2\\data\\processed\\case\\case.csv\"\n",
    "\n",
    "process_case_folder(CASE_DIR, OUT_CASE)\n",
    "print(f\"[OK] case.csv 생성 완료 → {OUT_CASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fcdfb-7815-4dc5-bd0b-6c6abe916ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4ef0dcc-03d6-49e6-9ce7-a2d12aa3f7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "      <th>article</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243e0786-a330-4475-a2cd-f7750119749b</td>\n",
       "      <td>case</td>\n",
       "      <td>4</td>\n",
       "      <td>사례 1</td>\n",
       "      <td>case_1_1</td>\n",
       "      <td>2025전세피해지원사례집.pdf</td>\n",
       "      <td>전세대출 연체 문제\\n주요\\n전세피해주택에서 퇴거하고자 하나 임대인이 연락 두절(또...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e5820dc-2fc3-4122-8d35-e32b91540fc0</td>\n",
       "      <td>case</td>\n",
       "      <td>4</td>\n",
       "      <td>사례 2</td>\n",
       "      <td>case_2_1</td>\n",
       "      <td>2025전세피해지원사례집.pdf</td>\n",
       "      <td>전세피해 임차인 무이자 대출 지원 3 생업상 주거이전 문제\\n전세 계약기간이 끝났지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33692535-ffd9-4531-8729-a05c2dd6dd10</td>\n",
       "      <td>case</td>\n",
       "      <td>4</td>\n",
       "      <td>사례 2</td>\n",
       "      <td>case_2_2</td>\n",
       "      <td>2025전세피해지원사례집.pdf</td>\n",
       "      <td>은 임차인이\\n전세대출을 상환하기 어려운 경우, 대출보증기관(HUG, HF, SGI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>675ef49b-5f37-46b0-b5e4-795e410b025a</td>\n",
       "      <td>case</td>\n",
       "      <td>4</td>\n",
       "      <td>사례 4</td>\n",
       "      <td>case_4_1</td>\n",
       "      <td>2025전세피해지원사례집.pdf</td>\n",
       "      <td>깡통주택 매수 문제 5 보증금반환소송 등 소송비용 문제\\n임대인이 보증금을 돌려줄 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c6674abe-c69d-4bd1-897b-c6d358b5623c</td>\n",
       "      <td>case</td>\n",
       "      <td>4</td>\n",
       "      <td>사례 4</td>\n",
       "      <td>case_4_2</td>\n",
       "      <td>2025전세피해지원사례집.pdf</td>\n",
       "      <td>택을 경매신청 하기 위해서는 주택에 전세권을 설정하였거나, 보증금반환청구소송\\n등을...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id category  priority article  chunk_id  \\\n",
       "0  243e0786-a330-4475-a2cd-f7750119749b     case         4    사례 1  case_1_1   \n",
       "1  0e5820dc-2fc3-4122-8d35-e32b91540fc0     case         4    사례 2  case_2_1   \n",
       "2  33692535-ffd9-4531-8729-a05c2dd6dd10     case         4    사례 2  case_2_2   \n",
       "3  675ef49b-5f37-46b0-b5e4-795e410b025a     case         4    사례 4  case_4_1   \n",
       "4  c6674abe-c69d-4bd1-897b-c6d358b5623c     case         4    사례 4  case_4_2   \n",
       "\n",
       "              source                                               text  \n",
       "0  2025전세피해지원사례집.pdf  전세대출 연체 문제\\n주요\\n전세피해주택에서 퇴거하고자 하나 임대인이 연락 두절(또...  \n",
       "1  2025전세피해지원사례집.pdf  전세피해 임차인 무이자 대출 지원 3 생업상 주거이전 문제\\n전세 계약기간이 끝났지...  \n",
       "2  2025전세피해지원사례집.pdf  은 임차인이\\n전세대출을 상환하기 어려운 경우, 대출보증기관(HUG, HF, SGI...  \n",
       "3  2025전세피해지원사례집.pdf  깡통주택 매수 문제 5 보증금반환소송 등 소송비용 문제\\n임대인이 보증금을 돌려줄 ...  \n",
       "4  2025전세피해지원사례집.pdf  택을 경매신청 하기 위해서는 주택에 전세권을 설정하였거나, 보증금반환청구소송\\n등을...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "case_path = r\"C:\\ai\\source\\프로젝트 2\\data\\processed\\case\\case.csv\"\n",
    "df_case = pd.read_csv(case_path)\n",
    "\n",
    "df_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e7245-01fd-4d0e-b960-1332cc0e1725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97487520-19b6-4056-80d7-1bee875b0442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44d7c6b6-0fa3-485a-8a13-95132934644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data/processed/law/law_labeled.csv 완료\n",
      "✅ data/processed/rule/rule_labeled.csv 완료\n",
      "✅ data/processed/case/case_labeled.csv 완료\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "FILES = [\n",
    "    \"data/processed/law/law.csv\",\n",
    "    \"data/processed/rule/rule.csv\",\n",
    "    \"data/processed/case/case.csv\",\n",
    "]\n",
    "\n",
    "LAW_PRIORITY_MAP = {\n",
    "    \"주택임대차보호법\": 1,\n",
    "    \"시행령\": 2,\n",
    "    \"시행규칙/대법원규칙\": 3,\n",
    "    \"민법\": 4,\n",
    "    \"사례/판례/피해상담\": 50,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# law_type 판별 함수\n",
    "# =========================\n",
    "def classify_law_type(source, article):\n",
    "    source = str(source)\n",
    "    article = str(article)\n",
    "\n",
    "    if \"사례\" in article or \"판례\" in source or \"사례집\" in source:\n",
    "        return \"사례/판례/피해상담\"\n",
    "\n",
    "    if \"주택임대차보호법\" in source and \"법률\" in source:\n",
    "        return \"주택임대차보호법\"\n",
    "\n",
    "    if \"시행령\" in source:\n",
    "        return \"시행령\"\n",
    "\n",
    "    if \"시행규칙\" in source or \"대법원규칙\" in source:\n",
    "        return \"시행규칙/대법원규칙\"\n",
    "\n",
    "    if \"민법\" in source:\n",
    "        return \"민법\"\n",
    "\n",
    "    return \"사례/판례/피해상담\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 실행\n",
    "# =========================\n",
    "for file in FILES:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df[\"law_type\"] = df.apply(\n",
    "        lambda row: classify_law_type(row.get(\"source\"), row.get(\"article\")),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df[\"priority\"] = df[\"law_type\"].map(LAW_PRIORITY_MAP)\n",
    "\n",
    "    out = file.replace(\".csv\", \"_labeled.csv\")\n",
    "    df.to_csv(out, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"✅ {out} 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f42d9d4-7947-4001-9cf4-52e5eddc5060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b93da-ddf1-42a7-97ca-761dbd5b884a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
